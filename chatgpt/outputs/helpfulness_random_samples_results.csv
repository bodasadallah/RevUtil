review_point,paper_id,venue,focused_review,actionability,actionability_label,actionability_label_type,batch,grounding_specificity,grounding_specificity_label,grounding_specificity_label_type,verifiability,verifiability_label,verifiability_label_type,helpfulness,helpfulness_label,helpfulness_label_type,professional_tone,professional_tone_label,professional_tone_label_type,valid_point,valid_point_label,valid_point_label_type,chatgpt_helpfulness_definitions_score,chatgpt_helpfulness_definitions_rationale
"- The applicability of the robust training scheme seems unlikely to scale to practical datasets, particularly those supported on high-dimensional domains. It seems like the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension.",NIPS_2020_916,NIPS_2020,"My major complaints can be characterized into the following bullet points: - Robustness is argued only indirectly by way of Lipschitz constants. While the authors present a novel formulation (i.e., differing from the standard low-lipschitz=>robustness claims in the ML literature) of how controlling the lipschitz function of the classifier controls sensitivity to adversarial perturbations, this setting differs slightly from standard classification settings. In the standard classification setting, where labels are 1-hot vectors in R^dim(Y), a classifier typically returns as a label the argmax of the vector-valued function. Robustness then is usually considered as whether the argmax returns the right label, rather than a strictly-convex loss applied to the one-hot-label: this work incorporates 'confidence' into the robustness evaluation. - The applicability of the robust training scheme seems unlikely to scale to practical datasets, particularly those supported on high-dimensional domains. It seems like the accuracy would scale unfavorably unless the size of V scales exponentially with the dimension. - The example data distribution could be better chosen. As it stands, a classifier with (true) loss would require a Lipschitz constant that tends to infinity. A more standard/practical dataset would admit a perfect classifier that has a valid Lipschitz constant.","['1', '2', '1', '1']",1.0,gold,3,"['1', '5', '4', '3']",,,"['4', '3', '3', '5']",3,silver,"['2', '3', '2', '2']",2.0,gold,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,3,"the comment identifies a potential weakness in the scalability of the robust training scheme to practical high-dimensional datasets. however, it lacks specific guidance or suggestions for how the authors might address this issue. the concern about accuracy scaling unfavorably is noted, but without elaboration on how to measure or improve this scalability, the feedback is somewhat helpful but incomplete. the authors gain some insights into a potential problem area but need more detailed suggestions to effectively improve their draft."
"- Relating to the first point, authors should describe more about the traits of the experts and justify why annotation must be carried out by the experts, outside its commercial values. Were the experts linguistic experts or domain experts? Was annotation any different from what non-experts would do? Did it introduce any linguistic challenges?",ARR_2022_112_review,ARR_2022,"- The paper does not discuss much about linguistic aspect of the dataset. While their procedures are thoroughly described, analyses are quite limited in that they do not reveal much about linguistic challenges in the dataset as compared to, for example, information extraction. The benefit of pretraining on the target domain seems to be the only consistent finding in their paper and I believe this argument holds in majority of datasets.
- Relating to the first point, authors should describe more about the traits of the experts and justify why annotation must be carried out by the experts, outside its commercial values. Were the experts linguistic experts or domain experts? Was annotation any different from what non-experts would do? Did it introduce any linguistic challenges?
- The thorough description of the processes is definitely a strength, it might be easier to follow if the authors moved some of the details to appendix.
L23: I was not able to find in the paper that single-task models consistently outperformed multi-task models. Could you elaborate a bit more about this?
Table 1: It would be easier if you explain about ""Type of Skills"" in the caption. It might also be worth denoting number of sentences for your dataset, as Jia et al (2018) looks larger than SkillSpan at a first glance.
Section 3: This section can be improved to better explain which of ""skill"", ""knowledge"" and ""attitude"" correspond to ""hard"" and ""soft"" knowledge. Soft skills are referred as attitudes (L180) but this work seems to only consider ""skill"" and ""knowledge"" (L181-183 and Figure 1)? This contradicts with the claim that SkillSpan incorporates both hard and soft knowledge.
L403: I don't think it is the field's norm to call it multi-task learning when it is merely solving two sequential labeling problems at a same time.
L527: Is there any justification as to why you suspected that domain-adaptive pre-raining lead to longer spans?
L543: What is continuous pretraining?
L543: ""Pre-training"" and ""pretraining"" are not spelled consistently.","['2', '5', '4', '4', '3', '1', '5', '5']",5.0,gold,2,"['3', '5', '5', '5', '4', '2', '5', '3']",5.0,gold,"['1', '5', 'X', 'X', '4', '1', '5', 'X']",X,gold,"['2', '5', '5', '5', '3', '3', '5', '4']",5.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0', '0', '0', '0']",0.0,gold,4,"the comment identifies a specific area that needs more clarification in the authors' draft, namely the traits of the experts involved and the necessity of using experts for annotation beyond its commercial value. it provides clear guidance on what additional information is needed (type of experts, differences in annotation, potential linguistic challenges). this feedback is actionable and would help the authors improve their draft significantly. however, the comment could be more comprehensive by suggesting how the authors might address these points in their draft, which would elevate the score to a 5."
"2 The experiments are not quite convincing. The authors choose the old baseline like R3D and C3D. To reduce computation complexity, many papers have been proposed in 3D CNN (X3D, SlowFast, etc). Does the proposed method also works on these 3D CNNs? Or compared to these approaches, what is the advantage of the proposed method?",ICLR_2023_4741,ICLR_2023,"Weakness
1 The novelty is limited. The low-rank design is relevant to (Hu et al., 2021). The sparse design is similar to Taylor pruning (Molchanov et al., 2019).
2 The experiments are not quite convincing. The authors choose the old baseline like R3D and C3D. To reduce computation complexity, many papers have been proposed in 3D CNN (X3D, SlowFast, etc). Does the proposed method also works on these 3D CNNs? Or compared to these approaches, what is the advantage of the proposed method?
3 The paper is hard to follow. In fact, I have to read many times to get what it is. I understand it is a theoretical-kind paper. But please further explain the mathmetical formulation clearly to show why and how it works.","['4', '4', '5']",4.0,silver,4,"['3', '5', '5']",5.0,silver,"['4', '4', '5']",4,silver,"['4', '4', '5']",4.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the comment is mostly helpful as it clearly identifies a weakness in the experimental setup and suggests exploring more recent baselines, which is actionable for the authors. it also prompts the authors to demonstrate the advantages of their method over these recent techniques, which could lead to significant improvements in their draft. however, it could be more comprehensive by providing additional guidance or specific examples on how to implement these suggestions, hence it does not receive the highest score."
"1) p_k symbols are used without definition (tough I think I these are the network predictions p(\hat{y}=k I) 2) the relation of the formula presented to the known EMD is not clear. The latter is a problem solved as linear programming or similar, and not a closed form formula",ICLR_2021_2208,ICLR_2021,"+ Nice idea Consistent improvements over cross entropy for hierarchical class structures Improvements w.r.t other competitors (though not consistent) Good ablation study
The improvements are small The novelty is not very significant
More comments:
Figure 1: - It is not clear what distortion is at this stage - It is not clear what perturbed MNist is, and respectively: why is the error of a 3-layer CNN so high (12-16% error are reported)? CNNs with 2-3 layers can solve MNist with accuracy higher than 99.5%? - This figure cannot be presented on page 2 without proper definitions. It should be either presented on page 5, where the experiment is defined, or better explained
Page 4: It is said that s can be computed efficiently and this is shown in the appendix, but the version I have do not have an appendix Page 6: the XE+EMD method is not present in a comprehensible manner. 1) p_k symbols are used without definition (tough I think I these are the network predictions p(\hat{y}=k I) 2) the relation of the formula presented to the known EMD is not clear. The latter is a problem solved as linear programming or similar, and not a closed form formula 3) it is not clear what the role of \mu is and why can be set to 3 irrespective of the scale of metric D page 7: The experiments show small, but consistent improvements of the suggested method over standard cross entropy, and improvements versus most competitors in most cases
I have read the reviews of others and the author's response. My main impression of the work remains as it was: that it is nice idea with small but significant empirical success. However, my acquaintance with the previous literature in this subject is partial compared to the acquaintance of other reviewers, so It may well be possible that they are in a better position than me to see the incremental nature of the proposed work. I therefore reduce the rating a bit, to become closer to the consensus.","['2', '4']",,,4,"['2', '5']",,,"['2', '3']",,,"['2', '4']",,,"['1', '1']",1.0,silver,"['0', '0']",0.0,silver,4,"the review point identifies two distinct weaknesses in the draft: the undefined use of symbols and the unclear relation of a formula to the known earth mover's distance (emd). it provides clear and actionable feedback by pointing out specific elements needing clarification or definition, which should be helpful for the authors to improve their draft. however, the comment could be more detailed by suggesting how to address these issues, particularly the relationship with emd. therefore, it is mostly helpful but could be expanded to be fully comprehensive."
- The authors approach is only applicable for problems that are small or medium scale. Truly large problems will overwhelm current LP-solvers.,NIPS_2018_430,NIPS_2018,"- The authors approach is only applicable for problems that are small or medium scale. Truly large problems will overwhelm current LP-solvers. - The authors only applied their method on peculiar types of machine learning applications that were already used for testing boolean classifier generation. It is unclear whether the method could lead to progress in the direction of cleaner machine learning methods for standard machine learning tasks (e.g. MNIST). Questions: - How where the time limits in the inner and outer problem chosen? Did larger timeouts lead to better solutions? - It would be helpful to have an algorithmic writeup of the solution of the pricing problem. - SVM gave often good results on the datasets. Did you use a standard SVM that produced a linear classifier or a Kernel method? If the former is true, this would mean that the machine learning tasks where rather easy and it would be necessary to see results on more complicated problems where no good linear separator exists. Conclusion: I very much like the paper and strongly recommend its publication. The authors propose a theoretically well grounded approach to supervised classifier learning. While the number of problems that one can attack with the method is not so large, the theoretical (problem formulation) and practical (Dantzig-Wolfe solver) contribution can possibly serve as a starting point for further progress in this area of machine learning.","['1', '1', '1']",1.0,gold,4,"['1', '3', '3']",3.0,silver,"['3', '3', 'X']",3,silver,"['2', '3', '2']",2.0,silver,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,3,"the comment identifies a valid limitation of the authors' approach concerning the scalability of their solution with large problems. however, it lacks specific suggestions or guidance on how the authors might address this limitation or improve their approach to accommodate larger problems. thus, while it enables the authors to acknowledge a potential issue, it is somewhat helpful but not comprehensive enough to guide substantial improvements."
"- The amount of data used to train the text disambiguation model was significantly lower than the data used for training the end-to-end system. Given that the difference between the two proposed systems is only a few percentage points, it brings into question the conclusion that the direct model is clearly the better of the two (but they still are both demonstrably superior to the baseline).",CEPkRTOlut,EMNLP_2023,"No ethics section, but there are ethical issues that deserve discussion (see the ethics section).
Also a few, mostly minor points:
- When the corpus was created, participants were told to speak in such a way to make the intent of the speech unambiguous. This may lead to over-emphasis compared with natural speech. There was no mention of any evaluation of the data to avoid this.
- The corpus was created with only ambiguous sentences, and the non-ambiguous content was taken from another source. There is a chance that different recording qualities between news (LSCVR) and crowdsourced data could artificially raise the ability of the model to distinguish between ambiguous (tag 1 or 2) and non-ambiguous (tag 0) sentences.
- The amount of data used to train the text disambiguation model was significantly lower than the data used for training the end-to-end system. Given that the difference between the two proposed systems is only a few percentage points, it brings into question the conclusion that the direct model is clearly the better of the two (but they still are both demonstrably superior to the baseline).
- It would be hard to reproduce the fine tuning of the IndoBART model without a little more information. Was it fine-tuned for a certain number of steps, for example?","['1', '2', '1', '2']",1.0,silver,3,"['5', '5', '5', '3']",5.0,gold,"['4', '4', '4', '5']",4,gold,"['2', '4', '2', '2']",2.0,gold,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,3,"the review point identifies a weakness in the methodology related to the data used for training different components of the system, which could affect the validity of the conclusions. however, it lacks specific guidance on how to address this issue, such as suggestions for additional experiments or data collection strategies. therefore, while the comment provides some insights into potential shortcomings of the study, it does not fully equip the authors with the necessary information to improve their draft."
"2) it only compares with some weak baselines in Tables 3, 4 and 6. Though the approach can surpass the sentence-level model baseline, the naive document-to-document translation model and Zheng et al. (2020), these baselines seem weak, for example, Voita et al. (2019) achieve 81.6, 58.1, 72.2 and 80.0 for deixis, lexical cohesion, ellipsis (infl.) and ellipsis (VP) respectively with the CADec model, while this work only gets 64.7, 46.3, 65.9 and 53.0. It seems that there is still a large gap with the presented approach in these linguistic evaluations.",ARR_2022_123_review,ARR_2022,"1) it uses different experiment settings (e.g., a 32k batch size, a beam size of 5) and does not mention some details (e.g., the number of training steps), these different settings may contribute the performance and the comparisons in Table 2 may not be sufficiently reliable.
2) it only compares with some weak baselines in Tables 3, 4 and 6. Though the approach can surpass the sentence-level model baseline, the naive document-to-document translation model and Zheng et al. (2020), these baselines seem weak, for example, Voita et al. (2019) achieve 81.6, 58.1, 72.2 and 80.0 for deixis, lexical cohesion, ellipsis (infl.) and ellipsis (VP) respectively with the CADec model, while this work only gets 64.7, 46.3, 65.9 and 53.0. It seems that there is still a large gap with the presented approach in these linguistic evaluations.
3) the multi-resolutional data processing approach may somehow increase the instance weight of the document-level data, and how this affects the performance is not studied.
1) It's better to adopt experiment settings consistent with previous work.
2) There is still a large performance gap compared to Voita et al. (2019) in linguistic evaluations, while BLEU may not be able to reflect these document-level phenomena and linguistic evaluations are important. The issues for the performance gap shall be investigated and solved.
3) It's better to investigate whether the model really leverages document-level contexts correctly, probably refer to this paper: Do Context-Aware Translation Models Pay the Right Attention? In ACL 2021.","['3', '5', '1']",,,1,"['4', '5', '5']",5.0,silver,"['5', '5', '5']",5,gold,"['5', '5', '2']",5.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0']",0.0,silver,3,"the review point identifies a significant shortcoming in the authors' work by highlighting that their approach is only compared with weak baselines. this insight is important as it highlights a potential gap in the evaluation of the proposed method. however, the feedback lacks detailed guidance on how the authors could address this issue beyond noting the weakness of their baselines and suggesting a comparison with stronger models like the cadec model from voita et al. (2019). providing more specific suggestions or strategies for improvement could make this comment more helpful, potentially raising it to a higher score."
"- Lack of comparison with a highly relevant method. [1] also proposes to utilize the previous knowledge with ‘inter-task ensemble’, while enhancing the current task’s performance with ‘intra-task’ ensemble. Yet, the authors didn’t include the method comparison or performance comparison.",yIv4SLzO3u,ICLR_2024,"- Lack of comparison with a highly relevant method. [1] also proposes to utilize the previous knowledge with ‘inter-task ensemble’, while enhancing the current task’s performance with ‘intra-task’ ensemble. Yet, the authors didn’t include the method comparison or performance comparison.
- Novelty is limited. From my perspective, the submission simply applies the existing weight averaging and the bounded update to the class incremental learning problems.
- No theoretical justification or interpretation. Is there any theoretical guarantee that to what extent inter-task weight averaging or bounded update counter catastrophic forgetting?
- Though it shows in Table 3 that bounded model update mitigates the forgetting, the incorporation of bounded model update doesn’t seem to have enough motivation from the methodological perspective. The inter-task weight average is designed to incorporate both old and new knowledge, which is by design enough to tackle forgetting.
##### References:
1.Miao, Z., Wang, Z., Chen, W., & Qiu, Q. (2021, October). Continual learning with filter atom swapping. In International Conference on Learning Representations.","['2', '4', '5', '5']",5.0,silver,3,"['2', '3', '5', '5']",5.0,silver,"['2', '5', '5', 'X']",5,silver,"['2', '4', '5', '4']",4.0,silver,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,4,"the comment highlights a specific weakness in the draft by identifying the omission of a comparison with a highly relevant method. it also provides a reference to the work [1], where 'inter-task ensemble' and 'intra-task' ensemble are used to enhance performance. this gives the authors a concrete direction for improving their draft by including these comparisons. however, the comment could be more helpful if it elaborated on why this comparison is important or how it might impact the results, thereby expanding on the guidance provided to the authors."
"1 The Algorithm should be presented and described in detail, which is helpful for understanding the proposed method.",NIPS_2022_528,NIPS_2022,"weakness 1 The Algorithm should be presented and described in detail. 2 The background of Sharpness-Aware Minimization (SAM) shoud be described in detail.
1 The Algorithm should be presented and described in detail, which is helpful for understanding the proposed method. 2 The background of Sharpness-Aware Minimization (SAM) shoud be described in detail.","['3', '3', '5']",3.0,silver,4,"['2', '2', '5']",2.0,silver,"['2', '1', 'X']",,,"['2', '2', '4']",2.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the comment highlights an area for improvement by mentioning that the algorithm should be presented and described in detail. this is somewhat helpful as it gives the authors insight into what needs more attention. however, it lacks specificity and actionable suggestions, such as which parts of the algorithm need more detail or what aspects of the method need clarification, thus not fully addressing the author's needs for improving the draft."
"6: How many topics were used? How did you get topic-word parameters for this ""real"" dataset? How big is the AG news dataset? Main paper should at least describe how many documents in train/test, and how many vocabulary words.",ICLR_2022_1872,ICLR_2022,"I list 5 concerns here, with detailed discussion and questions for the authors below
W1: While theorems suggest ""existence"" of a linear transformation that will approximate the posterior, the actual construction procedure for the ""recovered topic posterior"" is unclear
W2: Many steps are difficult to understand / replicate from main paper
W3: Unclear what theorems can say about finite training sets
W4: Justification / intuition for Theorems is limited in the main paper
Responses to W1-W3 are most important for the rebuttal.
W1: Actual procedure for constructing the ""recovered topic posterior"" is unclear
In both synthetic and real experiments, the proposed self-supervised learning (SSL) method is used to produce a ""recovered topic posterior"" p( w x). However, the procedure used here is unclear... how do we estimate p( w x) using the learning function f(x)?
The theorems imply that a linear function exists with limited (or zero) approximation error for any chosen scalar summary of the doc-topic weights w. However, how such a linear function is constructed is unclear. The bottom of page four suggests that when t=1 and A is full rank, that ""one can use the pseudoinverse of A to recover the posterior"", however it seems (1) unclear what the procedure is in general and what its assumptions are, and (2) odd that the prior may not needed at all.
Can the authors clarify how to estimate the recovered topic posterior using the proposed SSL method?
W2: Many other steps are difficult to understand / replicate from main paper
Here's a quick list of questions on experimental steps I am confused about / would have trouble reproducing
For the toy experiments in Sec. 5:
Do you estimate the topic-word parameter A? Or assume the true value is given?
What is the format for document x provided as input to the neural networks that define f(x)? The top paragraph of page 7 makes it seem like you provide an ordered list of words. Wouldn't a bag-of-words count vector be a more robust choice?
How do you set t=1 (predict one word given others) but somehow also use ""the last 6 words are chosen as the prediction target""?
How do you estimate the ""recovered topic posterior"" for each individual model (LDA, CTM, etc)? Is this also using HMC (which is used to infer the ground-truth posterior)?
Why use 2000 documents for the ""pure"" topic model but 500 in test set for other models? Wouldn't more complex models benefit from a larger test set?
For the real experiments in Sec. 6:
How many topics were used?
How did you get topic-word parameters for this ""real"" dataset?
How big is the AG news dataset? Main paper should at least describe how many documents in train/test, and how many vocabulary words.
W3: Unclear what theorems / methods can say about finite training sets
All the theorems seem to hold when considering terms that are expectations over a known distribution over observed-data x and missing-data y. However, in practical data analysis we do not know the true data generating distribution, we only have a finite training set.
I am wondering about this method's potential in practice for modest-size datasets. For the synthetic dataset with V=5000 (a modest vocabulary size), the experiments considered 0.72 million to 6 million documents, which seems quite large.
What practically must be true of the observed dataset for the presented methods to work well?
W4: Justification / intuition for Theorems is limited in the main paper
All 3 theorems in the main paper are presented without much intuition or justification about why they should be true, which I think limits their impact on the reader. (I'll try to wade thru the supplement, but did not have time before the review deadline).
Theorem 3 tries to give intuition for the t=1 case, but I think could be stronger: why should f(x) have an optimal form p ( y = v 1 x )
? Why should ""these probabilities"" have the form A E [ w x ]
? I know space is limited, but helping your reader figure things out a bit more explicitly will increase the impact.
Furthermore, the reader would benefit from understanding how tight the bounds in Theorem 4 are. Can we compute the bound quality for toy data and understand it more practically?
Detailed Feedback on Presentation
No need to reply to these in rebuttal but please do address as you see fit in any revision
Page 3:
""many topic models can be viewed""... should probably say ""the generative process of many topic models can be viewed...""
the definition of A_ij is not quite right. I would not say ""word i \in topic j"", I would say ""word i topic j"". A word is not contained in a topic, Each word has a chance of being generated.
I'd really avoid writing Δ ( K )
and would just use Δ
throughout .... unclear why this needs to be a function of K
but the topic-word parameters (whose size also depends on K
) does not
Should we call the reconstruction objective a ""partial reconstruction"" or ""masked reconstruction""? I'm used to reconstruction in an auto-encoder context, where the usual ""reconstruction"" objective is literally to recover all observed data, not a piece of observed data that we are pretending not to see
In Eq. 1, are you assuming an ordered or unordered representation of the words in x and y?
Page 4:
I would not reuse the variable y in both reconstruction and contrastive contexts. Find another variable. Same with theta.
Page 5:
I would use f ∗
to denote the exact minimizer, not just f
Figure 2 caption should clarify:
what is the takeaway for this figure? Does reader want to see low values? Does this figure suggest the approach is working as expected?
what procedure is used for the ""recovered"" posterior? Your proposed SSL method?
why does Pure have a non-monotonic trend as alpha gets larger?","['5', '5', '5']",5.0,gold,4,"['3', '3', '3']",3.0,gold,"['2', 'X', 'X']",X,silver,"['3', '4', '4']",4.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the comment identifies specific areas where the main paper lacks information, such as the number of topics used, the process for obtaining topic-word parameters, and details about the dataset size. however, it lacks depth as it does not provide suggestions on how to address these gaps or offer explicit guidance on how the authors can improve the draft. while the authors gain some understanding of the missing elements, the feedback does not thoroughly empower them to enhance the manuscript."
"2. Â Some ablation study is missing, which could cause confusion and extra experimentation for practitioners. For example, the \sigma in the RBF kernel seems to play a crucial role, but no analysis is given on it. Figure 4 analyzes how changing \lambda changes the performance, but it would be nice to see how \eta and \tau in equation (7) affect performance. Minor comments:",NIPS_2019_1131,NIPS_2019,"1. There is no discussion on the choice of ""proximity"" and the nature of the task. On the proposed tasks, proximity on the fingertip Cartesian positions is strongly correlated with proximity in the solution space. However, this relationship doesn't hold for certain tasks. For example, in a complicated maze, two nearby positions in the Euclidean metric can be very far in the actual path. For robotic tasks with various obstacles and collisions, similar results apply. The paper would be better if it analyzes what tasks have reasonable proximity metrics, and demostrate failure on those that don't. 2. Â Some ablation study is missing, which could cause confusion and extra experimentation for practitioners. For example, the \sigma in the RBF kernel seems to play a crucial role, but no analysis is given on it. Figure 4 analyzes how changing \lambda changes the performance, but it would be nice to see how \eta and \tau in equation (7) affect performance. Minor comments: 1. The diversity term, defined as the facility location function, is undirected and history-invariant. Thus it shouldn't be called ""curiosity"", since curiosity only works on novel experiences. Please use a different name. 2. The curves in Figure 3 (a) are suspiciously cut at Epoch = 50, after which the baseline methods seem to catch up and perhaps surpass CHER. Perhaps this should be explained.","['5', '5', '5', '5']",5.0,gold,3,"['5', '5', '5', '5']",5.0,gold,"['5', 'X', '4', '5']",5,silver,"['5', '5', '5', '5']",5.0,gold,"['1', '1', '1', '0']",1.0,gold,"['0', '0', '0', '1']",0.0,gold,4,"the comment is mostly helpful as it identifies specific areas where the analysis is lacking, particularly regarding the ablation study related to parameters \(\sigma\), \(\eta\), and \(\tau\) in the rbf kernel and equation (7), respectively. it highlights the importance of these parameters and how their omission could lead to confusion for practitioners. however, while the comment is actionable by suggesting the inclusion of analyses for these parameters, it could be more comprehensive by specifying how these analyses would benefit the overall study or providing a direction on how to conduct them. despite this, the feedback is clear and provides a good basis for the authors to enhance their work."
"2. The contribution of different modalities of different instances may be different, e.g., we have modalities A and B, some instances with good performance of modality A which belongs to the strong modality, whereas some instances with good performance modality B which belongs to the strong modality. Equation 3 directly removes the modal subset of all instances. How to deal with the problem mentioned above.",NIPS_2021_2152,NIPS_2021,"Weakness: 1. This manuscript is more like an experimental discovery paper, and the proposed method is similar to the traditional removal method, i.e., traverse all the modal feature subsets and calculate the perceptual score, removing the last subset. The reviewer believes that the contribution of the manuscript still has room for improvement. 2. The contribution of different modalities of different instances may be different, e.g., we have modalities A and B, some instances with good performance of modality A which belongs to the strong modality, whereas some instances with good performance modality B which belongs to the strong modality. Equation 3 directly removes the modal subset of all instances. How to deal with the problem mentioned above.","['4', '3', '1', '3']",3.0,silver,3,"['5', '5', '1', '5']",5.0,gold,"['5', '4', 'X', 'X']",X,silver,"['5', '4', '1', '3']",,,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,2,"the comment identifies an issue related to how different modalities perform across instances and questions the approach used in equation 3. however, it is vague and lacks clarity on how exactly the issue impacts the paper's findings. it does not provide actionable guidance or suggestions on how the authors can address this problem in their draft, making it only slightly beneficial."
"1) The character tri-gram LSTM seems a little unmotivated. Did the authors try other character n-grams as well? As a reviewer, I can guess that character tri-grams roughly correspond to morphemes, especially in Semitic languages, but what made the authors report results for 3-grams as opposed to 2- or 4-? In addition, there are roughly 26^3=17576 possible distinct trigrams in the Latin lower-case alphabet, which is enough to almost constitute a word embedding table. Did the authors only consider observed trigrams? How many distinct observed trigrams were there?",ACL_2017_477_review,ACL_2017,"1) The character tri-gram LSTM seems a little unmotivated. Did the authors try other character n-grams as well? As a reviewer, I can guess that character tri-grams roughly correspond to morphemes, especially in Semitic languages, but what made the authors report results for 3-grams as opposed to 2- or 4-? In addition, there are roughly 26^3=17576 possible distinct trigrams in the Latin lower-case alphabet, which is enough to almost constitute a word embedding table. Did the authors only consider observed trigrams? How many distinct observed trigrams were there?
2) I don't think you can meaningfully claim to be examining the effectiveness of character-level models on root-and-pattern morphology if your dataset is unvocalised and thus doesn't have the 'pattern' bit of 'root-and-pattern'. I appreciate that finding transcribed Arabic and Hebrew with vowels may be challenging, but it's half of the typology.
3) Reduplication seems to be a different kind of phenomenon to the other three, which are more strictly morphological typologies. Indonesian and Malay also exhibit various word affixes, which can be used on top of reduplication, which is a more lexical process. I'm not sure splitting it out from the other linguistic typologies is justified.
- General Discussion: 1) The paper was structured very clearly and was very easy to read.
2) I'm a bit puzzled about why the authors chose to use 200 dimensional character embeddings. Once the dimensionality of the embedding is greater than the size of the vocabulary (here the number of characters in the alphabet), surely you're not getting anything extra?
------------------------------- Having read the author response, my opinions have altered little. I still think the same strengths and weakness that I have already discussed hold.","['3', '5', '5']",5.0,silver,1,"['4', '5', '4']",4.0,silver,"['X', '5', '5']",5,silver,"['3', '4', '5']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,5,"the review point is highly helpful as it thoroughly identifies a potential weakness in the choice of character tri-grams for the lstm model and questions the motivation behind this choice. it challenges the authors to consider alternative n-grams and provides a specific rationale for why this might be significant, particularly in the context of semitic languages. additionally, it poses questions about the number of observed trigrams, encouraging the authors to clarify their experimental choices and the scope of their dataset. this detailed feedback empowers the authors to critically evaluate and possibly improve their methodology, making significant improvements to their draft."
"3. The approach section is missing in the main paper. The reviewer did go through the “parallelization descriptions” in the supplementary material but the supplementary should be used more like additional information and not as an extension to the paper as it is. Timothy Nguyen, Zhourong Chen, and Jaehoon Lee. Dataset meta-learning from kernel ridge-regression. In International Conference on Learning Representations, 2021. Update: Please see my comment below. I have increased the score from 3 to 5.",NIPS_2021_386,NIPS_2021,"1. It is unclear if this proposed method will lead to any improvement for hyper-parameter search or NAS kind of works for large scale datasets since even going from CIFAR-10 to CIFAR-100, the model's performance reduced below prior art (if #samples are beyond 1). Hence, it is unlikely that this will help tasks like NAS with ImageNet dataset. 2. There is no actual new algorithmic or research contribution in this paper. The paper uses the methods of [Nguyen et al., 2021] directly. The only contribution seems to be running large-scale experiments of the same methods. However, compared to [Nguyen et al., 2021], it seems that there are some qualitative differences in the obtained images as well (lines 173-175). The authors do not clearly explain what these differences are, or why there are any differences at all (since the approach is identical). The only thing reviewer could understand is that this is due to ZCA preprocessing which does not sound like a major contribution. 3. The approach section is missing in the main paper. The reviewer did go through the “parallelization descriptions” in the supplementary material but the supplementary should be used more like additional information and not as an extension to the paper as it is.
Timothy Nguyen, Zhourong Chen, and Jaehoon Lee. Dataset meta-learning from kernel ridge-regression. In International Conference on Learning Representations, 2021.
Update: Please see my comment below. I have increased the score from 3 to 5.","['5', '5', '5']",5.0,gold,4,"['5', '5', '5']",5.0,gold,"['5', '5', '2']",5,silver,"['5', '5', '4']",5.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the review point is mostly helpful as it clearly points out a significant structural issue with the paper: the absence of the approach section in the main document. this feedback is actionable since it suggests the authors should integrate crucial elements of the 'parallelization descriptions' from the supplementary material into the main text. the comment emphasizes the importance of keeping the supplementary material as additional rather than essential reading. however, the review could have been more helpful if it included specific suggestions on how to incorporate the material into the paper or detailed the impacts of the missing section on the paper's understanding."
4)Why the results of Table 6 is not aligned with Table 1 (MCT-pair)? Also what about the ablation studies of MCT without the adaptive metrics.,ICLR_2021_2846,ICLR_2021,"Weakness: There are some concerns authors should further address: 1)The transductive inference stage is essentially an ensemble of a serial of models. Especially, the proposed data perturbation can be considered as a common data augmentation. What if such an ensemble is applied to the existing transductive methods? And whether the flipping already is adopted in the data augmentation before the inputs fed to the network? 2)During meta-training, only the selected single path is used in one transductive step, what about the performance of optimizing all paths simultaneously? Given during inference all paths are utilized. 3)What about the performance of MCT (pair + instance)? 4)Why the results of Table 6 is not aligned with Table 1 (MCT-pair)? Also what about the ablation studies of MCT without the adaptive metrics. 5)Though this is not necessary, I'm curious about the performance of the SOTA method (e.g. LST) combined with the adaptive metric.","['2', '4', '4']",4.0,silver,4,"['5', '5', '5']",5.0,gold,"['2', 'X', 'X']",X,silver,"['2', '5', '4']",,,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the review point identifies discrepancies between two tables and suggests an area for further analysis (ablation studies). however, it lacks specificity and depth. it does not provide detailed guidance on how to address the misalignment between the tables or clarify what specific insights the ablation studies should uncover. this makes it somewhat helpful, as it highlights areas needing attention, but leaves the authors with limited actionable steps for improvement."
"• I’m not convinced that the binary classification is a justifiable baseline metrics. While I agree with the TAL task is really important here and a good problem to solve, I’m not sure how coarse grained binary classification can assess models understanding of fine-grained error like technique error.",Uj2Wjv0pMY,ICLR_2024,"•	Compared to Assembly 101 (error detection), the paper seems like an inferior / less complicated dataset. Claims like higher ratio of error to normal videos needs to be validated.
•	Compared to datasets, the dataset prides itself on adding different modalities especially depth channel (RGB-D). The paper fails to validate the necessities of such modality. One crucial different between assembly dataset is use of depth values. What role does it play in training baseline models? Does it boost the model’s performance if these weren’t present. In current deep learning area, depth channels should be reasonably be producible via the help of existing models.
•	I’m not convinced that the binary classification is a justifiable baseline metrics. While I agree with the TAL task is really important here and a good problem to solve, I’m not sure how coarse grained binary classification can assess models understanding of fine-grained error like technique error.
•	Timing Error (Duration of an activity) and Temperature based error, does these really need ML based solutions? In sensitive tasks, simple sensor reading can indicate error. I’m not sure testing computer vision models on such tasks is justifiable. These require more heuristics-based methods, working with if-else statement.
•	Procedure Learning: its very vaguely defined, mostly left unexplained and seems like an after thought. I recommend authors devote passage to methods “M1 (Dwibedi et al., 2019)” and “M2 (Bansal, Siddhant et al., 2022)”. In Table 5, value of lambda? Is not mentioned.
•	The authors are dealing with a degree of subjectivity in terms of severity of errors. It would have been greatly beneficial, if the errors could be finely measured. For example if the person uses a tablespoon instead of teaspoon, is still an error? Some errors are more grave than others, is there a weighted scores? Is there a way to measure level of deviation for each type of error or time stamp of occurrence of error. Is one recipe more difficult than the other recipe.","['2', '2', '1']",2.0,silver,4,"['3', '5', '3']",3.0,silver,"['1', '2', '4']",,,"['2', '3', '3']",3.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '1']",0.0,silver,3,"the comment raises a concern about the suitability of binary classification as a baseline metric, suggesting that it may not effectively measure models' understanding of finer-grained errors. this provides the authors with valuable insight into a potential weakness in their methodology. however, the feedback is somewhat vague, as it doesn't offer specific alternative metrics or approaches to address the issue. consequently, while the authors gain awareness of a possible problem, they are left with limited guidance on how to address it, rendering the comment somewhat helpful."
"1. The paper raises two hypotheses in lines 078-086 about multilinguality and country/language-specific bias. While I don't think the hypotheses are phrased optimally (could they be tested as given?), their underlying ideas are valuable. However, the paper actually does not really study these hypotheses (nor are they even mentioned/discussed again). I found this not only misleading, but I would have also liked the paper to go deeper into the respective topics, at least to some extent.",ARR_2022_215_review,ARR_2022,"1. The paper raises two hypotheses in lines 078-086 about multilinguality and country/language-specific bias. While I don't think the hypotheses are phrased optimally (could they be tested as given?), their underlying ideas are valuable. However, the paper actually does not really study these hypotheses (nor are they even mentioned/discussed again). I found this not only misleading, but I would have also liked the paper to go deeper into the respective topics, at least to some extent. 2. It seemed a little disappointing to me that the 212 new pairs have _not_ been translated to English (if I'm not mistaken). To really make this dataset a bilingual resource, it would be good to have all pairs in both languages. In the given way, it seems that ultimately only the French version was of interest to the study - unlike it is claimed initially.
3. Almost no information about the reliability of the translations and the annotations is given (except for the result of the translation checking in line 285), which seems unsatisfying to me. To assess the translations, more information about the language/translation expertise of the authors would be helpful (I don't think this violates anonymity). For the annotations, I would expect some measure of inter-annotator agreement.
4. The metrics in Tables 4 and 5 need explanation, in order to make the paper self-contained. Without going to the original paper on CrowS-pairs, the values are barely understandable. Also, information on the values ranges should be given as well as whether higher or lower values are better.
- 066: social contexts >> I find this term misleading here, since the text seems to be about countries/language regions.
- 121: Deviding 1508 into 16*90 = 1440 cases cannot be fully correct. What about the remaining 68 cases?
- 241: It would also be good to state the maximum number of tasks done by any annotator.
- Table 3: Right-align the numeric columns.
- Table 4 (1): Always use the same number of decimal places, for example 61.90 instead of 61.9 to match the other values. This would increase readability. - Table 4 (2): The table exceeds the page width; that needs to be fixed.
- Tables 4+5 (1): While I undersand the layout problem, the different approaches would be much easier to compare if tables and columns were flipped (usually, one approach per row, one metric per column). - Tables 4+5 (2): What's the idea of showing the run-time? I didn't see for what this is helpful.
- 305/310: Marie/Mary >> I think these should be written the same.
- 357: The text speaks of ""53"", but I believe the value ""52.9"" from Table 4 is meant. In my view, such rounding makes understanding harder rather than helping.
- 575/577: ""1/"" and ""2/"" >> Maybe better use ""(1)"" and ""(2)""; confused me first.","['2', '4', '4', '3', '5', '3', '3', '4']",4.0,gold,2,"['4', '5', '5', '5', '5', '5', '5', '5']",5.0,gold,"['1', '5', '5', '5', '5', '5', '5', '4']",5,gold,"['2', '5', '5', '4', '5', '5', '5', '4']",5.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '1', '0', '0', '0', '0', '0']",0.0,gold,3,"the comment identifies a significant issue with the paper: the initial hypotheses are not followed through, which could potentially mislead readers. it also mentions that these hypotheses are valuable and suggests that the paper could benefit from a deeper exploration of these topics. however, the feedback lacks specific guidance on how the authors might address this issue or restructure their paper to better integrate or test the hypotheses. while the authors can gain some insights from this comment, it does not fully address how they might improve their draft in practice."
"- Small contributions over previous methods (NCNet [6] and Sparse NCNet [21]). Mostly (good) engineering. And despite that it seems hard to differentiate it from its predecessors, as it performs very similarly in practice.",NIPS_2020_1454,NIPS_2020,"- Small contributions over previous methods (NCNet [6] and Sparse NCNet [21]). Mostly (good) engineering. And despite that it seems hard to differentiate it from its predecessors, as it performs very similarly in practice. - Claims to be SOTA on three datasets, but this does not seem to be the case. Does not evaluate on what it trains on (see ""additional feedback"").","['1', '1', '1', '1']",1.0,gold,3,"['4', '2', '1', '5']",,,"['2', '5', '5', '5']",5,gold,"['2', '2', '1', '2']",2.0,gold,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,3,"the comment identifies a weakness in the draft by pointing out that the contributions over previous methods are small and primarily engineering-based. however, the feedback is somewhat vague and lacks depth, providing minimal guidance on how the authors might address this issue. it alerts the authors to a potential perception problem, but does not offer specific or actionable suggestions to improve the distinctiveness or significance of their contributions. therefore, it is somewhat helpful but not sufficiently detailed or constructive to earn a higher score."
1.It seems that the method part is very similar to the related work cited in the paper: Generating Adversarial Disturbances for Controller Verification. Could the author provide more clarification on this?,ICLR_2023_1979,ICLR_2023,"Weakness: 1.It seems that the method part is very similar to the related work cited in the paper: Generating Adversarial Disturbances for Controller Verification. Could the author provide more clarification on this? 2.Experimental comparison to RRT* seems not good: Even though the RRT* baseline is an oracle without partial observability, the visible region is still very large, which covers more than half of the obstacles. In this case, the naive RRT* (as mentioned in supp C1) can still outperform the proposed method by a large margin on the first task.","['3', '3', '2', '4']",3.0,silver,3,"['5', '4', '2', '4']",4.0,silver,"['2', '5', '3', '1']",,,"['2', '3', '2', '3']",2.0,silver,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,3,"the comment identifies a potential issue in the manuscript, specifically the similarity between the method section and previous related work. however, it lacks detailed guidance on how the authors could address this concern or improve their section. the request for clarification is valid and may lead to useful insights, but the feedback is somewhat incomplete and lacks depth. more specific suggestions or examples for differentiation or elaboration could enhance its helpfulness."
"3. Insufficient ablation study on \alpha. \alpha is only set to 1e-4, 1e-1, 5e-1 in section 5.4 with a large gap between 1e-4 and 1e-1. The author is recommended to provide more values of \alpha, at least 1e-2 and 1e-3.",ICLR_2023_2396,ICLR_2023,"1. Lack of the explanation about the importance and the necessity to design deep GNN models . In this paper, the author tries to address the issue of over-smoothing and build deeper GNN models. However, there is no explanation about why should we build a deep GNN model. For CNN, it could be built for thousands of layers with significant improvement of the performance. While for GNN, the performance decreases with the increase of the depth (shown in Figure 1). Since the deeper GNN model does not show the significant improvement and consumes more computational resource, the reviewer wonders the explanation of the importance and the necessity to design deep models. 2. The experimental results are not significantly improved compared with GRAND. For example, GRAND++-l on Cora with T=128 in Table 1, on Computers with T=16,32 in Table 2. Since the author claims that GRAND suffers from the over-smoothing issue while DeepGRAND significantly mitigates such issue, how to explain the differences between the theoretical and practical results, why GRAND performs better when T is larger? Besides, in Table 3, DeepGRAND could not achieve the best performance with 1/2 labeled on Citeseer, Pubmed, Computers and CoauthorCS dataset, which could not support the argument that DeepGRAND is more resilient under limited labeled training data. 3. Insufficient ablation study on \alpha. \alpha is only set to 1e-4, 1e-1, 5e-1 in section 5.4 with a large gap between 1e-4 and 1e-1. The author is recommended to provide more values of \alpha, at least 1e-2 and 1e-3. 4. Minor issues. The x label of Figure 2, Depth (T) rather than Time (T).","['5', '5', '5']",5.0,gold,4,"['5', '5', '5']",5.0,gold,"['5', '3', 'X']",,,"['5', '4', '5']",5.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the comment is mostly helpful as it clearly identifies a specific weakness in the experimental setup regarding the range of values tested for \alpha in the ablation study. it provides actionable feedback by recommending additional values of \alpha (1e-2 and 1e-3), which can help the authors enhance the robustness and comprehensiveness of their analysis. however, the comment could be improved by explaining why the suggested values would be valuable or by providing additional context or guidance on conducting a more thorough ablation study. thus, while it is clear and actionable, it could be more comprehensive in its guidance."
"2. A minor point would be that few-shot would be a more realistic setup for that task, as domain-specific TODOs are easy to acquire, however I agree that the current setup is adequate as well.",ARR_2022_89_review,ARR_2022,"1. The experiments are held on a private datasets and the exact setup is impossible to reproduce.
2. A minor point would be that few-shot would be a more realistic setup for that task, as domain-specific TODOs are easy to acquire, however I agree that the current setup is adequate as well.
3. More error analysis could be useful, especially on the public dataset, as their data could be included without any restrictions, e.g., error types/examples? patterns? Examples when non-contextualized embeddings outperform contextualized ones, or even LITE?
I urge the authors to release at least some part of the dataset to the wider public, or under some end user-agreement.
Comments: 1. I suggest the authors to focus their comparison on word2vec baselines (currently in appendix), instead of Sentence-BERT, as the latter does not show good performance on the short texts. It seems that non-contextualized embeddings are more suitable for the task.
2. Maybe it makes more sense to try out models pre-trained on conversations, e.g., text from Twitter or natural language conversations.","['3', '5', '4']",,,1,"['3', '5', '2']",,,"['5', '5', '3']",5,silver,"['5', '5', '2']",5.0,silver,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,3,"the comment provides an observation on the task's setup in the paper, suggesting that a few-shot setup might be more realistic. however, it acknowledges that the current setup is still adequate, which somewhat dilutes the emphasis on the suggested improvement. while the comment identifies a potential improvement area, it lacks depth and elaborate guidance, making it somewhat helpful but not comprehensive in empowering the authors to make significant changes."
"2. Line 148: I think it would make sense to make a distinction between hard prompt work updates the frozen model (Schick and Schütez, etc) from ones that don't.",ARR_2022_223_review,ARR_2022,"The majority of the weaknesses in the paper seem to stem from confusion and inconsistencies between some of the prose and the results.
1. Figure 2, as it is, isn't totally convincing there is a gap in convergence times. The x-axis of the graph is time, when it would have been more convincing using steps. Without an efficient, factored attention for prompting implementation a la [He et al. (2022)](https://arxiv.org/abs/2110.04366) prompt tuning can cause slow downs from the increased sequence length. With time on the x-axis it is unclear if prompt tuning requires more steps or if each step just takes more time. Similarly, this work uses $0.001$ for the learning rate. This is a lot smaller than the suggested learning rate of $0.3$ in [Lester et al (2021)](https://aclanthology.org/2021.emnlp-main.243/), it would have been better to see if a larger learning rate would have closed this gap. Finally, this gap with finetuning is used as a motivating examples but the faster convergence times of things like their initialization strategy is never compared to finetuning.
2. Confusion around output space and label extraction. In the prose (and Appendix A.3) it is stated that labels are based on the predictions at `[MASK]` for RoBERTa Models and the T5 Decoder for generation. Scores in the paper, for example the random vector baseline for T5 in Table 2 suggest that the output space is restricted to only valid labels as a random vector of T5 generally produces nothing. Using this rank classification approach should be stated plainly as direct prompt reuse is unlikely to work for actual T5 generation.
3. The `laptop` and `restaurant` datasets don't seem to match their descriptions in the appendix. It is stated that they have 3 labels but their random vector performance is about 20% suggesting they actually have 5 labels?
4. Some relative performance numbers in Figure 3 are really surprising, things like $1$ for `MRPC` to `resturant` transfer seem far too low, `laptop` source to `laptop` target on T5 doesn't get 100, Are there errors in the figure or is where something going wrong with the datasets or implementation?
5. Prompt similarities are evaluated based on correlation with zero-shot performance for direct prompt transfer. Given that very few direct prompt transfers yield gain in performance, what is actually important when it comes to prompt transferability is how well the prompt works as an initialization and does that boost performance. Prompt similarity tracking zero-shot performance will be a good metric if that is in turn correlated with transfer performance. The numbers from Table 1 generally support that this as a good proxy method as 76% of datasets show small improvements when using the best zero-shot performing prompt as initialization when using T5 (although only 54% of datasets show improvement for RoBERTa). However Table 2 suggests that this zero-shot performance isn't well correlated with transfer performance. In only 38% of datasets does the best zero-shot prompt match the best prompt to use for transfer (And of these 5 successes 3 of them are based on using MNLI, a dataset well known for giving strong transfer results [(Phang et al., 2017)](https://arxiv.org/abs/1811.01088)). Given that zero-shot performance doesn't seem to be correlated with transfer performance (and that zero-shot transfer is relatively easy to compute) it seems like _ON_'s strong correlation would not be very useful in practice.
6. While recent enough that it is totally fair to call [Vu et al., (2021)](https://arxiv.org/abs/2110.07904) concurrent work, given the similarity of several approaches there should be a deeper discussion comparing the two works. Both the prompt transfer via initialization and the prompt similarity as a proxy for transferability are present in that work. Given the numerous differences (Vu et al transfer mostly focuses on large mixtures transferring to tasks and performance while this work focuses on task to task transfer with an eye towards speed. _ ON_ as an improvement over the Cosine similarities which are also present in Vu et al) it seems this section should be expanded considering how much overlap there is.
7. The majority of Model transfer results seem difficult to leverage. Compared to cross-task transfer, the gains are minimal and the convergence speed ups are small. Coupled with the extra time it takes to train the projector for _Task Tuning_ (which back propagation with the target model) it seems hard to imagine situations where this method is worth doing (that knowledge is useful). Similarly, the claim on line 109 that model transfer can significantly accelerate prompt tuning seems lie an over-claim.
8. Line 118 claims `embedding distances of prompts do not well indicate prompt transferability` but Table 4 shows that C$_{\text{average}}$ is not far behind _ON_. This claim seems over-reaching and should instead be something like ""our novel method of measuring prompt similarity via model activations is better correlated with transfer performance than embedding distance based measures""
1. Line 038: They state that GPT-3 showed extremely large LM can give remarkable improvements. I think it would be correct to have one of their later citations on continually developed LM as the one that showed that. GPT-3 mostly showed promise for Few-Shot evaluation, not that it get really good performance on downstream tasks.
2. Line 148: I think it would make sense to make a distinction between hard prompt work updates the frozen model (Schick and Schütez, etc) from ones that don't.
3. Line 153: I think it makes sense to include [_Learning How to Ask: Querying LMs with Mixtures of Soft Prompts_ (Qin and Eisner, 2021)](https://aclanthology.org/2021.naacl-main.410.pdf) in the citation list for work on soft prompts.
4. Figure 3: The coloring of the PI group makes the text very hard to read in Black and White.
5. Table 1: Including the fact that the prompt used for initialization is the one that performed best in direct transfer in the caption as well as the prose would make the table more self contained.
6. Table 2: Mentioning that the prompt used as cross model initialization is from _Task Tuning_ in the caption would make the table more self contained.
7. Line 512: It is mentioned that _ON_ has a drop when applied to T$5_{\text{XXL}}$ and it is suggested this has to do with redundancy as the models grow. I think this section could be improved by highlighting that the Cosine based metrics have a similar drop (suggesting this is a fact of the model rather than the fault of the _ON_ method). Similarly, Figure 4 shows the dropping correlation as the model grows. Pointing out the that the _ON_ correlation for RoBERTA$_{\text{large}}$ would fit the tend of correlation vs model size (being between T5 Base and T5 Large) also strengths the argument but showing it isn't an artifact of _ON_ working poorly on encoder-decoder models. I think this section should also be reordered to show that this drop is correlated with model size. Then the section can be ended with hypothesizing and limited exploration of model redundancy.
8. Figure 6. It would have been interesting to see how the unified label space worked for T5 rather than RoBERTAa as the generative nature of T5's decoding is probably more vulnerable to issue stemming from different labels.
9. _ ON_ could be pushed farther. An advantage of prompt tuning is that the prompt is transformed by the models attention based on the value of the prompt. Without having an input to the model, the prompts activations are most likely dissimilar to the kind of activations one would expect when actually using the prompt.
10. Line 074: This sentence is confusing. Perhaps something like ""Thus"" over ""Hence only""?
11. Line 165: Remove ""remedy,""","['5', '5', '5', '4']",5.0,gold,3,"['5', '5', '5', '5']",5.0,gold,"['5', '4', '1', '2']",,,"['5', '4', '4', '4']",4.0,gold,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the review comment is mostly helpful as it identifies a specific area for improvement in the draft, namely the need to distinguish between different types of prompt work in the literature. the suggested distinction could enhance clarity and understanding for the reader. however, the comment could be expanded to provide more detailed guidance on how to make this distinction or why it is particularly important in the context of the paper. such additional information would move the comment closer to being highly helpful."
"3)It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)-smoothness condition. It seems one can directly apply standard analysis on the (L0,L1)-smoothness condition. So it is better to explain the challenges, especially the difference between this one and Zhang et al.",ICLR_2023_3705,ICLR_2023,"1)The main assumption is borrowed from other works but is actually rarely used in the optimization field. Moreover, the benefits of this assumption is not well investigated. For example, a) why it is more reasonable than the previous one? B) why it can add gradient norm L_1 \nabla f(w_1) in Eqn (3) or why we do not add other term? It should be mentioned that a milder condition does not mean it is better, since it may not reflect the truth. For me, problem B) is especially important in this work, since the authors do not well explain and investigate it.
2)Results in Theorem 1 show that Adam actually does not converge, since this is a constant term O(D_0^{0.5}\delta) in Eqn. (5). This is not intuitive, the authors claim it is because the learning rate may not diminish. But many previous works, e.g. [ref 1], can prove Adam-type algorithms can converge even using a constant learning rate. Of course, they use the standard smooth condition. But (L0,L1)-smoothness condition should not cause this kind of convergence, since for nonconvex problem, in most cases, we only need the learning rate to be small but does not care whether it diminishes to zero.
[ref 1] Dongruo Zhou, Jinghui Chen, et al. On the Convergence of Adaptive Gradient Methods for Nonconvex Optimization
3)It is not clear what are the challenges when the authors analyze Adam under the (L0,L1)-smoothness condition. It seems one can directly apply standard analysis on the (L0,L1)-smoothness condition. So it is better to explain the challenges, especially the difference between this one and Zhang et al.
4)Under the same assumption, the authors use examples to show the advantage of Adam over GD and SGD. This is good. But one issue is that is the example reasonable or does it share similar properties with practical problems, especially for networks. This is important since both SGD and ADAM are widely used in the deep learning field.
5)In the work, when comparing SGD and ADAM, the authors explain the advantage of adam comes from the cases when the local smoothness varies drastically across the domain. It is not very clear for me why Adam could better handle this case. Maybe one intuitive example could help.
6)The most important problem is that this work does not provide new insights, since it is well known that the second order moment could help the convergence of Adam. This work does not provide any insights beyond this point and also does not give any practical solution to further improve.","['5', '5', '5']",5.0,gold,4,"['5', '5', '3']",5.0,silver,"['5', '5', 'X']",5,silver,"['5', '5', '4']",5.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '1']",0.0,silver,3,"the review point highlights a potential weakness in the authors' explanation regarding the challenges with the (l0,l1)-smoothness condition. it suggests that the authors need to explain these challenges more clearly, especially in comparison to zhang et al. however, the feedback is somewhat vague, as it does not provide specific guidance on what aspects are unclear or how the comparison should be articulated. therefore, while it offers a direction for improvement, it does not fully address the authors' needs for enhancing their draft. more detailed suggestions or examples could improve the helpfulness of this review point."
- All the linear convergence rates rely on Theorem 8 which is burried at the end of the appendix and which proof is not clear enough.,NIPS_2017_74,NIPS_2017,"- Theorem 2 which presentation is problematic and does not really provide any convergence guaranty.
- All the linear convergence rates rely on Theorem 8 which is burried at the end of the appendix and which proof is not clear enough.
- Lower bounds on the number of good steps of each algorithm which are not really proved since they rely on an argument of the type ""it works the same as in another close setting"".
The numerical experiments are numerous and convincing, but I think that the authors should provide empirical evidences showing that the computational cost are of the same order of magnitude compared competing methods for the experiments they carried out.
%%%% Details on the main comments
%% Theorem 2
The presention and statement of Theorem 2 (and all the sublinear rates given in the paper) has the following form:
- Given a fixed horizon T
- Consider rho, a bound on the iterates x_0 ... x_T
- Then for all t > 0 the suboptimality is of the order of c / t where c depends on rho.
First, the proof cannot hold for all t > 0 but only for 0 < t <= T. Indeed, in the proof, equation (16) relies on the fact that the rho bound holds for x_t which is only ensured for t < = T.
Second the numerator actually contains rho^2. When T increases, rho could increase as well and the given bound does not even need to approach 0.
This presentation is problematic. One possible way to fix this would be to provide a priori conditions (such as coercivity) which ensure that the sequence of iterates remain in a compact set, allowing to define an upper bound independantly of the horizon T.
In the proof I did not understand the sentence ""The reason being that f is convex, therefore, for t > 0 we have f (x t ) < = f (0).""
%% Lemma 7 and Theorem 8
I could not understand Lemma 7.
The equation is given without any comment and I cannot understand its meaning without further explaination. Is this equation defining K'? Or is it the case that K' can be chosen to satisfy this equation? Does it have any other meaning?
Lemma 7 deals only with g-faces which are polytopes. Is it always the case? What happens if K is not a polytope? Can this be done without loss of generality? Is it just a typo?
Theorem 8:
The presentation is problematic. In Lemma 7, r is not a feasible direction. In Theorem 8, it is the gradient of f at x_t. Theorem 8 says ""using the notation from Lemma 7"". The proof of Theorem 8 says ""if r is a feasible direction"". All this makes the work of the reader very hard.
Notations of Lemma 7 are not properly used:
- What is e? e is not fixed by Lemma 7, it is just a variable defining a maximum. This is a recurent mistake in the proofs.
- What is K? K is supposed to be given in Lemma 7 but not in Theorem 8.
- Polytope?
All this could be more explicit.
""As x is not optimal by convexity we have that < r , e > > 0"". Where is it assumed that $x$ is not optimal? How does this translate in the proposed inequality?
What does the following mean?
""We then project r on the faces of cone(A) containing x until it is a feasible direction""
Do the author project on an intersection of faces or alternatively on each face or something else?
It would be more appropriate to say ""the projection is a feasible direction"" since r is fixed to be the gradient of f. It is very uncomfortable to have the value of r changing within the proof in an ""algorithmic fashion"" and makes it very hard to check accuracy of the arguments.
In any case, I suspect that the resulting r could be 0 in which case the next equation does not make sense. What prevents the resulting r from being null?
In the next sentences, the authors use Lemma 7 which assumes that r is not a feasible direction. This is contradictory with the preceeding paragraph. At this point I was completely confused and lost hope to understand the details of this proof.
What is r' on line 723 and in the preceeding equation?
I understand that there is a kind of recursive process in the proof. Why should the last sentence be true?
%% Further comments
Line 220, max should be argmax
I did not really understand the non-negative matrix facotrization experiment. Since the resulting approximation is of rank 10, does it mean that the authors ran their algorithm for 10 steps only?","['1', '3', '2']",,,4,"['2', '4', '5']",,,"['1', '1', '3']",1,silver,"['1', '3', '4']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,3,"the comment points out a critical issue regarding the organization of the theorem necessary for understanding the convergence rates, which is helpful for the authors. however, it lacks specific guidance on how to clarify the proof or suggestions for relocating the theorem for better access, making it somewhat helpful but not fully actionable."
- 241: It would also be good to state the maximum number of tasks done by any annotator.,ARR_2022_215_review,ARR_2022,"1. The paper raises two hypotheses in lines 078-086 about multilinguality and country/language-specific bias. While I don't think the hypotheses are phrased optimally (could they be tested as given?), their underlying ideas are valuable. However, the paper actually does not really study these hypotheses (nor are they even mentioned/discussed again). I found this not only misleading, but I would have also liked the paper to go deeper into the respective topics, at least to some extent. 2. It seemed a little disappointing to me that the 212 new pairs have _not_ been translated to English (if I'm not mistaken). To really make this dataset a bilingual resource, it would be good to have all pairs in both languages. In the given way, it seems that ultimately only the French version was of interest to the study - unlike it is claimed initially.
3. Almost no information about the reliability of the translations and the annotations is given (except for the result of the translation checking in line 285), which seems unsatisfying to me. To assess the translations, more information about the language/translation expertise of the authors would be helpful (I don't think this violates anonymity). For the annotations, I would expect some measure of inter-annotator agreement.
4. The metrics in Tables 4 and 5 need explanation, in order to make the paper self-contained. Without going to the original paper on CrowS-pairs, the values are barely understandable. Also, information on the values ranges should be given as well as whether higher or lower values are better.
- 066: social contexts >> I find this term misleading here, since the text seems to be about countries/language regions.
- 121: Deviding 1508 into 16*90 = 1440 cases cannot be fully correct. What about the remaining 68 cases?
- 241: It would also be good to state the maximum number of tasks done by any annotator.
- Table 3: Right-align the numeric columns.
- Table 4 (1): Always use the same number of decimal places, for example 61.90 instead of 61.9 to match the other values. This would increase readability. - Table 4 (2): The table exceeds the page width; that needs to be fixed.
- Tables 4+5 (1): While I undersand the layout problem, the different approaches would be much easier to compare if tables and columns were flipped (usually, one approach per row, one metric per column). - Tables 4+5 (2): What's the idea of showing the run-time? I didn't see for what this is helpful.
- 305/310: Marie/Mary >> I think these should be written the same.
- 357: The text speaks of ""53"", but I believe the value ""52.9"" from Table 4 is meant. In my view, such rounding makes understanding harder rather than helping.
- 575/577: ""1/"" and ""2/"" >> Maybe better use ""(1)"" and ""(2)""; confused me first.","['5', '4', '5', '5', '5', '3', '4', '5']",5.0,gold,2,"['5', '5', '5', '5', '5', '4', '2', '5']",5.0,gold,"['1', '5', '4', 'X', '5', '2', '3', '1']",1,silver,"['5', '5', '5', '5', '5', '2', '4', '2']",5.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0', '0', '0', '0']",0.0,gold,3,"the comment suggests an improvement by recommending the inclusion of information about the maximum number of tasks done by any annotator, which could provide valuable context and clarity. however, the comment lacks depth and does not explain why this information would be beneficial or how it could impact the study's findings or the draft's quality. the authors can infer an area for improvement, but the feedback does not provide detailed guidance or fully address the implications of the suggestion."
"1) there is a drop of correlation after a short period of training, which goes up with more training iterations;",NIPS_2022_1770,NIPS_2022,"Weakness: There are still several concerns with the finding that the perplexity is highly correlated with the number of decoder parameters.
According to Figure 4, the correlation decreases as top-10% architectures are chosen instead of top-100%, which indicates that the training-free proxy is less accurate for parameter-heavy decoders.
The range of sampled architectures should also affect the correlation. For instance, once the sampled architectures are of similar sizes, it could be more challenging to differentiate their perplexity and thus the correlation can be lower.
Detailed Comments:
Some questions regarding Figure 4: 1) there is a drop of correlation after a short period of training, which goes up with more training iterations; 2) the title ""Top-x%"" should be further explained;
Though the proposed approach yields the Pareto frontier of perplexity, latency and memory, is there any systematic way to choose a single architecture given the target perplexity?","['1', '1', '1']",1.0,gold,4,"['3', '4', '1']",,,"['3', 'X', 'X']",X,silver,"['1', '1', '1']",1.0,gold,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,2,"the review point identifies an issue related to the drop and rise in correlation with training iterations, but it is vague and lacks specific details or suggestions. it does not provide actionable feedback on how to address the observed pattern, leaving the authors with minimal guidance. to be more helpful, the comment could include potential causes, the impact on the study, or suggestions for experiment adjustments."
- This pipeline style method including two models does not give better average results for both XVNLI and MaRVL. Baseline models in the experiments are not well introduced.,4kuLaebvKx,EMNLP_2023,"- The chained impacts of image captioning and multilingual understanding model in the proposed pipeline. If the Image caption gives worse results and the final results could be worse. So The basic performance of the image caption model and multilingual language mode depends on the engineering model choice when it applies to zero-shot.
- This pipeline style method including two models does not give better average results for both XVNLI and MaRVL. Baseline models in the experiments are not well introduced.","['1', '3', '3', '2']",3.0,silver,3,"['3', '4', '5', '4']",4.0,silver,"['1', '2', 'X', '1']",1,silver,"['1', '3', '3', '3']",3.0,gold,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,3,"the review point identifies a specific weakness in the manuscript by pointing out that the pipeline style method does not yield better average results for both xvnli and marvl, and that baseline models are not well introduced. while this feedback helps the authors understand an area needing improvement, it lacks detailed suggestions on how to address these issues or improve their methodology and experiment descriptions. more specific guidance and depth would enhance its utility."
"2 More analysis and comments are recommended on the performance trending of increasing the number of parameters for ViT (DeiT) in the Figure 3. I disagree with authors' viewpoint that ""Both CNNs and ViTs seem to benefit similarly from increased model capacity"". In the Figure 3, the DeiT-B models does not outperform DeiT-T in APTOS2019, and it does not outperform DeiT-S on APTOS2019, ISIC2019 and CheXpert (0.1% won't be significant). However, CNNs can give more almost consistent model improvements as the capacity goes up except on the ISIC2019.",ICLR_2022_1794,ICLR_2022,"1 Medical imaging are often obtained in 3D volumes, not only limited to 2D images. So experiments should include the 3D volume data as well for the general community, rather than all on 2D images. And the lesion detection is another important task for the medical community, which has not been studied in this work.
2 More analysis and comments are recommended on the performance trending of increasing the number of parameters for ViT (DeiT) in the Figure 3. I disagree with authors' viewpoint that ""Both CNNs and ViTs seem to benefit similarly from increased model capacity"". In the Figure 3, the DeiT-B models does not outperform DeiT-T in APTOS2019, and it does not outperform DeiT-S on APTOS2019, ISIC2019 and CheXpert (0.1% won't be significant). However, CNNs can give more almost consistent model improvements as the capacity goes up except on the ISIC2019.
3 On the segmentation mask involved with cancer on CSAW-S, the segmentation results of DEEPLAB3-DEIT-S cannot be concluded as better than DEEPLAB3-RESNET50. The implication that ViTs outperform CNNs in this segmentation task cannot be validly drawn from an 0.2% difference with larger variance.
Questions: 1 For the grid search of learning rate, is it done on the validation set?
Minor problems: 1 The n number for Camelyon dataset in Table 1 is not consistent with the descriptions in the text in Page 4.","['5', '5', '2', '5']",5.0,gold,3,"['5', '5', '5', '5']",5.0,gold,"['5', '5', '5', '5']",5,gold,"['5', '5', '2', '5']",5.0,gold,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,5,"the review comment is highly helpful as it thoroughly identifies a specific weakness in the analysis of the performance trend related to the number of parameters in vit models. the reviewer clearly disagrees with the authors' interpretation of results and provides detailed observations from figure 3, where they describe the lack of significant improvement in deit models with increased parameters in certain datasets. moreover, the reviewer contrasts this with cnns' performance, offering constructive critique and a basis for deeper analysis. this empowers the authors to revisit their analysis and consider the nuanced differences in model capacity trends, providing a significant opportunity for improving their draft."
"- ""semantic"" segmentation is not low-level since the categories are specified for each pixel so the statements about semantic segmentation being a low-level cue should be removed from the paper.",NIPS_2018_25,NIPS_2018,"- My understanding is that R,t and K (the extrinsic and intrinsic parameters of the camera) are provided to the model at test time for the re-projection layer. Correct me in the rebuttal if I am wrong. If that is the case, the model will be very limited and it cannot be applied to general settings. If that is not the case and these parameters are learned, what is the loss function? - Another issue of the paper is that the disentangling is done manually. For example, the semantic segmentation network is the first module in the pipeline. Why is that? Why not something else? It would be interesting if the paper did not have this type of manual disentangling, and everything was learned. - ""semantic"" segmentation is not low-level since the categories are specified for each pixel so the statements about semantic segmentation being a low-level cue should be removed from the paper. - During evaluation at test time, how is the 3D alignment between the prediction and the groundtruth found? - Please comment on why the performance of GTSeeNet is lower than that of SeeNetFuse and ThinkNetFuse. The expectation is that groundtruth 2D segmentation should improve the results. - line 180: Why not using the same amount of samples for SUNCG-D and SUNCG-RGBD? - What does NoSeeNet mean? Does it mean D=1 in line 96? - I cannot parse lines 113-114. Please clarify.","['5', '5', '5', '5']",5.0,gold,3,"['5', '3', '5', '3']",5.0,silver,"['4', '4', '4', '5']",4,gold,"['4', '5', '3', '5']",5.0,silver,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the review point is mostly helpful as it clearly identifies a specific issue in the paper related to the incorrect classification of 'semantic segmentation' as a low-level task. the comment provides clear guidance by suggesting that statements regarding semantic segmentation as a low-level cue should be removed. however, the comment could be more comprehensive by explaining why this misclassification is critical, or by suggesting a more accurate characterization of semantic segmentation. this additional context would further help the authors understand and improve their draft."
- The experiments are limited to toy data. There is a range of problems with real data where barycenters can be used and it would be interesting to show performance of the method in those settings too.,NIPS_2020_83,NIPS_2020,"While I think the paper makes a good contribution, there are some limitation at the present stage: - [Remark 3.1] While it has been done in previous works, I think that a deeper understanding of those cases where modelling the pushforward P in (8) as a composition of perturbation in an RKHS does not introduce an error, would increase the quality of the work. Alternatively, trying to undestand the kind of error that this parametrization introduces would be valuable too. - The analysis does not cover explicitly what happens when the input measures \beta_i are absolutely continuous and one has to rely on samples. How does the sampling part impact the bound? - The experiments are limited to toy data. There is a range of problems with real data where barycenters can be used and it would be interesting to show performance of the method in those settings too.","['4', '5', '1']",,,4,"['2', '4', '3']",,,"['3', '3', '4']",3,silver,"['3', '3', '3']",3.0,gold,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the review point highlights a significant limitation in the experiments by pointing out their reliance on toy data, and suggests exploring real-data scenarios to better demonstrate the method's applicability. this feedback is clear and actionable, as it guides the authors to broaden their scope for more comprehensive validation. however, it lacks specific examples or detailed guidance on which real data problems to consider, preventing it from being a 5. overall, the comment is mostly helpful in enhancing the paper's contribution and relevance."
"- This paper investigates the issue of robustness in video action recognition, but it lacks comparison with test-time adaptation (TTA) methods, such as [A-B]. These TTA methods also aim to adapt to out-of-distribution data when the input data is disturbed by noise. Although these TTA methods mainly focus on updating model parameters, and this paper primarily focuses on adjusting the input data, how to prove that data processing is superior to model parameter adjustment? I believe a comparison should be made based on experimental results.",eI6ajU2esa,ICLR_2024,"- This paper investigates the issue of robustness in video action recognition, but it lacks comparison with test-time adaptation (TTA) methods, such as [A-B]. These TTA methods also aim to adapt to out-of-distribution data when the input data is disturbed by noise. Although these TTA methods mainly focus on updating model parameters, and this paper primarily focuses on adjusting the input data, how to prove that data processing is superior to model parameter adjustment? I believe a comparison should be made based on experimental results.
- Under noisy conditions, many TTA methods can achieve desirable results, while the improvement brought by this paper's method is relatively low.
- In appendix A.2.1, under noisy conditions, the average performance improvement brought by this paper's method is very low and can even be counterproductive under certain noise conditions. Does this indicate an issue with the approach of changing input data?
- How to verify the reliability of the long-range photometric consistency in section 3.3? Are there any ablation study results reflecting the performance gain brought by each part?
- The explanation of the formula content in Algorithm 1 in the main body is not clear enough.
[A] Temporal Coherent Test-Time Optimization for Robust Video Classification. ICLR23
[B] Video Test-Time Adaptation for Action Recognition. CVPR23","['5', '5', '5', '5']",5.0,gold,3,"['5', '5', '4', '5']",5.0,gold,"['5', '5', '5', 'X']",5,gold,"['5', '5', '4', '4']",5.0,silver,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the comment addresses a notable weakness in the paper by pointing out the lack of comparison with test-time adaptation (tta) methods, which are relevant to the topic being investigated. it provides a clear suggestion for improvement by recommending a comparison to establish how the proposed data processing method stands relative to model parameter adjustment methods. this feedback is actionable, as it guides the authors to include experimental comparisons. however, the comment could be more comprehensive by suggesting specific metrics or scenarios for the comparison or by elaborating on the potential implications of the comparison results. therefore, the review is mostly helpful but not entirely exhaustive or detailed."
- Table 4: Caption should make it clear these are F1 scores as well as clarifying how the F1 score is weighted (e.g. micro/macro). This should also be made clear in the “evaluation metrics” section on page 6.,ACL_2017_727_review,ACL_2017,"Quantitative results are given only for the author's PSL model and not compared against any traditional baseline classification algorithms, making it unclear to what degree their model is necessary. Poor comparison with alternative approaches makes it difficult to know what to take away from the paper.
The qualitative investigation is interesting, but the chosen visualizations are difficult to make sense of and add little to the discussion. Perhaps it would make sense to collapse across individual politicians to create a clearer visual.
- General Discussion: The submission is well written and covers a topic which may be of interest to the ACL community. At the same time, it lacks proper quantitative baselines for comparison. Minor comments: - line 82: A year should be provided for the Boydstun et al. citation - It’s unclear to me why similar behavior (time of tweeting) should necessarily be indicative of similar framing and no citation was given to support this assumption in the model.
- The related work goes over quite a number of areas, but glosses over the work most clearly related (e.g. PSL models and political discourse work) while spending too much time mentioning work that is only tangential (e.g. unsupervised models using Twitter data).
- Section 4.2 it is unclear whether Word2Vec was trained on their dataset or if they used pre-trained embeddings.
- The authors give no intuition behind why unigrams are used to predict frames, while bigrams/trigrams are used to predict party.
- The authors note that temporal similarity worked best with one hour chunks, but make no mention of how important this assumption is to their results. If the authors are unable to provide full results for this work, it would still be worthwhile to give the reader a sense of what performance would look like if the time window were widened.
- Table 4: Caption should make it clear these are F1 scores as well as clarifying how the F1 score is weighted (e.g. micro/macro). This should also be made clear in the “evaluation metrics” section on page 6.","['3', '5', '5']",5.0,silver,1,"['3', '5', '5']",5.0,silver,"['X', '5', 'X']",X,silver,"['2', '4', '5']",,,"['1', '1', '1']",1.0,gold,"['1', '1', '0']",1.0,silver,5,"the review point is highly helpful as it clearly identifies a specific area for improvement (clarification of f1 scores in table 4's caption and the evaluation metrics section). it provides detailed, actionable suggestions on what needs to be clarified, empowering the authors to significantly enhance the clarity and interpretability of their results, thus addressing a meaningful aspect of their document."
"2.It is better for authors to display the performance of accelerating SGMs by involving some other baselines with a different perspective, such as “optimizing the discretization schedule or by modifying the original SGM formulation” [16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45]",NIPS_2022_1807,NIPS_2022,"Weakness:
1.The authors should provide more descriptions of the wavelet transforms in this paper. It is hard for me to understand the major idea in this paper before learning some necessary knowledge about wavelet whitening, wavelet coefficient, and so on.
2.It is better for authors to display the performance of accelerating SGMs by involving some other baselines with a different perspective, such as “optimizing the discretization schedule or by modifying the original SGM formulation” [16, 15, 23, 46, 36, 31, 37, 20, 10, 25, 35, 45]","['5', '3', '5']",5.0,silver,4,"['5', '3', '3']",3.0,silver,"['5', '5', '1']",5,silver,"['5', '4', '4']",4.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the review point is mostly helpful because it clearly suggests incorporating additional baselines that involve different perspectives, specifically mentioning 'optimizing the discretization schedule' or 'modifying the original sgm formulation'. it also provides references for the authors to explore further. however, it could be more comprehensive by suggesting specific examples or further elaborating on how these perspectives could be demonstrated, leading to an even more actionable feedback for the authors."
"3: To further backup the proposed visual reference resolution model works in real dataset, please also conduct ablation study on visDial dataset. One experiment I'm really interested is the performance of ATT(+H) (in figure 4 left). What is the result if the proposed model didn't consider the relevant attention retrieval from the attention memory.",NIPS_2017_356,NIPS_2017,"]
My major concerns about this paper is the experiment on visual dialog dataset. The authors only show the proposed model's performance on discriminative setting without any ablation studies. There is not enough experiment result to show how the proposed model works on the real dataset. If possible, please answer my following questions in the rebuttal.
1: The authors claim their model can achieve superior performance having significantly fewer parameters than baseline [1]. This is mainly achieved by using a much smaller word embedding size and LSTM size. To me, it could be authors in [1] just test model with standard parameter setting. To backup this claim, is there any improvements when the proposed model use larger word embedding, and LSTM parameters?
2: There are two test settings in visual dialog, while the Table 1 only shows the result on discriminative setting. It's known that discriminative setting can not apply on real applications, what is the result on generative setting?
3: To further backup the proposed visual reference resolution model works in real dataset, please also conduct ablation study on visDial dataset. One experiment I'm really interested is the performance of ATT(+H) (in figure 4 left). What is the result if the proposed model didn't consider the relevant attention retrieval from the attention memory.","['5', '5', '5', '5']",5.0,gold,3,"['5', '5', '5', '5']",5.0,gold,"['5', 'X', 'X', 'X']",X,gold,"['5', '4', '5', '5']",5.0,gold,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the comment is mostly helpful as it provides clear and actionable feedback by suggesting that the authors conduct an ablation study on the visdial dataset to further validate their model. it specifically points out an area of interest (the performance of att(+h) in figure 4) and questions the impact of the proposed model not considering attention retrieval, which can guide the authors to conduct additional experiments. however, it could be more comprehensive by elaborating on why this experiment is important or how it could improve the paper, thus not reaching the highest level of helpfulness."
"4. The promised dataset has not yet been made publicly available, so a cautious approach should be taken regarding this contribution until the dataset is openly accessible.",OvoRkDRLVr,ICLR_2024,"1. The paper proposes a multimodal framework built atop a frozen Large Language Model (LLM) aimed at seamlessly integrating and managing various modalities. However, this approach seems to be merely an extension of the existing InstructBLIP.
2. Additionally, the concept of extending to multiple modalities, such as the integration of audio and 3D modalities, has already been proposed in prior works like PandaGPT. Therefore, the paper appears to lack sufficient novelty in both concept and methodology.
3. In Table 1, there is a noticeable drop in performance for X-InstructBLIP. Could you please clarify the reason behind this? If this drop is due to competition among different modalities, do you propose any solutions to mitigate this issue?
4. The promised dataset has not yet been made publicly available, so a cautious approach should be taken regarding this contribution until the dataset is openly accessible.","['1', '2', '5', '1']",1.0,silver,3,"['1', '3', '5', '3']",3.0,silver,"['X', '3', 'X', 'X']",X,gold,"['2', '3', '4', '1']",,,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,3,"the comment identifies a significant issue regarding the availability of the dataset, which is an important aspect of the contribution. however, it lacks depth or specific guidance on how the authors can address this issue or what steps they might take to make the dataset available. while it provides some insight into a crucial part of the draft, it does not fully empower the authors to take specific actions to ameliorate the problem."
"1) While the authors' methods allow for learning a state-action-dependent weighting of the shaping rewards, it seemed to me possible that in all of the experiments presented, learning a *uniform* state-action-independent weighting would have sufficed. Moreover, since learning a state-action-independent weighting is much simpler (i.e. it is a single scalar), it may even outperform the authors' methods for the current experiments. Based on this, I would like to suggest the following: 1a) Could the authors provide visualizations of the state-action variation of their learnt weightings? They plot the average weight in some cases (Fig 1 and",NIPS_2020_1335,NIPS_2020,"Given how strong the first four sections (five pages) of the paper were, I was relatively disappointed in the experiments, which were somewhat light. Specifically: 1) While the authors' methods allow for learning a state-action-dependent weighting of the shaping rewards, it seemed to me possible that in all of the experiments presented, learning a *uniform* state-action-independent weighting would have sufficed. Moreover, since learning a state-action-independent weighting is much simpler (i.e. it is a single scalar), it may even outperform the authors' methods for the current experiments. Based on this, I would like to suggest the following: 1a) Could the authors provide visualizations of the state-action variation of their learnt weightings? They plot the average weight in some cases (Fig 1 and 3), but given Cartpole has such a small state-action space, it should be possible to visualize the variation. The specific question here is: do the weights vary much at all in these cases? 1b) Could the authors include a baseline of learnt state-action-*independent* weights? In other words, this model has a single parameter, replacing z_phi(s,a) with a single scalar z. This should be pretty easy to implement. The authors could take any (or all) of their existing gradient approximators and simply average them across all (s,a) in a batch to get the gradient w.r.t. z. 1c) Could the authors include an additional experiment that specifically benefits from learning state-action-*dependent* (so non-uniform) weights? Here is a simple example for Cartpole: the shaping reward f(s,a) is helpful for half the state space and unhelpful for the other half. The ""halves"" could be whether the pole orientation is in the left or right half. The helpful reward could be that from Section 5.1 while the unhelpful reward could be that from the first adaptability test in Section 5.3. 2) To me, the true power of the author's approach is not in learning to ignore bad rewards (just turn them off!) but to intelligently incorporate sort-of-useful-but-not-perfect rewards. This way a researcher can quickly hand design an ok shaping reward but then let the authors' method transform it into a good one. Thus, I was surprised the experiments focussed primarily on ignoring obviously bad rewards and upweighting obviously good rewards. In particular, the MuJoCo experiments would be more compelling if they included more than just a single unhelpful shaping reward. I think the authors could really demonstrate the usefulness of their method there by doing the following: hand design a roughly ok shaping reward for each task. For example, the torso velocity or head height off the ground for Humanoid-v2. Then apply the authors' method and show that it outperforms naive use of this shaping reward. 3) Although the authors discussed learning a shaping reward *from scratch* in the related work section, I was surprised that they did not included this as a baseline. One would like to see that their method, when provided with a decent shaping reward to start, can learn faster by leveraging this hand-crafted knowledge. Fortunately, it seems to me again very easy to implement a baseline like this within the author's framework: simply set f(s,a)=1 and use the authors' methods (perhaps also initializing z_phi(s,a)=0).","['5', '5']",5.0,silver,4,"['5', '5']",5.0,silver,"['5', '4']",,,"['5', '4']",,,"['1', '1']",1.0,silver,"['1', '0']",,,4,"the comment is mostly helpful because it identifies a potential weakness in the authors' methods, specifically questioning whether a simpler, uniform state-action-independent weighting could suffice for their experiments. it provides actionable feedback by suggesting that the authors provide visualizations of the state-action variation of their learnt weightings. however, the review stops mid-sentence, which slightly limits its comprehensiveness and does not provide a complete explanation or detailed guidance. despite this, the authors can gain valuable insights into how to enhance their analysis and explanation of their method's effectiveness."
"4. The model AUC can assess the model discriminant ability, i.e., the probability of a positive case is bigger than that of a negative case, but may be hard to show its consistency between predicted score and actual risk. However, this consistency may be more crucial to the clinical scoring system (differentiated with classification task). Therefore, the related studies are encouraged to conduct calibration curves to show the agreement. It would be better to prove the feasibility of the generated scoring system? The difference between the traditional method and our method can also be discussed in this paper.",NIPS_2022_1637,NIPS_2022,"1. The examples of scoring systems in the Introduction seem out of date, there are many newer and recognized clinical scoring systems. It also should briefly introduce the traditional framework of the scoring system and its difference in methodology and performance with the proposed method. 2. As shown in figure 3, the performance improvement of proposed methods seems not so significant, the biggest improvement in the bank dataset was ~0.02. Additionally, using some tables to directly show the key improvements may be more intuitive and detailed. 3. Although extensive experiments and discussion on performance, in my opinion, its most significant improvement would be efficiency, and there are few discussions or ablation experiments on efficiency. 4. The model AUC can assess the model discriminant ability, i.e., the probability of a positive case is bigger than that of a negative case, but may be hard to show its consistency between predicted score and actual risk. However, this consistency may be more crucial to the clinical scoring system (differentiated with classification task). Therefore, the related studies are encouraged to conduct calibration curves to show the agreement. It would be better to prove the feasibility of the generated scoring system? The difference between the traditional method and our method can also be discussed in this paper.","['5', '5', '4']",5.0,silver,4,"['5', '5', '3']",5.0,silver,"['5', '3', '5']",5,silver,"['5', '3', '4']",,,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the review point is mostly helpful because it identifies potential weaknesses in the draft related to the model's auc and its implications on clinical scoring systems. it provides guidance on conducting calibration curves to address these concerns and suggests areas for discussion such as comparing the traditional method with the proposed one. however, the feedback could be expanded with more detailed suggestions on how to improve these sections, making it not fully comprehensive, but still providing clear and actionable insights for the authors."
"- The authors may want to generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. Thus, this raises my concern about LLMs' ability to model problems with large instance sizes.",fsDZwS49uY,ICLR_2025,"- The authors may want to generate instances with more constraints and variables, as few instances in the paper have more than 7 variables. Thus, this raises my concern about LLMs' ability to model problems with large instance sizes.
- Given that a single optimization problem can have multiple valid formulations, it would be beneficial for the authors to verify the accuracy and equivalence of these formulations with ground-truth ones.
- There are questions regarding the solving efficiency of the generated codes. It would be valuable to assess whether the code produced by LLMs can outperform human-designed formulations and codes.","['3', '5', '5']",5.0,silver,4,"['2', '5', '3']",,,"['3', 'X', '5']",,,"['3', '5', '4']",,,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the comment identifies a potential weakness in the paper regarding the scarcity of instances with a high number of variables, which may affect the study's analysis of large-scale problems. however, the suggestion to generate instances with more constraints and variables lacks specificity and depth. while it highlights a possible limitation, it does not provide detailed guidance on how the authors might address this issue or how it impacts the overall conclusions of the paper. therefore, it offers some insight but does not fully empower the authors to make comprehensive improvements."
"- Disentanglement. It is not clear how disentanglement is guaranteed. Although ""Broader Impacts and Limitations"" stated that ""Obtaining fully disentangled latent vectors ... a limitation"", it is still important to highlight how the disentanglement is realized and guaranteed without certain bias types.",NIPS_2021_37,NIPS_2021,", * Typos/Comments)
Overall, I like and value the research topic and motivation of this paper and lean positive. However, some details are not clear enough. I would update my rating depending on the authors' feedback. The details are as follows.
+ Interesting and important research problem. This paper focuses on how to obtain disentangle representations for feature-level augmentation. This topic is interesting and important, and will attract many interests of the NeurIPS community.
+ Good quality of writing and organization. Overall, the writing quality is good and the paper is well organized. It is comfortable to read this paper, although some details are not clear.
+ Comprehensive experiments. Experiments are conducted on two synthetic datasets Colored MNIST and Corrupted CIFAR-10) and two real-world datasets (BAR and Biased FFHQ).
- Relative difficulty score and generalized cross-entropy (GCE) loss. It is not clear how the relative difficulty score W ( x )
in Eq. (1) is used in the pipeline. W(x) is not mentioned again in both the overall objective functions Eq. (2) or Algorithm 1. Since readers may not be familiar with the generalized cross-entropy (GCE) loss, it is encouraged to briefly introduce the formulation and key points of the GCE loss to make this paper more self-contained.
- How bias-conflicting samples and bias-aligned samples are selected. This weakness follows the first one. It seems that the ""bias-conflicting"" is determined based on the relative difficulty score, but the details are missed. Also, the ablation study on how the ""bias-conflicting"" is determined, e.g., setting the threshold for the relative difficulty score, is encouraged to be considered and included.
- Disentanglement. It is not clear how disentanglement is guaranteed. Although ""Broader Impacts and Limitations"" stated that ""Obtaining fully disentangled latent vectors ... a limitation"", it is still important to highlight how the disentanglement is realized and guaranteed without certain bias types.
- Inference stage. It is not clear how the inference is conducted during testing. Which encoders/decoders are preserved during the test stage?
- Figure 1 is not clear. First, it seems that the two y towards L CE
are the outputs of C i
, but they are illustrated like labels rather than predictions. Second, the illustration of the re-weighting module is not clear. Does it represent Eq. (4)?
- Table 4 reported a much lower performance of ""swapping"" on BAR compared to the other three datasets. Is there any explanation for this, like the difference of datasets?
- Sensitivity to hyperparameters. The proposed framework consists of three important hyperparameters, ( λ dis , λ s w a p b , λ swap )
. It is not clear whether the framework is sensitive to these hyperparameters and how these hyperparameters are determined.
* (Suggestion) Illustration of backpropagation. As introduced in Line 167-168, the loss from C i
is not backpropagated to E b
. It would be clearer if this can be added in Figure 1.
* Line 280. Is ""the first row and column ... respectively"" a typo? It is a little confusing for me to understand this.
* Typos in Algorithm 1. Are λ dis and λ s w a p b
missed in L dis and L swap ?
* Typo in Line 209. Corrputed -> Corrupted.
============================= After rebuttal ===================================
After reading the authors' response to my questions and concerns, I would like to vote for acceptance.
The major strengths of this paper are:
The research problem, unbiased classification via learning debiased representation, is interesting and would attract the NeurIPS audience's attention.
The proposed method is simple but effective. The method is built on top of LfF [12] and further considers (1) intrinsic and bias feature disentanglement and (2) data augmentation by swapping the bias features among training samples.
The paper is clearly written and well organized.
These strengths and contributions are also pointed out by other colleague reviewers.
My main concerns were:
Unclear technical details of the GCE loss and the relative difficulty score. This concern was also shared with Reviewer 8Ai1 and iKKw. The authors' response clearly introduced the details and addressed my concern well.
Sensitivity to hyper-parameters. The authors' response provided adequate results to show the sensitivity to hyper-parameters. Other details of implementation and analysis of experimental results. The authors' responses clearly answered my questions.
Considering both strengths and the weakness, I am happy to accept this paper.
The authors have adequately addressed the limitations and potential negative societal impact of their work.","['3', '5', '3', '5']",3.0,silver,3,"['3', '5', '4', '5']",5.0,silver,"['4', '4', 'X', '3']",4,silver,"['4', '4', '3', '4']",4.0,gold,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the comment is mostly helpful as it identifies a specific weakness in the manuscript related to an unclear explanation of disentanglement and its guarantee. it stresses the need for clarification on how disentanglement is achieved and safeguarded against bias. while it provides clear guidance on what needs to be addressed, it does not offer detailed suggestions on how the authors might approach this improvement. expanding the comment with examples or potential approaches could improve its comprehensiveness and make it fully impactful."
"1) First of all, to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, it should be used standard regularization trick.",kklwv4c4dI,ICLR_2024,"Table 1 presents the previous and current results strangely:
1) First of all, to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, it should be used standard regularization trick.
2) From my point of you, when complexity contains several terms, each of them should be added.
About Table 2, The authors claim that ""The sequential version of FeDualEx leads to the stochastic dual extrapolation for CO and yields, to our knowledge, the first convergence rate for the stochastic optimization of composite SPP in non-Euclidean settings ."" It is not true, there is a wide field related to operator splitting in deterministic and stochastic cases. Look at this paper please https://epubs.siam.org/doi/epdf/10.1137/20M1381678.
Also, compared to the previous works, the authors use bounded stochastic gradient assumption and homogeneity of data. In many federated learning papers, those assumptions are avoided. Despite that the authors write ""Assumption e is a standard assumption"", it would be better to provide analysis without it to have more generality.
In Theorem 1, and Theorem 2, the final result contains mistakes in complexity, because some of them were done in the proof.
The first mistake is made in theorem 3 and repeats in the main theorem. Please look at the last inequality on page 40:
To make $3\eta^2\beta^2 -1 \leq 0$, the stepsize should be chosen in the following way: $\eta \leq \frac{1}{\sqrt{3}\beta}$. This will change the complexity of the methods. The same was done in the proof of Theorems 1, and 2. Please see Lemma 3, 17.
The second mistake is made in the proof of Lemma 13, in the last two inequalities, where should be $\dots\sqrt{2V^l_z(\cdot)} \leq \dots \sqrt{B}$. This thing also will change the final complexity.
The appendix is hard to read in terms of the order of Lemmas. I think it would be better if the numeration of Lemmas had a strict order (for example, after Lemma 5 lemma 6 follows.)
Other things dealing with weaknesses, please, see in questions.","['2', '5', '4', '3']",,,3,"['2', '3', '4', '3']",3.0,silver,"['2', '3', '3', '1']",3,silver,"['2', '3', '4', '2']",2.0,silver,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,2,"the review point identifies a potential area for improvement - comparing the obtained complexity with previous results. however, it is vague and lacks specific guidance on how the 'standard regularization trick' should be applied. the comment does not provide sufficient detail or actionable steps for the authors to follow, making it only slightly beneficial. expanding on the specific regularization techniques and their implications could improve its usefulness."
"1. The work uses only binary features. Real world data is usually a mix of binary, real and categorical features. It is not clear if the method is applicable to real and categorical features too.",NIPS_2019_653,NIPS_2019,"of the method. Clarity: The paper has been written in a manner that is straightforward to read and follow. Significance: There are two factors which dent the significance of this work. 1. The work uses only binary features. Real world data is usually a mix of binary, real and categorical features. It is not clear if the method is applicable to real and categorical features too. 2. The method does not seem to be scalable, unless a distributed version of it is developed. It's not reasonable to expect a single instance can hold all the training data that the real world datasets ususally contain.","['1', '4', '2']",,,4,"['3', '5', '2']",,,"['3', 'X', '4']",,,"['2', '5', '4']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,3,"the comment identifies a potential weakness in the work by highlighting that it only uses binary features, which may not be representative of real-world data. however, it lacks specific suggestions or guidance on how the authors might address this issue or test their method with real and categorical features. while the authors can gain insight into an area of concern, the feedback is somewhat lacking in depth and detail, making it only somewhat helpful for improving the draft."
"- For effectiveness, the performance comparison in Table 1 is unfair. VINS sets different sample weights W u i in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1.",ICLR_2022_1923,ICLR_2022,"Weakness: 1. The novelty of this paper is limited. First, the analysis of the vertex-level imbalance problem is not new, which is a reformulation of the observations in previous works [Rendle and Freudenthaler, 2014; Ding et al., 2019]. Second, the designed negative sampler uses reject sampling to increase the chance of popular items, which is similar to the proposed one in PRIS [Lian et al., 2020]. 2. The paper overclaims on its ability of debiasing sampling. The “debiased” term in the paper title is confusing. 3. The methodology detail is unclear in Sec. 4.2. The proposed design that improves sampling efficiency seems interesting but the corresponding description is hard to follow given the limited space. 4. Space complexity of the proposed VINS should also be analyzed and compared in empirical studies, given that each (u, i) corresponds to a b u f f e r u i
. 5. Experiment results are not convincing enough to demonstrate the superiority of VINS on effectiveness and efficiency. - For effectiveness, the performance comparison in Table 1 is unfair. VINS sets different sample weights W u i
in the training process, while most compared baselines like DNS, AOBPR, SA, PRIS set all sample weights as 1. - For efficiency, Table 2 should also include the theoretical analysis for contrast.","['1', '4', '2']",,,4,"['4', '5', '4']",4.0,silver,"['2', '5', '5']",5,silver,"['2', '5', '4']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,3,"the comment is somewhat helpful as it identifies a potential issue with the fairness of the performance comparison in table 1 by noting the difference in sample weight handling. however, the feedback lacks depth and does not offer specific suggestions for how the authors might address this issue, such as recommending adjustments to the comparison methodology or including additional information to ensure fair comparisons. therefore, while the authors gain insight into a possible weakness, they are left without detailed guidance on how to resolve it, making the feedback incomplete."
2. Missing link to similar work on Continuous Conditional Random Fields [Ristovski 2013] and Continuous Conditional Neural Fields [Baltrusaitis 2014] that has a similar structure of the CRF and ability to perform exact inference.,NIPS_2019_220,NIPS_2019,"1. Unclear experimental methodology. The paper states that 300W-LP is used to train the model, but later it is claimed same procedure is used as was used for baselines. Most baselines do not use 300W-LP dataset in their training. Is 300W-LP used in all experiments or just some? If it is used in all this would provide an unfair advantage to the proposed method. 2. Missing link to similar work on Continuous Conditional Random Fields [Ristovski 2013] and Continuous Conditional Neural Fields [Baltrusaitis 2014] that has a similar structure of the CRF and ability to perform exact inference. 3. What is Gaussian NLL? This seems to come out of nowhere and is not mentioned anywhere in the paper, besides the ablation study? Trivia: Consider replacing ""difference mean"" with ""expected difference"" between two landmarks (I believe it would be clearer)","['2', '5', '5', '5']",5.0,gold,3,"['3', '3', '5', '5']",3.0,silver,"['1', '5', '5', 'X']",5,silver,"['2', '5', '5', '4']",5.0,silver,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,4,"the review point is mostly helpful as it identifies a specific weakness in the draft regarding the missing links to similar work. it points out relevant references, which guides the authors to consider additional literature that is pertinent to their work. this comment provides actionable feedback by suggesting specific studies to incorporate or compare, thereby aiding the authors in improving the context and depth of their research. however, the comment could be more comprehensive by explaining how these references specifically relate to the authors' work or suggesting how the authors might integrate or address these studies in their draft."
- the required implicit call to the Witness oracle is confusing.,NIPS_2018_914,NIPS_2018,"of the paper are (i) the presentation of the proposed methodology to overcome that effect and (ii) the limitations of the proposed methods for large-scale problems, which is precisely when function approximation is required the most. While the intuition behind the two proposed algorithms is clear (to keep track of partitions of the parameter space that are consistent in successive applications of the Bellman operator), I think the authors could have formulated their idea in a more clear way, for example, using tools from Constraint Satisfaction Problems (CSPs) literature. I have the following concerns regarding both algorithms: - the authors leverage the complexity of checking on the Witness oracle, which is ""polynomial time"" in the tabular case. This feels like not addressing the problem in a direct way. - the required implicit call to the Witness oracle is confusing. - what happens if the policy class is not realizable? I guess the algorithm converges to an \empty partition, but that is not the optimal policy. minor: line 100 : ""a2 always moves from s1 to s4 deterministically"" is not true line 333 : ""A number of important direction"" -> ""A number of important directions"" line 215 : ""implict"" -> ""implicit"" - It is hard to understand the figure where all methods are compared. I suggest to move the figure to the appendix and keep a figure with less curves. - I suggest to change the name of partition function to partition value. [I am satisfied with the rebuttal and I have increased my score after the discussion]","['1', '1', '1', '2']",1.0,gold,3,"['3', '2', '5', '2']",2.0,silver,"['1', '1', '1', '1']",1,gold,"['1', '1', '3', '1']",1.0,gold,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,2,"the review point identifies an issue with the draft by stating that the 'required implicit call to the witness oracle is confusing,' which could help authors recognize an area that needs clarification. however, the comment lacks clarity and specific guidance on how to address the confusion, providing only minimal benefit to the authors. more detailed suggestions or examples on how to clarify the call would make the feedback more actionable."
"- I would assume that the performance is closely related to the number of scenarios used for training, and therefore, it is interesting to examine the performance with different numbers of scenarios (which is fixed as 200 in the paper).",ICLR_2022_497,ICLR_2022,"I have the following questions to which I wish the author could respond in the rebuttal. If I missed something in the paper, I would appreciate it if the authors could point them out.
Main concerns: - In my understanding, the best scenarios are those generated from the true distribution P (over the scenarios), and therefore, the CVAE essentially attempts to approximate the true distribution P. In such a sense, if the true distribution P is independent of the context (which is the case in the experiments in this paper), I do not see the rationale for having the scenarios conditioned on the context, which in theory does not provide any statistical evidence. Therefore, the rationale behind CVAE-SIP is not clear to me. If the goal is not to approximate P but to solve the optimization problem, then having the objective values involved as a predicting goal is reasonable; in this case, having the context involved is justified because they can have an impact on the optimization results. Thus, CVAE-SIPA to me is a valid method. - While reducing the scenarios from 200 to 10 is promising, the quality of optimization has decreased a little bit. On the other hand, in Figure 2, using K-medoids with K=20 can perfectly recover the original value, which suggests that K-medoids is a decent solution and complex learning methods are not necessary for the considered settings. In addition, I am also wondering the performance under the setting that the 200 scenarios (or random scenarios of a certain number from the true distributions) are directly used as the input of CPLEX. In addition, to justify the performance, it is necessary to provide information about robustness as well as to identify the case where simple methods are not satisfactory (such as larger graphs).
Minor concerns: - Given the structure of the proposed CVAE, the generation process takes the input of z and c where z
is derived from w
. This suggests that the proposed method requires us to know a collection of scenarios from the true distribution. If this is the case, it would be better to have a clear problem statement in Sec 3. Based on such understanding, I am wondering about the process of generating scenarios used for getting K representatives - it would be great if codes like Alg 1 was provided. - I would assume that the performance is closely related to the number of scenarios used for training, and therefore, it is interesting to examine the performance with different numbers of scenarios (which is fixed as 200 in the paper). - The structure of the encoder is not clear to me. The notation q_{\phi} is used to denote two different functions q(z w,D) and q ( c , D )
. Does that mean they are the same network? - It would be better to experimentally justify the choice of the dimension of c and z. - It looks to me that the proposed methods are designed for graph-based problems, while two-stage integer programming does not have to be graph problems in general. If this is the case, it would be better to clearly indicate the scope of the considered problem. Before reaching Sec 4.2, I was thinking that the paper could address general settings. - The paper introduces CVAE-SIP and CVAE-SIPA in Sec 5 -- after discussing the training methods, so I am wondering if they follow the same training scheme. In particular, it is not clear to me by saying “append objective values to the representations” at the beginning of Sec 5. - The approximation error is defined as the gap between the objective values, which is somehow ambiguous unless one has seen the values in the table. It would be better to provide a mathematical characterization.","['4', '5', '5']",5.0,silver,4,"['3', '5', '3']",3.0,silver,"['2', 'X', '4']",,,"['3', '4', '5']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,4,"the comment is mostly helpful as it suggests a specific area of investigation that might affect the performance—examining the performance with different numbers of scenarios. this provides the authors clear guidance on a possible way to enrich their study. however, it could be improved by offering additional details or suggestions on how to explore this aspect or why specifically it might be important, which would make it even more comprehensive and actionable."
"4. Section 3.2.1: The first expression for J ( θ ) is incorrect, which should be Q ( s t 0 , π θ ( s t 0 ) ) .",ICLR_2021_863,ICLR_2021,"Weakness 1. The presentation of the paper should be improved. Right now all the model details are placed in the appendix. This can cause confusion for readers reading the main text. 2. The necessity of using techniques includes Distributional RL and Deep Sets should be explained more thoroughly. From this paper, the illustration of Distributional RL lacks clarity. 3. The details of state representation are not explained clear. For an end-to-end method like DRL, it is crucial for state representation for training a good agent, as for network architecture. 4. The experiments are not comprehensive for validating that this algorithm works well in a wide range of scenarios. The efficiency, especially the time efficiency of the proposed algorithm, is not shown. Moreover, other DRL benchmarks, e.g., TD3 and DQN, should also be compared with. 5. There are typos and grammar errors.
Detailed Comments 1. Section 3.1, first paragraph, quotation mark error for ""importance"". 2. Appendix A.2 does not illustrate the state space representation of the environment clearly. 3. The authors should state clearly as to why the complete state history is enough to reduce POMDP for the no-CSI case. 4. Section 3.2.1: The first expression for J ( θ )
is incorrect, which should be Q ( s t 0 , π θ ( s t 0 ) )
. 5. The paper did not explain Figure 2 clearly. In particular, what does the curve with the label ""Expected"" in Fig. 2(a) stand for? Not to mention there are multiple misleading curves in Fig. 2(b)&(c). The benefit of introducing distributional RL is not clearly explained. 6. In Table 1, only 4 classes of users are considered in the experiment sections, which might not be in accordance with practical situations, where there can be more classes of users in the real system and more user numbers. 7. In the experiment sections, the paper only showed the Satisfaction Probability of the proposed method is larger than conventional methods. The algorithm complexity, especially the time complexity of the proposed method in an ultra multi-user scenario, is not shown. 8. There is a large literature on wireless scheduling with latency guarantees from the networking community, e.g., Sigcomm, INFOCOM, Sigmetrics. Representative results there should also be discussed and compared with.
====== post rebuttal: My concern regarding the experiments remains. I will keep my score unchanged.","['5', '5', '5', '5']",5.0,gold,3,"['5', '5', '5', '5']",5.0,gold,"['5', '5', 'X', 'X']",5,silver,"['5', '5', '5', '4']",5.0,gold,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,3,"the comment identifies a specific mistake in the expression for j(θ) and suggests the correct formulation q(sₜ₀, πθ(sₜ₀)). this provides the authors with a clear directive on what needs to be corrected. however, it lacks additional context or explanation that might help the authors understand why this change is necessary, preventing it from being rated higher. the comment is somewhat helpful because it guides correction but does not fully explore the issue or provide deeper insights that might aid in substantial improvements."
"4 - For sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption. This limitations prevents the use of even single deep neural networks on homomorphically encrypted data.",ICLR_2023_2057,ICLR_2023,"1 - The main idea of using ensemble of neural networks is trivial and very common in machine learning literature. The paper doesn't provide any specific adaptation to the homomorphic encryption domain. 2 - The discussion on the homomorphic encryption schemes is completely missing. What type of HE do you use? 3 - How do you preform majority voting in the encrypted domain? Most of HE schemes do not support argmax operation. 4 - For sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption. This limitations prevents the use of even single deep neural networks on homomorphically encrypted data.","['2', '3', '1', '5']",,,3,"['3', '3', '2', '3']",3.0,gold,"['2', '4', '1', '5']",,,"['2', '4', '1', '4']",4.0,silver,"['1', '1', '1', '0']",1.0,gold,"['1', '0', '0', '1']",1.0,silver,3,"the comment identifies a relevant area for improvement by highlighting the limitations of sequential ensembling due to noise accumulation in the context of homomorphic encryption. however, it lacks depth in specifying how the authors might address this issue or explore it further, and does not provide detailed, actionable suggestions. therefore, while the feedback is relevant and provides some insight, it does not fully equip the authors to make significant improvements, warranting a score of 3."
"- line 126: by the black *line* in the input # Further Questions - Would it make sense to include and learn AccNet as part of a larger predictor, e.g., for semantic segmentation, that make use of similar operators?",NIPS_2018_134,NIPS_2018,"- Some parts of the work are harder to follow and it helps to have checked [Cohen and Shashua, 2016] for background information. # Typos and Presentation - The citation of Kraehenbuehl and Koltun: it seems that the first and last name of the first author, i.e. Philipp, are swapped. - The paper seems to be using a different citation style than the rest of the NIPS submission. Is this intended? - line 111: it might make sense to not call g activation function, but rather a binary operator; similar to Cohen and Shashua, 2016. They do introduce the activation-pooling operator though that fulfils the required conditions. - line 111: I believe that the weight w_i is missing in the sum. - line 114: Why not mention that the operator has to be associative and commutative? - eq 6 and related equations: I believe that the operator after w_i should be the multiplication of the underlying vector space and not \cross_g: It is an operator between a scalar and a tensor, and not just between two scalars. - line 126: by the black *line* in the input # Further Questions - Would it make sense to include and learn AccNet as part of a larger predictor, e.g., for semantic segmentation, that make use of similar operators? - Do you plan to publish their implementation of the proposed AccNet? # Conclusion The work shows that the proposed method is expressive enough to approximate high-dimensional filtering operations while being fast. I think the paper makes an interesting contribution and I would like to see this work being published.","['5', '4', '5']",5.0,silver,4,"['5', '5', '5']",5.0,gold,"['5', 'X', 'X']",X,silver,"['4', '5', '4']",4.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the review comment highlights a potential area for improvement by suggesting the integration of accnet into a larger predictor for semantic segmentation. however, it lacks detailed guidance or any concrete examples on how to achieve this integration. while it does open up a new possibility for the authors to consider, it doesn't provide sufficient specifics to fully aid them in improving their draft. hence, it's somewhat helpful but not comprehensive enough to be more valuable."
"- The authors mainly seem to focus on SSC, and do not contrast their method with several other subsequent methods (thresholded subspace clustering (TSC), greedy subspace clustering by Park, etc) which are all computationally efficient as well as come with similar guarantees.",NIPS_2017_645,NIPS_2017,"- The main paper is dense. This is despite the commendable efforts by the authors to make their contributions as readable as possible. I believe it is due to NIPS page limit restrictions; the same set of ideas presented at their natural length would make for a more easily digestible paper.
- The authors do not quite discuss computational aspects in detail (other than a short discussion in the appendix), but it is unclear whether their proposed methods can be made practically useful for high dimensions. As stated, their algorithm requires solving several LPs in high dimensions, each involving a parameter that is not easily calculable. This is reflected in the authorsâ experiments which are all performed on very small scale datasets.
- The authors mainly seem to focus on SSC, and do not contrast their method with several other subsequent methods (thresholded subspace clustering (TSC), greedy subspace clustering by Park, etc) which are all computationally efficient as well as come with similar guarantees.","['4', '4', '4', '1']",4.0,gold,3,"['3', '5', '4', '3']",3.0,silver,"['4', '4', '4', 'X']",4,gold,"['4', '4', '4', '2']",4.0,gold,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the comment is mostly helpful as it clearly identifies a weakness in the paper—the lack of comparison with other efficient subspace clustering methods. it specifies which methods the authors should consider comparing their work against, namely thresholded subspace clustering (tsc) and greedy subspace clustering by park. this feedback is actionable because it provides the authors with specific methods to include in their evaluation, helping them strengthen their study's validity and comprehensiveness. however, the comment could be more comprehensive by suggesting how to implement these comparisons or elaborating on the expected outcome or impact of such comparisons."
1: Poor writing and annotations are a little hard to follow.,NIPS_2018_245,NIPS_2018,"Weakness] 1: Poor writing and annotations are a little hard to follow. 2: Although applying GCN on FVQA is interesting, the technical novelty of this paper is limited. 3: The motivation is to solve when the question doesn't focus on the most obvious visual concept when there are synonyms and homographs. However, from the experiment, it's hard to see whether this specific problem is solved or not. Although the number is better than the previous method, it will be great if the authors could product more experiments to show more about the question/motivation raised in the introduction. 4: Following 3, applying MLP after GCN is very common, and I'm not surprised that the performance will drop without MLP. The authors should show more ablation studies on performance when varying the number of facts retrieval, what happened if we different number of layer of GCN?","['1', '2', '1']",1.0,silver,4,"['1', '1', '1']",1.0,gold,"['X', '1', '1']",1,silver,"['1', '2', '1']",1.0,silver,"['0', '1', '1']",1.0,silver,"['1', '0', '0']",0.0,silver,2,"the comment identifies a weakness in writing and annotations being hard to follow, but it is vague and lacks clarity. it does not provide specific examples or guidance on how the authors can improve these areas, making the feedback only slightly beneficial for them."
"- Some questionable design choices. Perplexity is used as a measure of the model retaining semantic information after fine-tuning, and while that does relate to the original task, there are also aspects of domain drift which are possible and separate from catastrophic forgetting. How are such factors controlled?",KE5QunlXcr,EMNLP_2023,"- The PLMs used (BERT) are by current standards, quite old, and quite small. As work in scaling PLMs up to sizes orders of magnitude greater, performance on syntactic tasks has shown to improve naturally (along with many other useful emergent forms of knowledge). Some comparison to larger models / application of this method to such models, is necessary to ensure that the method has any practical purpose.
- There are also no baselines from existing work. There are other forms of fine-tuning, such as adapters, which seek to add additional knowledge to PLMs with less chance of catastrophic forgetting. The authors even cite one of these papers. This is also a confusing oversight, because the many appropriate inline citations which contrast various decisions in this work to decisions in existing work demonstrate a great familiarity with the literation, so lacking any comparison to any existing methods is an odd oversight.
- Some questionable design choices. Perplexity is used as a measure of the model retaining semantic information after fine-tuning, and while that does relate to the original task, there are also aspects of domain drift which are possible and separate from catastrophic forgetting. How are such factors controlled?
- Related, there is questionable motivation. Often when talking about catastrophic forgetting, both the original training and the new task are both relevant. This is clear in the context of robotics, where learning a new behavior should not result in hindering the robot from performing existing behaviors. Is this true in this case? PPL is almost always not a valuable end goal, and the entire PLM/LLM paradigm is built around this notion of pre-training in whatever way leads to learning useful linguistic representations, before fine-tuning, aligning, or few-shotting the model towards the task the user actually cares about. If users never care about both tasks in approximately equal measure, than what good is retaining the original model weights which were not pertinent to the target task?
- There's arguably too much going on here. The focus of the paper aims to be about catastrophic forgetting, but secondary to that, is also the problem of matching the right syntactic fine-tuning task to the right problem. This is not entirely known a priori, so all possible pairings are explored, but realistically a good guess can be made (as it would likely be if pursued in a more practical setting). For instance, it is no surprise that the phrase syntax task helps with key phrase identification. The disadvantage of the exhaustive approach is that it has both distracted from the main takeaway points while cutting into the space available for supporting the main hypothesis.
- No inclusion of baselines from existing work / SOTA on performance tables
- Key extraction F1 results are better than standard optimizers, but negligibly so.
- No discussion of GC vs EWC. When a priori would you choose which method? If the paper included only one such method, traditional optimizers would be the best choice in most situations.","['4', '5', '3']",,,4,"['3', '3', '3']",3.0,gold,"['4', 'X', 'X']",X,silver,"['2', '5', '3']",,,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the comment identifies a specific issue with the design choices related to using perplexity as a measure, which may not adequately address domain drift separate from catastrophic forgetting. it prompts the authors to consider how these factors are controlled, providing clear and actionable feedback. however, it could be more comprehensive by suggesting specific methods or approaches to address this concern, making it mostly helpful rather than highly helpful."
"- ""While higher scores might be achieved with MT systems that explicitly address rare words, these systems don't focus on sentiment words"": it's true, but I was wondering whether sentiment words are rare in the corpus. If they are, those MT systems should obviously handle them (in addition to other rare words).",ACL_2017_96_review,ACL_2017,"lack statistics of the datsets (e.g. average length, vocabulary size) the baseline (Moses) is not proper because of the small size of the dataset the assumption ""sarcastic tweets often differ from their non sarcastic interpretations in as little as one sentiment word"" is not supported by the data. - General Discussion: This discussion gives more details about the weaknesses of the paper. Half of the paper is about the new dataset for sarcasm interpretation.
However, the paper doesn't show important information about the dataset such as average length, vocabulary size. More importantly, the paper doesn't show any statistical evidence to support their method of focusing on sentimental words. Because the dataset is small (only 3000 tweets), I guess that many words are rare. Therefore, Moses alone is not a proper baseline. A proper baseline should be a MT system that can handle rare words very well. In fact, using clustering and declustering (as in Sarcasm SIGN) is a way to handle rare words.
Sarcasm SIGN is built based on the assumption that ""sarcastic tweets often differ from their non sarcastic interpretations in as little as one sentiment word"". Table 1 however strongly disagrees with this assumption: the human interpretations are often different from the tweets at not only sentimental words. I thus strongly suggest the authors to give statistical evidence from the dataset that supports their assumption. Otherwise, the whole idea of Sarcasm SIGN is just a hack.
-------------------------------------------------------------- I have read the authors' response. I don't change my decision because of the following reasons: - the authors wrote that ""the Fiverr workers might not take this strategy"": to me it is not the spirit of corpus-based NLP. A model must be built to fit given data, not that the data must follow some assumption that the model is built on.
- the authors wrote that ""the BLEU scores of Moses and SIGN are above 60, which is generally considered decent in the MT literature"": to me the number 60 doesn't show anything at all because the sentences in the dataset are very short. And that, if we look at table 6, %changed of Moses is only 42%, meaning that even more than half of the time translation is simply copying, the BLUE score is more than 60.
- ""While higher scores might be achieved with MT systems that explicitly address rare words, these systems don't focus on sentiment words"": it's true, but I was wondering whether sentiment words are rare in the corpus. If they are, those MT systems should obviously handle them (in addition to other rare words).","['2', '5', '4']",,,1,"['1', '5', '5']",5.0,silver,"['3', '5', 'X']",,,"['1', '5', '4']",,,"['0', '1', '1']",1.0,silver,"['0', '0', '0']",0.0,gold,2,"the comment raises a relevant point about the treatment of sentiment words in mt systems, suggesting that they should be handled if they are rare in the corpus. however, the comment lacks specificity and actionable guidance for the authors on how to address this issue. it opens up a potentially important discussion but does not provide detailed suggestions or solutions, making it only marginally helpful for the authors."
1) The paper does not dig into the theory profs and show the convergence properties of the proposed algorithm.,ACL_2017_554_review,ACL_2017,"1) The paper does not dig into the theory profs and show the convergence properties of the proposed algorithm.
2) The paper only shows the comparison between SG-MCMC vs RMSProp and did not conduct other comparison. It should explain more about the relation between pSGLD vs RMSProp other than just mentioning they are conterparts in two families.
2) The paper does not talk about the training speed impact with more details.
- General Discussion:","['1', '2', '3', '2', '3', '1', '1', '2']",1.0,gold,2,"['2', '2', '4', '2', '2', '1', '1', '1']",2.0,gold,"['1', '2', '2', 'X', '1', '1', '1', 'X']",1,gold,"['1', '2', '3', '1', '1', '1', '1', '2']",1.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0', '0', '0', '0', '0']",0.0,gold,3,"the comment identifies a significant area of improvement by pointing out the lack of theoretical proofs and convergence properties in the proposed algorithm. this is a valuable insight as these theoretical aspects are often crucial for validating the algorithm's effectiveness. however, the feedback is somewhat lacking in depth, as it does not provide specific guidance or suggestions on how the authors might address these theoretical gaps. therefore, while it highlights an important issue, it does not fully empower the authors with actionable steps for improvement."
"1. When discussing related work it is crucial to mention related work on modular networks for VQA such as [A], otherwise the introduction right now seems to paint a picture that no one does modular architectures for VQA.",NIPS_2017_53,NIPS_2017,"Weakness
1. When discussing related work it is crucial to mention related work on modular networks for VQA such as [A], otherwise the introduction right now seems to paint a picture that no one does modular architectures for VQA.
2. Given that the paper uses a billinear layer to combine representations, it should mention in related work the rich line of work in VQA, starting with [B] which uses billinear pooling for learning joint question image representations. Right now the manner in which things are presented a novice reader might think this is the first application of billinear operations for question answering (based on reading till the related work section). Billinear pooling is compared to later.
3. L151: Would be interesting to have some sort of a group norm in the final part of the model (g, Fig. 1) to encourage disentanglement further.
4. It is very interesting that the approach does not use an LSTM to encode the question. This is similar to the work on a simple baseline for VQA [C] which also uses a bag of words representation.
5. (*) Sec. 4.2 it is not clear how the question is being used to learn an attention on the image feature since the description under Sec. 4.2 does not match with the equation in the section. Speficially the equation does not have any term for r^q which is the question representation. Would be good to clarify. Also it is not clear what \sigma means in the equation. Does it mean the sigmoid activation? If so, multiplying two sigmoid activations (with the \alpha_v computation seems to do) might be ill conditioned and numerically unstable.
6. (*) Is the object detection based attention being performed on the image or on some convolutional feature map V \in R^{FxWxH}? Would be good to clarify. Is some sort of rescaling done based on the receptive field to figure out which image regions belong correspond to which spatial locations in the feature map?
7. (*) L254: Trimming the questions after the first 10 seems like an odd design choice, especially since the question model is just a bag of words (so it is not expensive to encode longer sequences).
8. L290: it would be good to clarify how the implemented billinear layer is different from other approaches which do billinear pooling. Is the major difference the dimensionality of embeddings? How is the billinear layer swapped out with the hadarmard product and MCB approaches? Is the compression of the representations using Equation. (3) still done in this case?
Minor Points:
- L122: Assuming that we are multiplying in equation (1) by a dense projection matrix, it is unclear how the resulting matrix is expected to be sparse (arenât we mutliplying by a nicely-conditioned matrix to make sure everything is dense?).
- Likewise, unclear why the attended image should be sparse. I can see this would happen if we did attention after the ReLU but if sparsity is an issue why not do it after the ReLU?
Perliminary Evaluation
The paper is a really nice contribution towards leveraging traditional vision tasks for visual question answering. Major points and clarifications for the rebuttal are marked with a (*).
[A] Andreas, Jacob, Marcus Rohrbach, Trevor Darrell, and Dan Klein. 2015. âNeural Module Networks.â arXiv [cs.CV]. arXiv. http://arxiv.org/abs/1511.02799.
[B] Fukui, Akira, Dong Huk Park, Daylen Yang, Anna Rohrbach, Trevor Darrell, and Marcus Rohrbach. 2016. âMultimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding.â arXiv [cs.CV]. arXiv. http://arxiv.org/abs/1606.01847.
[C] Zhou, Bolei, Yuandong Tian, Sainbayar Sukhbaatar, Arthur Szlam, and Rob Fergus. 2015. âSimple Baseline for Visual Question Answering.â arXiv [cs.CV]. arXiv. http://arxiv.org/abs/1512.02167.","['2', '5', '5', '5']",5.0,gold,3,"['3', '5', '5', '5']",5.0,gold,"['3', '5', '2', '4']",,,"['3', '5', '3', '4']",3.0,silver,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the review point clearly identifies a specific weakness in the draft, namely the omission of important related work on modular networks for vqa. it provides actionable feedback by suggesting the inclusion of such works to improve the integrity and completeness of the introduction. while the comment could be enhanced by providing more detailed suggestions, such as specific studies or aspects to be covered, it is mostly helpful as it guides the authors to address a significant gap."
- It is not clear if authors also experimented with the usage of domain ontologies to avoid the generation of placeholders in the evaluated responses - Line 211: How many questions were created for this zero-shot intent classifier and what is the accuracy of this system?,ARR_2022_40_review,ARR_2022,"- Although author state that components can be replaced by other models for flexibility, authors did not try any change or alternative in the paper to proof the robustness of the proposed framework.
- Did authors tried using BlenderBot vs 2.0 with incorporated knowledge? it would be very interesting to see how the dialogs can be improved by using domain ontologies from the SGD dataset. - Although BlenderBot is finetuned on the SGD dataset, it is not clear how using more specific TOD chatbots can provide better results - Lines 159-162: Authors should provide more information about the type/number of personas created, and how the personas are used by the chatbot to generate the given responses. - It is not clear if authors also experimented with the usage of domain ontologies to avoid the generation of placeholders in the evaluated responses - Line 211: How many questions were created for this zero-shot intent classifier and what is the accuracy of this system?
- Line 216: How many paraphrases were created for each question, and what was their quality rate?
- Line 237: How critical was the finetuning process over the SQuad and CommonsenseQA models?
- Line 254-257: How many templates were manually created? - Line 265: How the future utterances are used during evaluation? For the generation part, are the authors generating some sort of sentence embedding representation (similar to SkipThoughs) to learn the generation of the transition sentence? and is it the transition sentence one taken from the list of manual templates? ( In general, this section 2.2.2 is the one I have found less clear) - Merge SGD: Did authors select the TOD dialogue randomly from those containing the same intent/topic? did you tried some dialogue embedding from the ODD part and tried to select a TOD dialogue with a similar dialogue embedding? if not, this could be an idea to improve the quality of the dataset. this could also allow the usage of the lexicalized version of the SGD and avoids the generation of placeholders in the responses - Line 324: how the repeated dialogues are detected? - Line 356: how and how many sentences are finally selected from the 120 generated sentences?
- Lines 402-404: How the additional transitions are generated? using the T5 model? how many times the manual sentences were selected vs the paraphrased ones?
- The paper: Fusing task-oriented and open-domain dialogues in conversational agents is not included in the background section and it is important in the context of similar datasets - Probably the word salesman is misleading since by reading some of the generated dialogues in the appendixes, it is not clear that the salesman agent is in fact selling something. It seems sometimes that they are still doing chitchat but on a particular topic or asking for some action to be done (like one to be done by an intelligent speaker)","['3', '5', '5']",5.0,silver,4,"['3', '5', '5']",5.0,silver,"['3', 'X', 'X']",X,silver,"['2', '5', '4']",,,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the review point raises two separate issues: the use of domain ontologies and the specifics of the zero-shot intent classifier. it raises important questions that could help the authors clarify and improve their work, particularly in terms of methodology and results. however, the comment lacks depth and detailed guidance on how the authors might address these issues. the feedback could be more complete by suggesting specific areas or methods to explore or by providing examples of what the authors could include to address these points. consequently, the feedback is somewhat helpful but not comprehensive or fully actionable for the authors."
"- Generally, this seems like only a very first step towards real strategic settings: in light of what they claim (""strategic predictions"", l28), their setting is only partially strategic/game theoretic as the opponent doesn't behave strategically (i.e., take into account the other strategic player).",NIPS_2017_143,NIPS_2017,"For me the main issue with this paper is that the relevance of the *specific* problem that they study -- maximizing the ""best response"" payoff (l127) on test data -- remains unclear. I don't see a substantial motivation in terms of a link to settings (real or theoretical) that are relevant:
- In which real scenarios is the objective given by the adverserial prediction accuracy they propose, in contrast to classical prediction accuracy?
- In l32-45 they pretend to give a real example but for me this is too vague. I do see that in some scenarios the loss/objective they consider (high accuracy on majority) kind of makes sense. But I imagine that such losses already have been studied, without necessarily referring to ""strategic"" settings. In particular, how is this related to robust statistics, Huber loss, precision, recall, etc.?
- In l50 they claim that ""pershaps even in most [...] practical scenarios"" predicting accurate on the majority is most important. I contradict: in many areas with safety issues such as robotics and self-driving cars (generally: control), the models are allowed to have small errors, but by no means may have large errors (imagine a self-driving car to significantly overestimate the distance to the next car in 1% of the situations).
Related to this, in my view they fall short of what they claim as their contribution in the introduction and in l79-87:
- Generally, this seems like only a very first step towards real strategic settings: in light of what they claim (""strategic predictions"", l28), their setting is only partially strategic/game theoretic as the opponent doesn't behave strategically (i.e., take into account the other strategic player).
- In particular, in the experiments, it doesn't come as a complete surprise that the opponent can be outperformed w.r.t. the multi-agent payoff proposed by the authors, because the opponent simply doesn't aim at maximizing it (e.g. in the experiments he maximizes classical SE and AE).
- Related to this, in the experiments it would be interesting to see the comparison of the classical squared/absolute error on the test set as well (since this is what LSE claims to optimize).
- I agree that ""prediction is not done in isolation"", but I don't see the ""main"" contribution of showing that the ""task of prediction may have strategic aspects"" yet. REMARKS:
What's ""true"" payoff in Table 1? I would have expected to see the test set payoff in that column. Or is it the population (complete sample) empirical payoff?
Have you looked into the work by Vapnik about teaching a learner with side information? This looks a bit similar as having your discrapency p alongside x,y.","['1', '1', '1']",1.0,gold,4,"['3', '5', '2']",,,"['3', '2', '5']",,,"['2', '2', '2']",2.0,gold,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,3,"the comment points out a potential flaw in the theoretical setting of the paper, specifically that the strategic nature of the setting is only partially realized as the opponent does not act strategically. however, the feedback lacks specific suggestions on how to address this issue or how the setting could be improved to achieve the claimed 'strategic predictions.' this leaves the authors with some insight but without detailed guidance on how to make the necessary improvements."
"3) The description of HIERENC is unclear. From what I understand, each input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary. This does not seem to be a good idea since presumably only one of those instantiations is correct. This would most likely introduce a lot of noise.",ACL_2017_588_review,ACL_2017,"and the evaluation leaves some questions unanswered. - Strengths: The proposed task requires encoding external knowledge, and the associated dataset may serve as a good benchmark for evaluating hybrid NLU systems.
- Weaknesses: 1) All the models evaluated, except the best performing model (HIERENC), do not have access to contextual information beyond a sentence. This does not seem sufficient to predict a missing entity. It is unclear whether any attempts at coreference and anaphora resolution have been made. It would generally help to see how well humans perform at the same task.
2) The choice of predictors used in all models is unusual. It is unclear why similarity between context embedding and the definition of the entity is a good indicator of the goodness of the entity as a filler.
3) The description of HIERENC is unclear. From what I understand, each input (h_i) to the temporal network is the average of the representations of all instantiations of context filled by every possible entity in the vocabulary.
This does not seem to be a good idea since presumably only one of those instantiations is correct. This would most likely introduce a lot of noise.
4) The results are not very informative. Given that this is a rare entity prediction problem, it would help to look at type-level accuracies, and analyze how the accuracies of the proposed models vary with frequencies of entities.
- Questions to the authors: 1) An important assumption being made is that d_e are good replacements for entity embeddings. Was this assumption tested?
2) Have you tried building a classifier that just takes h_i^e as inputs?
I have read the authors' responses. I still think the task+dataset could benefit from human evaluation. This task can potentially be a good benchmark for NLU systems, if we know how difficult the task is. The results presented in the paper are not indicative of this due to the reasons stated above. Hence, I am not changing my scores.","['1', '5', '1', '2', '5', '3', '3', '2']",1.0,silver,2,"['4', '5', '4', '5', '1', '5', '5', '4']",5.0,gold,"['2', '5', '2', 'X', 'X', '5', '5', '5']",5,gold,"['2', '5', '2', '3', '3', '5', '5', '3']",5.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0', '0', '0', '0']",0.0,gold,4,"the review point identifies a specific weakness in the description of hierenc, providing a clear explanation of the issue—the potential introduction of noise by averaging representations of all possible entities. this feedback is actionable as it highlights a crucial area for clarification and improvement. however, it could be considered more helpful if it offered specific suggestions on how the authors might better approach or reevaluate their methodology to address the identified problem."
3)Since the cluster structure is defined by the identity. How does the number of images impact the model performance? Do more training images make the performance worse or better ? BYOL in the abstract should be explained for its first appearance.,NIPS_2021_953,NIPS_2021,"Although the paper gives detailed theoretical proof, the experiments are somewhat weak. I still have some concerns: 1）The most related works SwaV and Barlow Twins outperform the proposed method in some experimental results, as shown in Table 1,2,5. What are the main advantages of this method compared with SwaV and Barlow Twins? 2) HSIC(Z, Y) can be seen as a distance metric in the kernel space, where the cluster structure is defined by the identity. Although this paper maps identity labels into the kernel space, the information of one-hot label is somewhat limited compared with views embeddings in Barlow Twins. 3)Since the cluster structure is defined by the identity. How does the number of images impact the model performance? Do more training images make the performance worse or better ?
BYOL in the abstract should be explained for its first appearance.","['4', '5', '5']",5.0,silver,4,"['5', '5', '3']",5.0,silver,"['4', 'X', 'X']",X,silver,"['4', '5', '4']",4.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '1']",0.0,silver,4,"the comment addresses two specific areas that need clarification in the draft. the first part raises a question about the relationship between the number of images and model performance, prompting the authors to explore this potential variable's impact. this is a valuable remark as it encourages further explanation or experimentation. the second part requests an explanation of 'byol' in the abstract, ensuring clarity for readers unfamiliar with the term. both points guide the authors toward making improvements, however, the comment could be expanded to suggest how this exploration should be conducted or what specific elements of the performance should be considered. therefore, it falls short of a perfect score, as additional detail or suggestions would increase its helpfulness."
"- I found the notation / the explicit split between ""static"" and temporal features into two variables confusing, at least initially. In my view this requires more information than is provided in the paper (what is S and Xt).",NIPS_2019_494,NIPS_2019,"of the approach, it may be interesting to do that. Clarity: The paper is well written but clarity could be improved in several cases: - I found the notation / the explicit split between ""static"" and temporal features into two variables confusing, at least initially. In my view this requires more information than is provided in the paper (what is S and Xt). - even with the pseudocode given in the supplementary material I don't get the feeling the paper is written to be reproduced. It is written to provide an intuitive understanding of the work, but to actually reproduce it, more details are required that are neither provided in the paper nor in the supplementary material. This includes, for example, details about the RNN implementation (like number of units etc), and many other technical details. - the paper is presented well, e.g., quality of graphs is good (though labels on the graphs in Fig 3 could be slightly bigger) Significance: - from just the paper: the results would be more interesting (and significant) if there was a way to reproduce the work more easily. At present I cannot see this work easily taken up by many other researchers mainly due to lack of detail in the description. The work is interesting, and I like the idea, but with a relatively high-level description of it in the paper it would need a little more than the peudocode in the materials to convince me using it (but see next). - In the supplementary material it is stated the source code will be made available, and in combination with paper and information in the supplementary material, the level of detail may be just right (but it's hard to say without seeing the code). Given the promising results, I can imagine this approach being useful at least for more research in a similar direction.","['5', '3', '4', '1']",,,3,"['5', '5', '5', '5']",5.0,gold,"['4', 'X', 'X', '2']",X,silver,"['4', '5', '4', '3']",4.0,silver,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the comment is mostly helpful because it clearly identifies a specific confusion regarding the notation and the distinction between 'static' and temporal features. the reviewer suggests that the paper lacks information on this topic, which is an actionable piece of feedback. however, while the comment indicates where additional clarification is needed, it could be more helpful if it included suggestions on how the authors might address this confusion or provide examples of possible clarifications. therefore, it earns a score of 4, as it effectively points to an area for improvement but could be more comprehensive in guiding the authors."
"1: ""The uncertainty is defined based on the posterior distribution."" For more clarity it could be helpful to update this to say that the epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data. p.",ICLR_2021_2047,ICLR_2021,"As noted below, I have concerns around the experimental results. More specifically, I feel that there is a relative lack of discussion around the (somewhat surprising) outperformance of baselines that VPBNN is aiming to approximate, and I feel that the experiments are missing what I see as key VPBNN results that otherwise leave the reader with questions. Additionally, I think the current paper would benefit from including measurements and discussion around the specifics of computational and memory costs of their method. Recommendation
In general, I think this could be a great paper. However, given the above concerns, I'm currently inclined to suggest rejection of the paper in its current state. I would highly recommend that authors push further on the noted areas!
Additional comments
p. 1: ""The uncertainty is defined based on the posterior distribution."" For more clarity it could be helpful to update this to say that the epistemic model uncertainty is represented in the prior distribution, and upon observing data, those beliefs can be updated in the form of a posterior distribution, which yields model uncertainty conditioned on observed data.
p. 2: ""The MC dropout requires a number of repeated feed-forward calculations with randomly sampled weight parameters in order to obtain the predictive distribution."" This should be updated to indicate that in MC dropout, dropout is used (in an otherwise deterministic model) at test time with ""a number of repeated feed-forward calculations"" to effectively sample from the approximate posterior, but not directly via different weight samples (as in a variational BNN). With variational dropout, this ends up having a nice interpretation as a variational Bayes method, though no weight distributions are typically directly used with direct MC dropout.
p. 2: Lakshminarayanan et al. (2017) presented random seed ensembles, not bootstrap ensembles (see p. 4 of their work for more info). They used the full dataset, and trained M ensemble members with different random seeds, rather than resampled data.
p. 4: For variance propagation in a dropout layer with stochastic input, it's not exactly clear from the text how variance from the inputs and dropout is being combined into an output Gaussian. I believe using a Gaussian is an approximation, and while that would be fine, I think it would be informative to indicate that. The same issue comes up with local reparameterization for BNNs with parameter distributions, where they can be reparameterized exactly as output distributions (for, say, mean-field Gaussian weight dists) so long as the inputs are deterministic. Otherwise, the product of, say, two Gaussian RVs is non-Gaussian.
p. 7: Figure 1 is too small.
p. 7: ""Estimation of ρ is possible by observing the outputs of middle layers several times under the approximate predictive distribution. The additional computation cost is still kept quite small compared to MC dropout."" How exactly is ρ
estimated? Is it a one-time cost irregardless of data that can then be used for all predictions from the trained model? Without details, this seems like a key component that can yield arbitrary amounts of uncertainty.
p. 7, 8: For the language modeling experiment, why do you think VPBNN was able to achieve lower perplexity values than MC dropout? The text generally focuses on VPBNN as an approximation to MC dropout, and yet it outperforms it. The text would greatly benefit from more discussion around this point.
p. 8: For the OOD detection experiment, I'm surprised that ρ = 0
was the only VPBNN model used, since Section 5.1 and Figure 1 indicated that it led to overconfident models. Can you include results with other settings of ρ
? Moreover, from Figure 1 we see that (for that model) VPBNN with ρ = 0
qualitatively yielded the same amount of predictive variance as the Taylor approximation. However, in Table 2, we see VPBNN with ρ = 0
outperform MC dropout (with 100 or 2000 samples) and the Taylor approximation. Why do you think this is the case, particularly if the standard deviation was used as the uncertainty signal for the OOD decision. I see that ""This is because the approximation accuracy of the Taylor approximation is not necessarily high as shown in Section B"", but I did not find Section B or Figure 3 to be clear. I think the text would benefit from more discussion here, and from the additional experiments for ρ .
Can you include a discussion and measurements for FLOPS and memory usage for VPBNN? Specifically, given the discussion around efficiency and the implementation that doubles the dimensionality of the intermediates throughout the model, I believe it would be informative to have theoretical and possibly runtime measurements. Minor
p. 1: s/using the dropout/using dropout/
p. 1: s/of the language modeling/of language modeling/
p. 2: s/is the representative of/is representative of/
p. 2: s/In the deep learning/In deep learning/
p. 2: s/This relations/This relation/
p. 5: Need to define s
as the sigmoid function in the LSTM cell equations.","['5', '5', '5']",5.0,gold,4,"['5', '5', '5']",5.0,gold,"['2', 'X', '4']",,,"['4', '5', '2']",,,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,5,"the review point is highly helpful as it provides a clear and detailed explanation that guides the authors to enhance the clarity of their description regarding uncertainty in their model. by suggesting a specific way to articulate the concept of model uncertainty and its representation in prior and posterior distributions, the comment empowers the authors to significantly improve their draft's clarity and precision. the actionable guidance makes it easy for the authors to implement the suggested improvement."
"1) Is it necessary to treat concept map extraction as a separate task? On the one hand, many generic summarization systems build a similar knowledge graph and then generate summaries accordingly. On the other hand, with the increase of the node number, the concept map becomes growing hard to distinguish. Thus, the general summaries should be more readable.",ACL_2017_331_review,ACL_2017,"The document-independent crowdsourcing annotation is unreliable. - General Discussion: This work creates a new benchmark corpus for concept-map-based MDS. It is well organized and written clearly. The supplement materials are sufficient. I have two questions here.
1) Is it necessary to treat concept map extraction as a separate task?
On the one hand, many generic summarization systems build a similar knowledge graph and then generate summaries accordingly. On the other hand, with the increase of the node number, the concept map becomes growing hard to distinguish. Thus, the general summaries should be more readable.
2) How can you determine the importance of a concept independent of the documents? The definition of summarization is to reserve the main concepts of documents. Therefore, the importance of a concept highly depends on the documents. For example, in the given topic of coal mining accidents, assume there are two concepts: A) an instance of coal mining accidents and B) a cause of coal mining accidents. Then, if the document describes a series of coal mining accidents, A is more important than B. In comparison, if the document explores why coal mining accidents happen, B is more significant than A. Therefore, just given the topic and two concepts A&B, it is impossible to judge their relative importance.
I appreciate the great effort spent by authors to build this dataset. However, this dataset is more like a knowledge graph based on common sense rather than summary.","['1', '2', '2', '1', '3', '1', '1', '3']",1.0,gold,2,"['1', '5', '4', '2', '4', '2', '4', '2']",4.0,gold,"['X', '5', '3', '4', '3', '3', '5', '4']",3,gold,"['1', '3', '4', '3', '2', '3', '4', '2']",3.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '1', '0', '0', '0', '0', '0']",0.0,gold,3,"the comment questions the necessity of treating concept map extraction as a separate task and compares it to generic summarization systems, suggesting that general summaries might offer more readability as the complexity of concept maps increases. however, it lacks clear guidance or actionable feedback for the authors. while it initiates a valid discussion point and provides some insight, it does not fully address how the authors can improve their draft or explore alternative approaches in detail."
2. The hyper-parameters $b$ (bit-width) and $\alpha$ (stability factor) may introduce significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy.,of2rhALq8l,ICLR_2024,"1. A significant weakness of this paper is the lack of clarity in explaining the implementation of the core concept, which involves the use of strictly diagonal matrices and the proposed Gradual Mask (GM). Figure 2 suggests that the GM matrix is element-wise multiplied by the matrix A, but the description implies a different interpretation, where it functions as a learning rate for each element in A. This discrepancy needs further clarification to provide a complete understanding of the method.
2. The hyper-parameters $b$ (bit-width) and $\alpha$ (stability factor) may introduce significant computational overhead in the pursuit of determining the optimal trade-off between model size and accuracy.","['2', '2', '1']",2.0,silver,4,"['3', '5', '3']",3.0,silver,"['3', '3', '2']",3,silver,"['2', '3', '2']",2.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the comment points out a potential issue regarding the hyper-parameters $b$ and $\alpha$, specifically in relation to computational overhead when optimizing the trade-off between model size and accuracy. however, it lacks depth and actionable suggestions that could guide the authors in addressing this problem. while it identifies a possible concern, additional details on how to mitigate this overhead or ways to analyze and balance these parameters would make it more helpful. as it stands, the comment is informative but not comprehensive enough to fully guide improvement."
"3. For evaluation, since the claim of this paper is to reduce exposure bias, training a discriminator on generations from the learned model is needed to confirm if it is the case, in a way similar to Figure 1. Note that it is different from Figure 4, since during training the discriminator is co-adapting with the generator, and it might get stuck at a local optimum.",NIPS_2020_1592,NIPS_2020,"Major concerns: 1. While it is impressive that this work gets slightly better results than MLE, there are more hyper-parameters to tune, including mixture weight, proposal temperature, nucleus cutoff, importance weight clipping, MLE pretraining (according to appendix). I find it disappointing that so many tricks are needed. If you get rid of pretraining/initialization from T5/BART, would this method work? 2. This work requires MLE pretraining, while prior work ""Training Language GANs from Scratch"" does not. 3. For evaluation, since the claim of this paper is to reduce exposure bias, training a discriminator on generations from the learned model is needed to confirm if it is the case, in a way similar to Figure 1. Note that it is different from Figure 4, since during training the discriminator is co-adapting with the generator, and it might get stuck at a local optimum. 4. This work is claiming that it is the first time that language GANs outperform MLE, while prior works like seqGAN or scratchGAN all claim to be better than MLE. Is this argument based on the tradeoff between BLEU and self-BLEU from ""language GANs falling short""? If so, Figure 2 is not making a fair comparison since this work uses T5/BART which is trained on external data, while previous works do not. What if you only use in-domain data? Would this still outperform MLE? Minor concerns: 5. This work only uses answer generation and summarization to evaluate the proposed method. While these are indeed conditional generation tasks, they are close to ""open domain"" generation rather than ""close domain"" generation such as machine translation. I think this work would be more convincing if it is also evaluated in machine translation which exhibits much lower uncertainties per word. 6. The discriminator accuracy of ~70% looks low to me, compared to ""Real or Fake? Learning to Discriminate Machine from Human Generated Text"" which achieves almost 90% accuracy. I wonder if the discriminator was not initialized with a pretrained LM, or is that because the discriminator used is too small? ===post-rebuttal=== The added scratch GAN+pretraining (and coldGAN-pretraining) experiments are fairer, but scratch GAN does not need MLE pretraining while this work does, and we know that MLE pretraining makes a big difference, so I am still not very convinced. My main concern is the existence of so many hyper-parameters/tricks: mixture weight, proposal temperature, nucleus cutoff, importance weight clipping, and MLE pretraining. I think some sensitivity analysis similar to scratch GAN's would be very helpful. In addition, rebuttal Figure 2 is weird: when generating only one word, why would cold GAN already outperform MLE by 10%? To me, this seems to imply that improvement might be due to hyper-parameter tuning.","['5', '5', '5']",5.0,gold,4,"['5', '5', '5']",5.0,gold,"['5', '4', '5']",5,silver,"['5', '4', '5']",5.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the review point identifies a specific area for improvement related to the paper's evaluation of its claim to reduce exposure bias. it provides clear and actionable feedback by suggesting the training of a discriminator on generations from the learned model and differentiates this suggestion from a figure already present in the paper. this helps guide the authors in modifying their evaluation methodology. however, the comment could be expanded with additional details or suggestions to further assist the authors, such as elaborating on how to implement this discriminator or addressing potential challenges, to achieve a perfect score."
"2. In the experiment of face recognition, some state-of-the art references are missing, such as Baidu' work ""Targeting Ultimate Accuracy: Face Recognition via Deep Embedding"", http://vis-www.cs.umass.edu/lfw/results.html#baidu. In that work, the triplet loss is also used and it reported the result trained on the dataset containing 9K identities and 450K images, which is similar with Webface. The VRF can achieve 98.65% on LFW which is better than the result in Table 3 in this paper.",NIPS_2016_208,NIPS_2016,"1. The novelty is a little weak. It is not clear what's the significant difference and advantage compared to NCA [6] and ""Small codes and large image databases for recognition"", A. Torralba et al., 2008, which used NCA in deep learning. 2. In the experiment of face recognition, some state-of-the art references are missing, such as Baidu' work ""Targeting Ultimate Accuracy: Face Recognition via Deep Embedding"", http://vis-www.cs.umass.edu/lfw/results.html#baidu. In that work, the triplet loss is also used and it reported the result trained on the dataset containing 9K identities and 450K images, which is similar with Webface. The VRF can achieve 98.65% on LFW which is better than the result in Table 3 in this paper.","['5', '3', '4', '5']",5.0,silver,3,"['5', '5', '5', '5']",5.0,gold,"['5', '5', '5', '5']",5,gold,"['5', '5', '4', '5']",5.0,gold,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the review point is mostly helpful as it highlights a significant area for improvement by pointing out missing state-of-the-art references that could enhance the rigor and completeness of the authors' experiment. the comment also provides a specific example of important related work, including relevant details like the dataset size and accuracy achieved, which can help the authors benchmark or contrast their results against existing work. however, the feedback could be more comprehensive by suggesting specific ways the authors might incorporate these references or by identifying additional ways to improve their experimental design or analysis. overall, it provides clear guidance but could still be a bit more detailed."
"8: s/expensive approaches2) allows/expensive approaches,2) allows/ p.8: s/estimates3) is/estimates, and3) is/ In the references: Various words in many of the references need capitalization, such as ""ai"" in Amodei et al. (2016), ""bayesian"" in many of the papers, and ""Advances in neural information processing systems"" in several of the papers. Dusenberry et al. (2020) was published in ICML 2020 Osawa et al. (2019) was published in NeurIPS 2019 Swiatkowski et al. (2020) was published in ICML 2020 p. 13, supplement, Fig.",ICLR_2021_872,ICLR_2021,"The authors push on the idea of scalable approximate inference, yet the largest experiment shown is on CIFAR-10. Given this focus on scalability, and the experiments in recent literature in this space, I think experiments on ImageNet would greatly strengthen the paper (though I sympathize with the idea that this can a high bar from a resources standpoint).
As I noted down below, the experiments currently lack results for the standard variational BNN with mean-field Gaussians. More generally, I think it would be great to include the remaining models from Ovadia et al. (2019). More recent results from ICML could also useful to include (as referenced in the related works sections). Recommendation
Overall, I believe this is a good paper, but the current lack of experiments on a dataset larger than CIFAR-10, while also focusing on scalability, make it somewhat difficult to fully recommend acceptance. Therefore, I am currently recommending marginal acceptance for this paper.
Additional comments
p. 5-7: Including tables of results for each experiment (containing NLL, ECE, accuracy, etc.) in the main text would be helpful to more easily assess
p. 7: For the MNIST experiments, in Ovadia et al. (2019) they found that variational BNNs (SVI) outperformed all other methods (including deep ensembles) on all shifted and OOD experiments. How does your proposed method compare? I think this would be an interesting experiment to include, especially since the consensus in Ovadia et al. (2019) (and other related literature) is that full variational BNNs are quite promising but generally methodologically difficult to scale to large problems, with relative performance degrading even on CIFAR-10. Minor
p. 6: In the phrase ""for 'in-between' uncertainty"", the first quotation mark on 'in-between' needs to be the forward mark rather than the backward mark (i.e., ‘ i n − b e t w e e n ′ ).
p. 7: s/out of sitribution/out of distribution/
p. 8: s/expensive approaches 2) allows/expensive approaches, 2) allows/
p. 8: s/estimates 3) is/estimates, and 3) is/
In the references:
Various words in many of the references need capitalization, such as ""ai"" in Amodei et al. (2016), ""bayesian"" in many of the papers, and ""Advances in neural information processing systems"" in several of the papers.
Dusenberry et al. (2020) was published in ICML 2020
Osawa et al. (2019) was published in NeurIPS 2019
Swiatkowski et al. (2020) was published in ICML 2020
p. 13, supplement, Fig. 5: error bar regions should be upper and lowered bounded by [0, 1] for accuracy.
p. 13, Table 2: Splitting this into two tables, one for MNIST and one for CIFAR-10, would be easier to read.","['5', '5', '5', '5']",5.0,gold,3,"['5', '5', '5', '5']",5.0,gold,"['5', 'X', '5', 'X']",5,silver,"['5', '5', '5', '4']",5.0,gold,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the review point is mostly helpful since it identifies specific issues related to formatting, capitalization, and the accuracy of references. these corrections provide clear and actionable feedback that the authors can implement to better align their paper with academic standards. however, the review could be further improved by offering additional context or explanations as to why these changes are necessary, making the feedback more comprehensive and impactful."
- The time complexity will be too high if the reply buffer is too large. [1] PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning,NIPS_2019_1366,NIPS_2019,"Weakness: - Although the method discussed by the paper can be applied in general MDP, the paper is limited in navigation problems. Combining RL and planning has already been discussed in PRM-RL~[1]. It would be interesting whether we can apply such algorithms in more general tasks. - The paper has shown that pure RL algorithm (HER) failed to generalize to distance goals but the paper doesn't discuss why it failed and why planning can solve the problem that HER can't solve. Ideally, if the neural networks are large enough and are trained with enough time, Q-Learning should converge to not so bad policy. It will be better if the authors can discuss the advantages of planning over pure Q-learning. - The time complexity will be too high if the reply buffer is too large. [1] PRM-RL: Long-range Robotic Navigation Tasks by Combining Reinforcement Learning and Sampling-based Planning","['1', '1', '1']",1.0,gold,4,"['1', '3', '1']",1.0,silver,"['2', '5', '5']",5,silver,"['2', '3', '1']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,2,"the comment identifies a potential weakness in terms of time complexity related to the size of the reply buffer. however, it is too vague and does not provide sufficient clarity or guidance on how to address or mitigate this issue. for the authors to find it beneficial, the comment should elaborate on why the time complexity is a concern and suggest strategies to improve or measure this aspect. therefore, this feedback is barely helpful."
"3. The paper does not clearly motivate GaRare; it lacks evidence or justification for GaRare's advantages over GaLore based on theoretical analysis. Additionally, a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients, which would enhance understanding.",pxclAomHat,ICLR_2025,"1. The paper does not explicitly link the quality of the optimization landscape to convergence speed or generalization performance, which undermines its stated goal of theoretically explaining the performance of LoRA and GaLore. Many claims also lack this connection (e.g., lines 60-61, 289-291, and 301-304), making them appear weaker and less convincing.
2. The theoretical results in this paper are derived from analyses of MLPs, whereas LLMs, with their attention mechanisms, layer normalization, etc., are more complex. Since there is a gap between MLPs and LLMs, and the paper does not directly validate its theoretical results on LLMs (instead of relying only on the convergence and performance outcomes), the theoretical conclusions are less convincing.
3. The paper does not clearly motivate GaRare; it lacks evidence or justification for GaRare's advantages over GaLore based on theoretical analysis. Additionally, a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients, which would enhance understanding.","['5', '4', '4', '5']",5.0,silver,3,"['5', '3', '4', '5']",5.0,silver,"['5', '3', 'X', '5']",5,silver,"['5', '3', '4', '5']",5.0,silver,"['1', '1', '1', '0']",1.0,gold,"['0', '0', '0', '1']",0.0,gold,4,"the comment identifies specific weaknesses in the paper, such as the lack of motivation and evidence for garare's advantages over galore and the need for a more detailed algorithmic presentation. it provides clear guidance on what aspects need improvement, particularly the theoretical justification and clarity in the algorithm description. while the feedback is mostly helpful and actionable, it could potentially provide even more detailed suggestions on how to present the advantages or clarify the algorithm further, which would make it fully comprehensive and achieve a score of 5."
"2. I'm curious to what extent the results are due to being able to capture periodicity, rather than compositionality more generally. The comparison model is one that cannot capture periodic relationships, and in all of the experiments except Experiment 1b the relationships that people were learning involved periodicity. Would adding periodicity to the spectral kernel be enough to allow it to capture all of these results at a similar level to the explicitly compositional model?",NIPS_2016_417,NIPS_2016,"1. Most of the human function learning literature has used tasks in which people never visualize data or functions. This is also the case in naturalistic settings where function learning takes place, where we have to form a continuous mapping between variables from experience. All of the tasks that were used in this paper involved presenting people with data in the form of a scatterplot or functional relationship, and asking them to evaluate lines applied to those axes. This task is more akin to data analysis than the traditional function learning task, and much less naturalistic. This distinction matters because performance in the two tasks is likely to be quite different. In the standard function learning task, it is quite hard to get people to learn periodic functions without other cues to periodicity. Many of the effects in this paper seem to be driven by periodic functions, suggesting that they may not hold if traditional tasks were used. I don't think this is a major problem if it is clearly acknowledged and it is made clear that the goal is to evaluate whether data-analysis systems using compositional functions match human intuitions about data analysis. But it is important if the paper is intended to be primarily about function learning in relation to the psychological literature, which has focused on a very different task. 2. I'm curious to what extent the results are due to being able to capture periodicity, rather than compositionality more generally. The comparison model is one that cannot capture periodic relationships, and in all of the experiments except Experiment 1b the relationships that people were learning involved periodicity. Would adding periodicity to the spectral kernel be enough to allow it to capture all of these results at a similar level to the explicitly compositional model? 3. Some of the details of the models are missing. In particular the grammar over kernels is not explained in any detail, making it hard to understand how this approach is applied in practice. Presumably there are also probabilities associated with the grammar that define a hypothesis space of kernels? How is inference performed?","['3', '4', '5']",,,4,"['5', '5', '3']",5.0,silver,"['5', 'X', 'X']",X,silver,"['5', '5', '3']",5.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the comment is mostly helpful because it raises an important question regarding the results' dependency on periodicity and the capabilities of different models in the study. the reviewer encourages the authors to consider whether adding periodicity to the spectral kernel could achieve similar results to the compositional model. this question prompts the authors to think critically about their model's assumptions and performance. however, the feedback could be even more helpful if it provided specific suggestions or examples on how to explore and test this hypothesis, making it a fully comprehensive and highly impactful comment."
"- Since overparameterization can often lead to powerful memorization and good generalization performance, the necessary conditions may have stronger implications if they are connected to generalization bounds. It is not clear in the paper that the constructions of ReLU networks for robust memorization would lead to robust generalization. I know the authors acknowledge this in the conclusion, but I think this is a very serious question.",47hDbAMLbc,ICLR_2024,"- The paper is mainly dedicated to the existence of robust training. No results on optimization or robust generalization are derived. Given that, the scope seems to be quite limited.
- Since overparameterization can often lead to powerful memorization and good generalization performance, the necessary conditions may have stronger implications if they are connected to generalization bounds. It is not clear in the paper that the constructions of ReLU networks for robust memorization would lead to robust generalization. I know the authors acknowledge this in the conclusion, but I think this is a very serious question.
- The main theorems 4.8 and 5.2 only guarantee the existence of optimal robust memorization. These results would be more useful if an optimization or constructive algorithm is given to find the optimal memorization.","['2', '4', '2']",2.0,silver,4,"['3', '3', '3']",3.0,gold,"['2', '3', '5']",,,"['2', '3', '3']",3.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the comment addresses a significant conceptual issue, raising an important question regarding the link between robust memorization and generalization in relu networks. it acknowledges that the authors have mentioned this concern in the conclusion, which indicates the comment is based on a valid weakness. however, the review point lacks specific guidance or suggestions on how the authors could address this issue or improve their discussion, making it somewhat helpful but not fully actionable for the authors."
2.The motivation is not clear at all. The introduction should be carefully revised to make this paper easy to follow.,ICLR_2023_3948,ICLR_2023,"1.This paper lacks novelty and is only a combination of some existing approaches, such as Qu et al. (2020). Moreover, I find that the equations are similar.
2.The motivation is not clear at all. The introduction should be carefully revised to make this paper easy to follow.
3.I find the experimental analysis is vague, and why the model works better is not clear. No case studies and no detailed ablation analysis.","['2', '2', '3']",2.0,silver,4,"['2', '4', '4']",4.0,silver,"['1', '2', '3']",,,"['2', '2', '4']",2.0,silver,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,2,"the comment is barely helpful because it identifies a weakness regarding the lack of clear motivation in the introduction. however, it is vague and lacks specific guidance on how the authors can address this issue. the suggestion to 'carefully revise' does not provide actionable steps or detailed feedback, making it only slightly beneficial to the authors."
1.Limited Discussion of Scalability Bounds:The paper doesn't thoroughly explore the upper limits of FedDES's scalability；No clear discussion of memory requirements or computational complexity.,pZk9cUu8p6,ICLR_2025,"1.Limited Discussion of Scalability Bounds:The paper doesn't thoroughly explore the upper limits of FedDES's scalability；No clear discussion of memory requirements or computational complexity.
2.Validation Scope:Evaluation focuses mainly on Vision Transformer with CIFAR-10;Could benefit from testing with more diverse models and datasets; Limited exploration of edge cases or failure scenarios
3.Network Modeling:While network delays are considered, there's limited discussion of complex network topologies or dynamic network conditions; The paper could benefit from more detailed analysis of how network conditions affect simulation accuracy","['3', '4', '2']",,,4,"['3', '5', '3']",3.0,silver,"['3', 'X', '4']",,,"['3', '5', '3']",3.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the comment is mostly helpful as it clearly identifies specific weaknesses in the paper related to the discussion of scalability bounds, memory requirements, and computational complexity. while it effectively points out the areas that need improvement, it could be more helpful by providing suggestions or guidance on how the authors can address these issues, such as proposing methods or frameworks to explore these limits. despite this, it still offers actionable feedback that can guide the authors in enhancing their draft."
"- It would be good to include in the left graph in fig 3 the learning curve for a model without any mean teacher or pi regularization for comparison, to see if mean teacher accelerates learning or slows it down.",NIPS_2017_114,NIPS_2017,"- More evaluation would have been welcome, especially on CIFAR-10 in the full label and lower label scenarios.
- The CIFAR-10 results are a little disappointing with respect to temporal ensembles (although the results are comparable and the proposed approach has other advantages)
- An evaluation on the more challenging STL-10 dataset would have been welcome. Comments
- The SVNH evaluation suggests that the model is better than pi an temporal ensembling especially in the low-label scenario. With this in mind, it would have been nice to see if you can confirm this on CIFAR-10 too (i.e. show results on CIFAR-10 with less labels)
- I would would have like to have seen what the CIFAR-10 performance looks like with all labels included.
- It would be good to include in the left graph in fig 3 the learning curve for a model without any mean teacher or pi regularization for comparison, to see if mean teacher accelerates learning or slows it down.
- I'd be interested to see if the exponential moving average of the weights provides any benefit on it's own, without the additional consistency cost.","['5', '5', '5', '5']",5.0,gold,3,"['5', '5', '5', '5']",5.0,gold,"['5', '3', 'X', '5']",5,silver,"['5', '4', '5', '5']",5.0,gold,"['1', '1', '1', '0']",1.0,gold,"['0', '0', '0', '1']",0.0,gold,4,"the review point is mostly helpful because it provides specific and actionable feedback that encourages the authors to make a direct comparison by including an additional learning curve in the graph. this suggestion can help assess the impact of the mean teacher or pi regularization on the learning process. however, the comment could be made more comprehensive by explaining why this comparison could provide valuable insights or detailing what specific conclusions could be drawn from such an addition."
". First of all, the experimental results are quite interesting, especially that the algorithm outperforms DQN on Atari. The results on the synthetic experiment are also interesting. I have three main concerns about the paper.",NIPS_2016_450,NIPS_2016,". First of all, the experimental results are quite interesting, especially that the algorithm outperforms DQN on Atari. The results on the synthetic experiment are also interesting. I have three main concerns about the paper. 1. There is significant difficulty in reconstructing what is precisely going on. For example, in Figure 1, what exactly is a head? How many layers would it have? What is the ""Frame""? I wish the paper would spend a lot more space explaining how exactly bootstrapped DQN operates (Appendix B cleared up a lot of my queries and I suggest this be moved into the main body). 2. The general approach involves partitioning (with some duplication) the samples between the heads with the idea that some heads will be optimistic and encouraging exploration. I think that's an interesting idea, but the setting where it is used is complicated. It would be useful if this was reduced to (say) a bandit setting without the neural network. The resulting algorithm will partition the data for each arm into K (possibly overlapping) sub-samples and use the empirical estimate from each partition at random in each step. This seems like it could be interesting, but I am worried that the partitioning will mean that a lot of data is essentially discarded when it comes to eliminating arms. Any thoughts on how much data efficiency is lost in simple settings? Can you prove regret guarantees in this setting? 3. The paper does an OK job at describing the experimental setup, but still it is complicated with a lot of engineering going on in the background. This presents two issues. First, it would take months to re-produce these experiments (besides the hardware requirements). Second, with such complicated algorithms it's hard to know what exactly is leading to the improvement. For this reason I find this kind of paper a little unscientific, but maybe this is how things have to be. I wonder, do the authors plan to release their code? Overall I think this is an interesting idea, but the authors have not convinced me that this is a principled approach. The experimental results do look promising, however, and I'm sure there would be interest in this paper at NIPS. I wish the paper was more concrete, and also that code/data/network initialisation can be released. For me it is borderline. Minor comments: * L156-166: I can barely understand this paragraph, although I think I know what you want to say. First of all, there /are/ bandit algorithms that plan to explore. Notably the Gittins strategy, which treats the evolution of the posterior for each arm as a Markov chain. Besides this, the figure is hard to understand. ""Dashed lines indicate that the agent can plan ahead..."" is too vague to be understood concretely. * L176: What is $x$? * L37: Might want to mention that these algorithms follow the sampled policy for awhile. * L81: Please give more details. The state-space is finite? Continuous? What about the actions? In what space does theta lie? I can guess the answers to all these questions, but why not be precise? * Can you say something about the computation required to implement the experiments? How long did the experiments take and on what kind of hardware? * Just before Appendix D.2. ""For training we used an epsilon-greedy ..."" What does this mean exactly? You have epsilon-greedy exploration on top of the proposed strategy?","['1', '1']",1.0,silver,4,"['3', '1']",,,"['2', '1']",,,"['1', '1']",1.0,silver,"['1', '1']",1.0,silver,"['1', '1']",1.0,silver,2,"the review comment acknowledges interesting experimental results but is vague in terms of providing actionable feedback. while it mentions having 'three main concerns,' it does not specify what these concerns are in this segment. as a result, the comment only offers minimal guidance and is barely helpful for the authors looking to improve their draft."
"4.The unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced, which is impractical in real-world applications. Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.",ICLR_2021_1181,ICLR_2021,"1.For domain adaptation in the NLP field, powerful pre-trained language models, e.g., BERT, XLNet, can overcome the domain-shift problem to some extent. Thus, the authors should be used as the base encoder for all methods and then compare the efficacy of the transfer parts instead of the simplest n-gram features.
2.The whole procedure is slightly complex. The author formulates the prototypical distribution as a GMM, which has high algorithm complexity. However, formal complexity analysis is absent. The author should provide an analysis of the time complexity and training time of the proposed SAUM method compared with other baselines. Besides, a statistically significant test is absent for performance improvements.
3.The motivation of learning a large margin between different classes is exactly discriminative learning, which is not novel when combined with domain adaptation methods and already proposed in the existing literature, e.g., Unified Deep Supervised Domain Adaptation and Generalization, Saeid et al., ICCV 2017. Contrastive Adaptation Network for Unsupervised Domain Adaptation, Kang et al., CVPR 2019 Joint Domain Alignment and Discriminative Feature Learning for Unsupervised Deep Domain Adaptation, Chen et al., AAAI 2019.
However, this paper lacks detailed discussions and comparisons with existing discriminative feature learning methods for domain adaptation.
4.The unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced, which is impractical in real-world applications. Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.
5.The paper lacks some related work about cross-domain sentiment analysis, e.g., End-to-end adversarial memory network for cross-domain sentiment classification, Li et al., IJCAI 2017 Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018 Hierarchical attention transfer network for cross-domain sentiment classification, Li et al., AAAI 18 Questions:
1.Have the authors conducted the significance tests for the improvements?
2.How fast does this algorithm run or train compared with other baselines?","['4', '5', '4', '3']",4.0,silver,3,"['5', '5', '5', '5']",5.0,gold,"['5', '5', '5', '5']",5,gold,"['4', '5', '5', '3']",5.0,silver,"['1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0']",0.0,gold,4,"the comment is mostly helpful as it provides specific feedback on a significant issue with the dataset being used by the authors - the impracticality of a perfectly balanced dataset in real-world applications. it suggests that the authors should adopt a more realistic data setting by using a method from a specific referenced work (adaptive semi-supervised learning for cross-domain sentiment classification by he et al., emnlp 2018). this suggestion is actionable and relevant, showing the authors a concrete way to enhance their work. however, the comment could be expanded by explaining why the balance is impractical and detailing how the signaled reference improves upon this issue for a perfect comprehensive score."
"1. The proposed method is not compared with other CWS models. The baseline model (Bi-LSTM) is proposed in [1] and [2]. However, these model is proposed not for CWS but for POS tagging and NE tagging. The description ""In this paper, we employ the state-of-the-art architecture ..."" (in Section 2) is misleading.",ACL_2017_326_review,ACL_2017,"1. The proposed method is not compared with other CWS models. The baseline model (Bi-LSTM) is proposed in [1] and [2]. However, these model is proposed not for CWS but for POS tagging and NE tagging. The description ""In this paper, we employ the state-of-the-art architecture ..."" (in Section 2) is misleading.
2. The purpose of experiments in Section 6.4 is unclear. In Sec. 6.4, the purpose is that investigating ""datasets in traditional Chinese and simplified Chinese could help each other."" However, in the experimental setting, the model is separately trained on simplified Chinese and traditional Chinese, and the shared parameters are fixed after training on simplified Chinese. What is expected to fixed shared parameters?
- General Discussion: The paper should be more interesting if there are more detailed discussion about the datasets that adversarial multi-criteria learning does not boost the performance.
[1] Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional lstm-crf models for sequence tagging. arXiv preprint arXiv:1508.01991.
[2] Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354 .","['2', '5', '2']",2.0,silver,1,"['2', '4', '3']",,,"['4', '4', '5']",4,silver,"['2', '4', '3']",,,"['1', '1', '1']",1.0,gold,"['1', '1', '0']",1.0,silver,4,"the review point identifies a significant weakness in the draft, namely the lack of comparison with other cws models and the misleading description of the baseline model. the reviewer provides specific references to the models used, which aids the authors in understanding the issue. however, while it highlights the problem clearly, the feedback could be expanded with suggestions on specific cws models to consider for comparison, making it even more comprehensive and actionable for the authors."
1) The proposed methods - contrastive training objective and contrastive search - are two independent methods that have little inner connection on both the intuition and the algorithm.,NIPS_2022_2315,NIPS_2022,Weakness: 1) The proposed methods - contrastive training objective and contrastive search - are two independent methods that have little inner connection on both the intuition and the algorithm. 2) The justification for isotropic representation and contractive search could be more solid.,"['1', '1', '1']",1.0,gold,4,"['3', '4', '2']",,,"['3', '2', '1']",,,"['3', '3', '2']",3.0,silver,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,2,"the comment identifies a potential issue with the proposed methods, suggesting they may lack an inner connection. however, it is vague and provides no guidance or suggestions on how the authors could address or explore this issue further. to be more helpful, the reviewer could clarify why this is an issue and propose ways to either strengthen the connection between the methods or justify their independence. as it stands, the comment offers minimal actionable feedback for the authors."
"2) How to deal with the different types of inputs (e.g., bio-medical signals or speech)? It would be valuable to discuss it and present your solutions in this paper. The citation seems a bit disordered.",NIPS_2021_291,NIPS_2021,"The writing is clear and the motivation is clarified clearly. Besides, the theoretical grounding and experimental evaluation are not sufficient to show their originality and significance. Here are some of the suggestions: 1) I would like to see ablation studies for the proposed training method, the traditional backpropagation framework refers as the baseline. 2) How to deal with the different types of inputs (e.g., bio-medical signals or speech)? It would be valuable to discuss it and present your solutions in this paper. The citation seems a bit disordered.","['4', '3', '4', '5']",4.0,silver,3,"['3', '2', '4', '3']",3.0,silver,"['1', '2', 'X', '1']",1,silver,"['3', '3', '3', '4']",3.0,gold,"['1', '1', '1', '0']",1.0,gold,"['1', '0', '0', '1']",1.0,silver,3,"the review point identifies a potential area for improvement by suggesting a discussion on handling different types of inputs, such as bio-medical signals or speech, which could enhance the draft. however, it lacks depth and specifics on how the authors might approach this topic or integrate it into their paper. additionally, the comment briefly notes an issue with the citation being disordered but does not provide clear guidance on how to address this. while the feedback is somewhat helpful in pointing out areas that need attention, it falls short of offering comprehensive, actionable guidance."
"1. The paper contains severe writing issues such as grammatical errors, abuses of mathematical symbols, unclear sentences, etc.",ICLR_2022_1675,ICLR_2022,"Weakness] 1. The paper contains severe writing issues such as grammatical errors, abuses of mathematical symbols, unclear sentences, etc. 2. The paper needs more literature survey, especially about the existing defense methods using the manifold assumption. 3. The paper does not have enough (either theoretical or experimental) progress to get accepted, compared to previous methods using the manifold assumption.
[Comments] 1. First of all, use some spell/grammar checker (or ask someone else to proofread) to fix basic grammatical errors. 2. Section 3 is very unclear in general. First, I cannot understand the reason why the Section is needed at all. Manifold-based defense against adversarial example is not a new approach and reviewers know well about the manifold assumption in the adversarial machine learning setting. Section 3 does not introduce anything new more than those reviewers’ understanding, and the reasonings are too crude to be called an “analysis”. Second, the writing is not cohesive enough. Each paragraph is saying some topic, however, the connections between the paragraphs are not very clear, making Section 3 more confusing. Even in a single paragraph, the logical reasonings between sentences are sometimes not provided at all. Third, some of those contents are added for no reason. For example, Figure 1 exists for no reason whereas the figure is not referred at all in the paper. The propositions mentioned in Section 3.3 are vaguely written and not used at all. By having these unnecessary parts, the writing looks to be verbose and overstating. 3. In Section 5, the defense method should be written with more formality. Based on the description given in the paper “dx = p(max)-p(secondmax)”, it is very unclear what each term means. Each probability (the authors did not even say that they are probabilities) must correspond to the output from a softmax layer, but which model provides such a softmax layer output, the target classifier, or is there another classifier prepared for it? How are the described transformations used to get the divergence value? What does the detector do with the divergence? (All of these details should be described in Section 5.) Section 6.2 mentions some thresholding strategies, how did the detector work in Section 6.1, though? When thresholding is used, what is the threshold value used and what is the rationale of the choice of the threshold value? There are so many missing details to understand the method. 4. Section 7 looks to be a conclusion for experiments. This should be moved to Section 6 and Section 7 should be an overall conclusion of the paper. 5. The suggested method is neither creative nor novel, compared to the existing methods utilizing the distance from manifolds. As pointed out, the defense based on the manifold assumption is not a new approach. [1][3][4][6](These papers are only a few representative examples. There are many other papers on this type of defense.) Moreover, the idea of using probability divergence is already proposed by previous work [1] and an effective attack for such detection already exists. [2] (Of course, this paper proposes another probability divergence, but there is no support that this method could be significantly better than the previous work.) 6. The experiment should be done more extensively. It looks like that some transformations were brought from the Raff et al. paper [5] which tested the defense against the adversary as strong as possible. Specifically, Raff et al. considered potential improvements of existing attacks to attack their work then tested the defense performance against the improved attack. However, the paper only uses vanilla implementation in the Cleverhans library (or by the original authors). The authors should have shown that the proposed method is robust against a stronger adversary because adversaries who are aware of the method will not use a simple version of the attack. (At least, those adversaries will try using the attack suggested by Raff et al.) [References]
[1] (Meng & Chen) MagNet: a Two-Pronged Defense Against Adversarial Examples
[2] (Carlini & Wagner) MagNet and “Efficient Defenses Against Adversarial Attacks” are Not Robust to Adversarial Examples
[3] (Samangouei et al.) Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models
[4] (Jiang et al.) To Trust or Not to Trust a Classifier
[5] (Raff et al.) Barrage of Random Transforms for Adversarially Robust Defense
[6] (Dubey et al.) Defense Against Adversarial Images using Web-Scale Nearest-Neighbor Search","['5', '3', '1']",,,4,"['1', '1', '1']",1.0,gold,"['3', '1', '1']",1,silver,"['4', '2', '1']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,2,"the comment identifies a significant issue related to the paper's writing quality which includes grammatical errors and unclear sentences, but it is vague and lacks specificity. it does not provide detailed guidance or examples of the errors, nor does it suggest how the authors can address these problems. therefore, it is barely helpful as it only slightly informs the authors about the problem without empowering them with actionable steps to improve their draft."
"- In figure 5, the y-axis label may use ""Exact Match ratio"" directly.",ARR_2022_113_review,ARR_2022,"The methodology part is a little bit unclear. The author could describe clearly how the depth-first path completion really works using Figure 3. Also, I'm not sure if the ZIP algorithm is proposed by the authors and also confused about how the ZIP algorithm handles multiple sequence cases.
- Figure 2, it is not clear about ""merge target"". If possible, you may use a shorter sentence.
- Line 113 (right column), will the lattice graph size explode? For a larger dataset, it may impossible to just get the lattice graph, am I right? How should you handle that case?
- Algorithm 1 step 4 and 5, you may need to give the detailed steps of *isRecomb* and *doRecomb* in the appendix.
- Line 154 left, ""including that it optimizes for the wrong objective"". Can you clearly state what objective? why the beam search algorithm is wrong? Beam search is a greedy algorithm that can recover the best output with high probability.
- For the ZIP method, one thing unclear to me is how you combine multiple sequences by if they have different lengths of shared suffixes?
- Line 377, is BFSZIP an existing work? If so, you need to cite their work. - In figure 5, the y-axis label may use ""Exact Match ratio"" directly.
- Line 409, could you cite the ""R2"" metric?
- Appendix A, the authors state ""better model score cannot result in better hypothesis"". You'd better state clearly what idea hypothesis you want. "" a near-optimal model score"" this sentence is unclear to me, could you explain in detail?
- In line 906, it is clear from the previous papers that Beam search results lack diversity and increase the beam size does not work. Can you simplify the paragraph?","['5', '5', '5', '4', '5', '1', '3', '5']",5.0,gold,2,"['5', '5', '5', '5', '5', '5', '3', '5']",5.0,gold,"['1', '5', '1', 'X', '5', '5', 'X', 'X']",5,gold,"['5', '5', '4', '4', '5', '5', '3', '5']",5.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '1', '0', '0', '0', '0', '0']",0.0,gold,2,"the comment identifies a potential issue with the y-axis labeling in figure 5 by suggesting an alternative label. however, it lacks clarity on why this change is necessary or beneficial, providing minimal guidance for the authors. the feedback is only slightly beneficial as it does not explain how the suggested label improves understanding or accuracy of the figure."
- Improvements on Multi30k are quite small (< 1 BLEU) and reported over single runs and measuring BLEU scores alone. It would be good to report averages over multiple runs and report some more modern metrics as well like COMET or BLEURT.,ARR_2022_338_review,ARR_2022,"- The unsupervised translation tasks are all quite superficial, taking existing datasets of similar languages (e.g. En-De Multi30k, En-Fr WMT) and editing them to an unsupervised MT corpus.
- Improvements on Multi30k are quite small (< 1 BLEU) and reported over single runs and measuring BLEU scores alone. It would be good to report averages over multiple runs and report some more modern metrics as well like COMET or BLEURT.
- It is initially quite unclear from the writing where the sentence-level representations come from. As they are explicitly modeled, they need supervision from somewhere. The constant comparison to latent variable models and calling these sentence representations latent codes does not add to the clarity of the paper. I hope this will be improved in a revision of the paper.
Some typos: - 001: ""The latent variables"" -> ""Latent variables"" - 154: ""efficiently to compute"" -> ""efficient to compute"" - 299: ""We denote the encoder and decoder for encoding and generating source-language sentences as the source encoder and decoder"" - unclear - 403: ""langauge"" -> ""language""","['5', '5', '5']",5.0,gold,1,"['5', '5', '3']",5.0,silver,"['X', '5', 'X']",X,silver,"['5', '5', '5']",5.0,gold,"['1', '1', '1']",1.0,gold,"['1', '1', '0']",1.0,silver,4,"the comment is mostly helpful as it provides clear and actionable feedback. it identifies specific weaknesses in the reporting of results, such as the reliance on single runs and the limited use of evaluation metrics. it suggests reporting averages over multiple runs and including more modern metrics like comet or bleurt. this feedback is clear and actionable, though it could be refined by providing more detailed guidance on how to implement these suggestions or explaining the benefits of using the additional metrics."
- l111: Please define the bounds for \tau_i^l because it is important for understanding the time-warp function.,NIPS_2017_110,NIPS_2017,"of this work include that it is a not-too-distant variation of prior work (see Schiratti et al, NIPS 2015), the search for hyperparameters for the prior distributions and sampling method do not seem to be performed on a separate test set, the simultion demonstrated that the parameters that are perhaps most critical to the model's application demonstrate the greatest relative error, and the experiments are not described with adequate detail. This last issue is particularly important as the rupture time is what clinicians would be using to determine treatment choices. In the experiments with real data, a fully Bayesian approach would have been helpful to assess the uncertainty associated with the rupture times. Paritcularly, a probabilistic evaluation of the prospective performance is warranted if that is the setting in which the authors imagine it to be most useful. Lastly, the details of the experiment are lacking. In particular, the RECIST score is a categorical score, but the authors evaluate a numerical score, the time scale is not defined in Figure 3a, and no overall statistics are reported in the evaluation, only figures with a select set of examples, and there was no mention of out-of-sample evaluation.
Specific comments:
- l132: Consider introducing the aspects of the specific model that are specific to this example model. For example, it should be clear from the beginning that we are not operating in a setting with infinite subdivisions for \gamma^1 and \gamma^m and that certain parameters are bounded on one side (acceleration and scaling parameters).
- l81-82: Do you mean to write t_R^m or t_R^{m-1} in this unnumbered equation? If it is correct, please define t_R^m. It is used subsequently and it's meaning is unclear.
- l111: Please define the bounds for \tau_i^l because it is important for understanding the time-warp function.
- Throughout, the authors use the term constrains and should change to constraints.
- l124: What is meant by the (*)?
- l134: Do the authors mean m=2?
- l148: known, instead of know
- l156: please define \gamma_0^{***}
- Figure 1: Please specify the meaning of the colors in the caption as well as the text.
- l280: ""Then we made it explicit"" instead of ""Then we have explicit it""","['5', '5', '5']",5.0,gold,4,"['3', '5', '3']",3.0,silver,"['5', 'X', 'X']",X,silver,"['5', '5', '4']",5.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '1']",0.0,silver,4,"the comment addresses a specific issue by requesting a definition for the bounds of \tau_i^l, which is crucial for understanding an important concept in the document, the time-warp function. this feedback is clear and actionable as it identifies an area that requires clarification, thereby aiding the authors. however, the comment could be improved by suggesting where to incorporate this definition or by specifying why the bounds are essential in the context of the authors' work, which would make it comprehensive and potentially lead to a higher score."
- Line 21-27 - the authors could have avoided this complicated structure for two simple sentences. Line 41 - Johnson et. al has SOTA on English-French and German-English. Line 77-79 there is no evidence provided as to why combination of multiple languages increases complexity. Please retract this statement or provide more evidence. Evidence in literature seems to suggest the opposite. Line 416-420 - The two lines here are repeated again. They were first mentioned in the previous paragraph. Line 577 - Figure 2 not 3!,ACL_2017_779_review,ACL_2017,"There were many sentences in the abstract and in other places in the paper where the authors stuff too much information into a single sentence. This could be avoided. One can always use an extra sentence to be more clear.
There could have been a section where the actual method used could be explained in a more detailed. This explanation is glossed over in the paper. It's non-trivial to guess the idea from reading the sections alone.
During test time, you need the source-pivot corpus as well. This is a major disadvantage of this approach. This is played down - in fact it's not mentioned at all. I could strongly encourage the authors to mention this and comment on it. - General Discussion: This paper uses knowledge distillation to improve zero-resource translation.
The techniques used in this paper are very similar to the one proposed in Yoon Kim et. al. The innovative part is that they use it for doing zero-resource translation. They compare against other prominent works in the field. Their approach also eliminates the need to do double decoding.
Detailed comments: - Line 21-27 - the authors could have avoided this complicated structure for two simple sentences.
Line 41 - Johnson et. al has SOTA on English-French and German-English.
Line 77-79 there is no evidence provided as to why combination of multiple languages increases complexity. Please retract this statement or provide more evidence. Evidence in literature seems to suggest the opposite.
Line 416-420 - The two lines here are repeated again. They were first mentioned in the previous paragraph.
Line 577 - Figure 2 not 3!","['5', '5', '5']",5.0,gold,1,"['5', '5', '5']",5.0,gold,"['5', '5', '1']",5,silver,"['5', '5', '4']",5.0,silver,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,4,"the review point provides several specific observations about the document, suggesting improvements and pointing out weaknesses, such as sentence structure simplification, the need for evidence regarding claims about language complexity, and corrections for repetition and figure mislabeling. these comments are clear and actionable, helping the authors address specific areas for improvement. however, some comments, like the mention of johnson et al., are less clearly actionable without further explanation or context, preventing this review from being fully comprehensive and therefore earning a score of 4 instead of 5."
"- There were too many missing details (for example, what is the distribution of people with ‘free off speech’ attitudes? What is the correlation of the chosen scale item in the breadth-of-posts study?). On a minor note, many important points are relegated to the appendix.",ARR_2022_60_review,ARR_2022,"- Underdefined and conflation of concepts - Several important details missing - Lack of clarity in how datasets were curated prevents one from assessing their validity - Too many results which are not fully justified or explained
This is a very important, interesting, and valuable paper with many positives. First and foremost, annotators’ backgrounds are an important factor and should be taken into consideration when designing datasets for hate speech, toxicity, or related phenomena. The paper not only accounts for demographic variables as done in previous work but other attitudinal covariates like attitude towards free speech that are well-chosen. The paper presents two well-thought out experiments and presents results in a clear manner which contain several important findings.
It is precisely because of the great potential and impact of this paper, I think the current manuscript requires more consideration and fine-tuning before it can reach its final stage. At this point, there seems to be a lack of important details that prevent me from fully gauging the paper’s findings and claims. Generally: - There were too many missing details (for example, what is the distribution of people with ‘free off speech’ attitudes? What is the correlation of the chosen scale item in the breadth-of-posts study?). On a minor note, many important points are relegated to the appendix.
- Certain researcher choices and experiment design choices were not justified (for example, why were these particular scales used?)
- The explanation of the creation of the breadth-of-posts was confusing. How accurate was the classification of AAE dialect and vulgarity? - The toxicity experiment was intriguing but there was too little space to be meaningful.
More concretely, - With regard to terminology and concepts, toxicity and hate speech may be related but are not the same thing. The instructions to the annotators seem to conflate both. The paper also doesn’t present a concrete definition of either. While it might seem redundant or trivial, the wording to annotators plays an important role and can confound the results presented here.
- Why were the particular scales chosen for obtaining attitudes? Particularly, for empathy there are several scale items [1], so why choose the Interpersonal Reactivity Index?
- What was the distribution of the annotator’s background with respect to the attitudes? For example, if there are too few ‘free of speech’ annotators, then the results shown in Table 3, 4, etc are underpowered. - What were the correlations of the chosen attitudinal scale item for the breadth-of-posts study with the toxicity in the breadth-of-workers study?
- How accurate are the automated classification in the breadth-of-posts experiment, i.e., how well does the states technique differentiate identity vs non-identity vulgarity or AAE language for that particular dataset. Particularly, how can it be ascertained whether the n-word was used as a reclaimed slur or not? - In that line, Section 6 discusses perceptions of vulgarity, but there are too many confounds here. Using b*tch in a sentence can be an indication of vulgarity and toxicity (due to sexism).
- In my opinion, the perspective API experiment was interesting but rather shallow. My suggestion would be to follow up on it in more detail in a new paper rather than include it in this one. The newly created space could be used to enter the missing details mentioned in the review. - Finally, given that the paper notes that MTurk tends to be predominantly liberal and the authors (commendably) took several steps to ensure greater participation from conservatives, I was wondering if ‘typical’ hate speech datasets are annotated by more homogenous annotators compared to the sample in this paper. What could be the implications of this? Do this paper's findings then hold for existing hate speech datasets?
Besides these, I also note some ethical issues in the ‘Ethical Concerns’ section. To conclude, while my rating might seem quite harsh, I believe this work has great potential and I hope to see it enriched with the required experimental details.
References: [1] Gerdes, Karen E., Cynthia A. Lietz, and Elizabeth A. Segal. "" Measuring empathy in the 21st century: Development of an empathy index rooted in social cognitive neuroscience and social justice."" Social Work Research 35, no. 2 (2011): 83-93.","['4', '5', '4']",4.0,silver,1,"['4', '1', '3']",,,"['3', '1', 'X']",,,"['2', '5', '4']",,,"['0', '1', '1']",1.0,silver,"['0', '1', '0']",0.0,silver,4,"the comment mostly helps the authors by pointing out specific areas where details are missing, allowing them to understand what content needs to be included or expanded. it gives clear examples, such as the distribution of attitudes and correlations in their study, which can guide the authors in enhancing their draft. the mention of relegating important points to the appendix also highlights an area for structural improvement. however, the comment could be more helpful if it elaborated further on how to incorporate these missing details effectively in the main body of the document or provided suggestions on making content adjustments. therefore, it is mostly helpful but not fully comprehensive for achieving the highest score."
"3. Dependent on the training data - I'm unsure if 44k dialogues is sufficient to capture a wide range of user traits and personalities across different content topics. LLMs are typically trained on trillions of tokens, I do not see how 44k dialogues can capture the combinations of personalities and topics. In theory, this dataset also needs to be massive to cover varied domains.",eCXfUq3RDf,EMNLP_2023,"1. Very limited reproducibility - Unless the authors release their training code, dialogue dataset, as well as model checkpoints, I find it very challenging to reproduce any of the claims in this paper. I encourage the authors to attach their code and datasets via anonymous repositories in the paper submission so that reviewers may verify the claims and try out the model for themselves.
2. Very high model complexity - The proposed paper employs a mathematically and computationally complex approach as compared to the textual input method. Does the proposed method outperform sending textual inputs to a large foundation model such as LLAMA or ChatGPT? The training complexity seems too high for any practical deployment of this model.
3. Dependent on the training data - I'm unsure if 44k dialogues is sufficient to capture a wide range of user traits and personalities across different content topics. LLMs are typically trained on trillions of tokens, I do not see how 44k dialogues can capture the combinations of personalities and topics. In theory, this dataset also needs to be massive to cover varied domains.
4. The paper is hard to read and often unintuitive. The mathematical complexity must be simplified and replaced with more intuitive design and modeling choice explanations so that readers may grasp core ideas faster.","['2', '4', '1']",,,4,"['5', '5', '3']",5.0,silver,"['4', '4', '5']",4,silver,"['3', '5', '3']",3.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the review point identifies a potential weakness in the limited size of the training data and its implications for capturing a diverse range of user traits and content topics. however, it lacks detailed guidance or suggestions on how the authors can address this issue. it raises a valid concern but does not offer actionable steps or solutions, making it somewhat helpful for the authors to consider but not fully comprehensive or impactful for improving their draft."
"- Although the related work is comprehensive, Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts.",NIPS_2017_337,NIPS_2017,"of the manuscript stem from the restrictive---but acceptable---assumptions made throughout the analysis in order to make it tractable. The most important one is that the analysis considers the impact of data poisoning on the training loss in lieu of the test loss. This simplification is clearly acknowledged in the writing at line 102 and defended in Appendix B. Another related assumption is made at line 121: the parameter space is assumed to be an l2-ball of radius rho.
The paper is well written. Here are some minor comments:
- The appendices are well connected to the main body, this is very much appreciated.
- Figure 2 and 3 are hard to read on paper when printed in black-and-white.
- There is a typo on line 237.
- Although the related work is comprehensive, Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts.
- The use of the terminology ""certificate"" in some contexts (for instance at line 267) might be misinterpreted, due to its strong meaning in complexity theory.","['2', '4', '4']",4.0,silver,4,"['2', '5', '5']",5.0,silver,"['1', '2', 'X']",,,"['2', '3', '4']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,4,"the review comment is mostly helpful as it provides clear and actionable feedback by suggesting that section 6 could be improved by comparing the perspective taken in the manuscript with prior efforts. this guidance can help the authors enhance their manuscript by providing a more thorough analysis. however, the comment could be more comprehensive by offering specific examples or methods to compare perspectives, which would make it even more actionable and impactful."
3. It will be nice to see some examples of the system on actual texts (vs. other components & models).,ARR_2022_98_review,ARR_2022,"1. Human evaluations were not performed. Given the weaknesses of SARI (Vásquez-Rodríguez et al. 2021) and FKGL (Tanprasert and Kauchak, 2021), the lack of human evaluations severely limits the potential impact of the results, combined with the variability in the results on different datasets.
2. While the authors explain the need to include text generation models into the framework of (Kumar et al., 2020), it is not clear as to why only the delete operation was retained from the framework, which used multiple edit operations (reordering, deletion, lexical simplification, etc.). Further, it is not clear how including those other operations will affect the quality and performance of the system.
3. ( minor) It is unclear how the authors arrived at the different components of the ""scoring function,"" nor is it clear how they arrived at the different threshold values/ranges.
4. Finally, one might wonder that the performance gains on Newsela are due to a domain effect, given that the system was explicitly tuned for deletion operations (that abound in Newsela) and that performance is much lower on the ASSET test corpus. It is unclear how the system would generalize to new datasets with varying levels of complexity, and peripheral content.
1. Is there any reason why 'Gold Reference' was not reported for Newsela? It makes it hard to assess the performance of the existing system. 2. Similarly, is there a reason why the effect of linguistic acceptability was not analyzed (Table 3 and Section 4.6)?
3. It will be nice to see some examples of the system on actual texts (vs. other components & models).
4. What were the final thresholds that were used for the results? It will also be good for reproducibility if the authors can share the full set of hyperparameters as well.","['3', '2', '4', '4', '5', '1', '1', '4']",4.0,gold,2,"['1', '2', '2', '5', '3', '1', '1', '3']",1.0,gold,"['1', '2', 'X', 'X', '2', '1', '1', '2']",1,gold,"['2', '2', '3', '5', '3', '1', '1', '3']",3.0,gold,"['1', '1', '1', '1', '1', '0', '1', '1']",1.0,gold,"['0', '1', '0', '0', '0', '0', '0']",0.0,gold,3,"the comment suggests an area for improvement by recommending the inclusion of examples of the system on actual texts. however, it lacks specificity and depth, as it does not clearly explain why these examples would be beneficial or how they should be integrated into the draft. while the suggestion can help the authors gain some insights, it does not provide comprehensive guidance on how to implement the feedback or the potential impact of doing so."
"3. The authors conduct comprehensive experiments to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation.",NIPS_2022_2373,NIPS_2022,"weakness in He et al., and proposes a more invisible watermarking algorithm, making their method more appealing to the community. 2. Instead of using a heuristic search, the authors elegantly cast the watermark search issue into an optimization problem and provide rigorous proof. 3. The authors conduct comprehensive experiments to validate the efficacy of CATER in various settings, including an architectural mismatch between the victim and the imitation model and cross-domain imitation. 4. This work theoretically proves that CATER is resilient to statistical reverse-engineering, which is also verified by their experiments. In addition, they show that CATER can defend against ONION, an effective approach for backdoor removal.
Weakness: 1. The authors assume that all training data are from the API response, but what if the adversary only uses the part of the API response? 2. Figure 5 is hard to comprehend. I would like to see more details about the two baselines presented in Figure 5.
The authors only study CATER for the English-centric datasets. However, as we know, the widespread text generation APIs are for translation, which supports multiple languages. Probably, the authors could extend CATER to other languages in the future.","['1', '1', '1']",1.0,gold,4,"['1', '1', '3']",1.0,silver,"['X', 'X', 'X']",X,gold,"['1', '1', '3']",1.0,silver,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,1,"the review point is not helpful as it does not identify any weaknesses or areas for improvement. it simply states that comprehensive experiments were conducted, which is more of a summary rather than evaluative or constructive feedback. there is no actionable guidance or suggestions provided to help the authors improve their draft."
"• I think epoch-wise analysis, especially for finite sum settings, could help provide insights into behaviors of optimization algorithms. For instance, it may enable to further investigate effect of batch size or different sampling strategies with respect to progress of the algorithms after every full pass of data. This may also help with comparative analysis of deterministic and stochastic methods.",ICLR_2021_1213,ICLR_2021,"weakness of the paper. Then, I present my additional comments which are related to specific expressions in the main text, proof steps in the appendix etc. I would appreciate it very much if authors could address my questions/concerns under “Additional Comments” as well, since they affect my assessment and understanding of the paper; consequently my score for the paper. Summary:
• The paper focuses on convergence of two newly-proposed versions of AdaGrad, namely AdaGrad-window and AdaGrad-truncation, for finite sum setting where each component is smooth and possibly nonconvex.
• The authors prove convergence rate with respect to number of epochs T, where in each epoch one full pass over the data is performed with respect to well-known “random shuffling” sampling strategy.
• Specifically, AdaGrad-window is shown to achieve O ~ ( T − 1 / 2 )
rate of convergence, whereas AdaGrad-truncation attains ( T − 1 / 2 )
convergence, under component-wise smoothness and bounded gradients assumptions. Additionally, authors introduce a new condition/assumption called consistency ratio which is an essential element of their analysis.
• The paper explains the proposed modification to AdaGrad and provide their intuition for such adjustments. Then, the main results are presented followed by a proof sketch, which demonstrates the main steps of the theoretical approach.
• In order to evaluate the practical performance of the modified adaptive methods in a comparative fashion, two set of experiments were provided: training logistic regression model on MNIST dataset and Resnet-18 model on CIFAR-10 dataset. In these experiments; SGD, SGD with random shuffling, AdaGrad and AdaGrad-window were compared. Additionally, authors plot the behavior of their proposed condition “consistency ratio” over epochs. Strengths:
• I think epoch-wise analysis, especially for finite sum settings, could help provide insights into behaviors of optimization algorithms. For instance, it may enable to further investigate effect of batch size or different sampling strategies with respect to progress of the algorithms after every full pass of data. This may also help with comparative analysis of deterministic and stochastic methods.
• I have checked the proof of Theorem 1 in details and had a less detailed look at Theorems 2 and 3. I appreciate some of the technically rigorous sections of the analysis as the authors bring together analytical tools from different resources and re-prove certain results with respect to their adjustments.
• Performance comparison in the paper is rather simple but the authors try to provide a perspective of their consistency condition through numerical evidence. It gives some rough idea about how to interpret this condition.
• Main text is written in a clear; authors highlight their modification to AdaGrad and also highlight what their new “consistency condition” is. Proposed contributions of the paper are stated clearly although I do not totally agree with certain claims. One of the main theorems has a proof sketch which gives an overall idea about authors’ approach to proving the results. Weaknesses:
• Although numerically the paper provides an insight into the consistency condition, it is not verifiable ahead of time. One needs to run a simulation to get some idea about this condition, although it still wouldn’t verify the correctness. Since authors did not provide any theoretical motivation for their condition, I am not fully convinced out this assumption. For instance, authors could argue about a specific problem setting in which this condition holds.
• Theorem 3 (Adagrad-truncation) sets the stepsize depends on knowledge of r
. I couldn’t figure out how it is possible to compute the value r
ahead of time. Therefore, I do not think this selection is practically applicable. Although I appreciate the theoretical rigor that goes into proving Theorem 3, I believe the concerns about computing r
weakens the importance of this result. If I am missing out some important point, I would like to kindly ask the authors to clarify it for me.
• The related work which is listed in Table 1, within the group “Adaptive Gradient Methods” prove \emph{iteration-wise} convergence rates for variants of Adam and AdaGrad, which I would call the usual practice. This paper argues about \emph{epoch-wise} convergence. The authors claim improvement over those prior papers although the convergence rate quantifications are not based on the same grounds. All of those methods consider the more general expectation minimization setting. I would suggest the authors to make this distinction clear and highlight iteration complexities of such methods while comparing previous results with theirs. In my opinion, total complexity comparison is more important that rate comparison for the setting that this paper considers.
• As a follow up to the previous comment, the related work could have highlighted related results in finite sum setting. Total complexity comparisons with respect to finite sum setting is also important. There exists results for finite-sum nonconvex optimization with variance reduction, e.g., Stochastic Variance Reduction for Nonconvex Optimization, 2016, Reddi et. al. I believe it is important to comparatively evaluate the results of this paper with that of such prior work.
• Numerically, authors only compare against AdaGrad and SGD. I would say this paper is a rather theory paper, but it claims rate improvements, for which I previously stated my doubts. Therefore, I would expect comparisons against other methods as well, which is of interest to ICLR community in my opinion.
• This is a minor comment that should be easy to address. For ICLR, supplementary material is not mandatory to check, however, this is a rather theoretical paper and the correctness/clarity of proofs is important. I would say authors could have explained some of the steps of their proof in a more open way. There are some crucial expressions which were obtained without enough explanations. Please refer to my additional comments in the following part.
Additional Comments:
• I haven’t seen the definition that x t , m + 1 = x t + 1 , 1
in the main text. It appears in the supplements. Could you please highlight this in the main text as it is important for indexing in the analysis?
• Second bullet point of your contributions claim that “[consistency] condition is easy to verify”. I do not agree with this as I cannot see how someone could guarantee/compute the value r
ahead of time or even after observing any sequence of gradients. Could you please clearly define what verification means in this context?
• In Assumption A3, I understand that G t e i = g t , i and G t e = ∑ i = 1 m g t , i
. I believe the existing notation makes it complicated for the reader to understand the implications of this condition.
• In the paragraph right above Section 4.2, authors state that presence of second moments, V t , i
enables adaptive methods to have improved rates of SGD through Lemma 3. Could the authors please explain this in details?
• In Corollary 1, authors state that “the computational complexity is nearly O ( m 5 / 2 n d 2 ϵ − 2 ) ~
”. A similar statement exists in Corollary 2. Could you please explain what “nearly” means in this context?
• In Lemma 8 in the supplements, a a T and b b T
in the main expression of the lemma are rank-1 matrices. This lemma has been used in the proof of Lemma 4. As far as I understood, Lemma 8 is used in such a way that a a T or b b T
correspond to something like g t , j 2 – g t − 1 , j 2
. I am not sure if this construction fits into Lemma 8 because, for instance, the expression g t , j 2 – g t − 1 , j 2
is difference of two rank-1 matrices, which could have rank \leq 2. Hence, there may not exist some vector a
such that a a T = g t , j 2 – g t − 1 , j 2
, hence Lemma 8 may not be applied. If I am mistaken in my judgment I am 100% open for a discussion with the authors.
• In the supplements, in section “A.1.7 PROOF OF MAIN THEOREM 1”, in the expression following the first line, I didn’t understand how you obtained the last upper bound to ∇ f ( x t , i )
. Could you please explain how this is obtained? Score:
I would like to vote for rejecting the paper. I praise the analytically rigorous proofs for the main theorems and the use of a range of tools for proving the key lemmas. Epoch-wise analysis for stochastic methods could provide insight into behavior of algorithms, especially with respect to real-life experimental setting. However, I have some concerns:
I am not convinced about the importance of consistency ratio and that it is a verifiable condition.
Related work in Table 1 has iteration-wise convergence in the general expectation-minimization setting whereas this paper considers finite sum structure with epoch-wise convergence rates. The comparison with related work is not sufficient/convincing in this perspective.
(Minor) I would suggest the authors to have a more comprehensive experimental study with comparisons against multiple adaptive/stochastic optimizers. More experimental insight might be better for demonstrating consistency ratio.
Overall, due to the reasons and concerns stated in my review, I vote for rejecting this paper. I am open for further discussions with the authors regarding my comments and their future clarifications.
======================================= Post-Discussions =======================================
I would like to thank the authors for their clarifications. After exchanging several responses with the authors and regarding other reviews, I decide to keep my score.
Although the authors come up with a more meaningful assumption, i.e., SGC, compared to their initial condition, I am not fully convinced about the contributions with respect to prior work: SGC assumption is a major factor in the improved rates and it is a very restrictive assumption to make in practice.
Although this paper proposes theoretical contributions regarding adaptive gradient methods, the experiments could have been a bit more detailed. I am not sure whether the experimental setup fully displays improvements of the proposed variants of AdaGrad.","['2', '5', '5', '5']",5.0,gold,3,"['3', '3', '5', '3']",3.0,gold,"['4', '4', '4', 'X']",4,gold,"['3', '4', '5', '4']",4.0,silver,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,4,"the comment is mostly helpful as it suggests the potential benefit of conducting an epoch-wise analysis, especially in the context of finite sum settings. this feedback identifies a specific area for improvement and provides a rationale for why this analysis could be insightful, such as investigating the effect of batch size and sampling strategies. additionally, it mentions a comparative analysis between deterministic and stochastic methods, offering a clear direction for authors to explore. however, the comment could be further enhanced with more detailed guidance or examples, making it fully comprehensive and impactful."
"* The analysis on BRP-NAS is also somewhat barebones: it only compares against 3 basic alternatives and ignores some other NAS (e.g. super-net/one-shot approaches, etc...).",NIPS_2020_878,NIPS_2020,"* The GCN-based predictor and experiments don't have open-sourced code (not mentioned in the main paper or supplement), however the authors do provide detailed descriptions. * Some correctness issues (see next section) * The paper presents 2 important NAS objectives: latency optimization and accuracy optimization. However, the BRP-NAS (section 4) seems out-of-place since the rest of the paper deals with latency prediction. It nearly feels like BRP-NAS could be a separate paper, or Section 3 was used only to suggest using GCN (in this case, why not directly start with accuracy prediction with GCN?). * The analysis on BRP-NAS is also somewhat barebones: it only compares against 3 basic alternatives and ignores some other NAS (e.g. super-net/one-shot approaches, etc...). * Unclear if code will be released, as the GCN implementation may be hard to reproduce without original code (though the author's descriptions are fairly detailed and there is more information in the supplement).","['3', '4', '1']",,,4,"['3', '5', '5']",5.0,silver,"['3', '4', '4']",4,silver,"['2', '4', '3']",,,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the comment identifies a weakness in the analysis by noting that it only compares against a limited number of basic alternatives and overlooks certain nas approaches. however, it lacks specifics on which additional baselines or nas methods should be included, and it does not provide detailed guidance on how to improve the analysis. while the authors can gain insights on the need to broaden their comparisons, the feedback could be more comprehensive and actionable."
"- The relatively poor performance on nouns makes me uneasy. While I can expect TWSI to do really well due to its nature, the fact that the oracle GAP for PPDBClus is higher than most clustering approaches is disconcerting, and I would like to understand the gap better. This also directly contradicts the claim that the clustering approach is generalizable to all parts of speech (124-126), since the performance clearly isn't uniform.",ACL_2017_614_review,ACL_2017,"- I don't understand effectiveness of the multi-view clustering approach.
Almost all across the board, the paraphrase similarity view does significantly better than other views and their combination. What, then, do we learn about the usefulness of the other views? There is one empirical example of how the different views help in clustering paraphrases of the word 'slip', but there is no further analysis about how the different clustering techniques differ, except on the task directly. Without a more detailed analysis of differences and similarities between these views, it is hard to draw solid conclusions about the different views. - The paper is not fully clear on a first read. Specifically, it is not immediately clear how the sections connect to each other, reading more like disjoint pieces of work. For instance, I did not understand the connections between section 2.1 and section 4.3, so adding forward/backward pointer references to sections should be useful in clearing up things. Relatedly, the multi-view clustering section (3.1) needs editing, since the subsections seem to be out of order, and citations seem to be missing (lines 392 and 393).
- The relatively poor performance on nouns makes me uneasy. While I can expect TWSI to do really well due to its nature, the fact that the oracle GAP for PPDBClus is higher than most clustering approaches is disconcerting, and I would like to understand the gap better. This also directly contradicts the claim that the clustering approach is generalizable to all parts of speech (124-126), since the performance clearly isn't uniform.
- General Discussion: The paper is mostly straightforward in terms of techniques used and experiments. Even then, the authors show clear gains on the lexsub task by their two-pronged approach, with potentially more to be gained by using stronger WSD algorithms.
Some additional questions for the authors : - Lines 221-222 : Why do you add hypernyms/hyponyms?
- Lines 367-368 : Why does X^{P} need to be symmetric?
- Lines 387-389 : The weighting scheme seems kind of arbitrary. Was this indeed arbitrary or is this a principled choice?
- Is the high performance of SubstClus^{P} ascribable to the fact that the number of clusters was tuned based on this view? Would tuning the number of clusters based on other matrices affect the results and the conclusions?
- What other related tasks could this approach possibly generalize to? Or is it only specific to lexsub?","['1', '5', '1', '2', '5', '2', '1', '2']",1.0,gold,2,"['5', '5', '4', '5', '5', '3', '5', '5']",5.0,gold,"['2', '5', '2', 'X', '5', '2', 'X', '5']",2,gold,"['2', '5', '3', '3', '5', '2', '1', '3']",3.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0', '0', '0', '0']",0.0,gold,3,"the comment identifies a specific weakness relating to the performance of nouns and raises concerns about the generalizability of the clustering approach. however, it lacks depth in providing concrete suggestions or guiding the authors on how to address the identified issues. while it highlights contradictions in the claims made by the authors, it does not offer detailed guidance on how to resolve these contradictions or improve the draft, making it somewhat helpful but not fully comprehensive."
"- L.490: “we take the embedding of the first subword token as the verb embedding.” It is also quite common in cases like that to average over the subword representations, which is done e.g. by [Hewitt and Manning (2019, footnote 4)](https://aclanthology.org/N19-1419.pdf).",ARR_2022_161_review,ARR_2022,"The amount of background provided can be reduced, and consists of quite a few detailed descriptions of topics and experiments that are not directly related to the experiments of the paper (e.g. the Priming paragraph at L210, Novel verbs paragraph at L224). The space that is currently occupied by this extensive background could be used more efficiently, and cutting it down a bit opens up space for additional experiments. The ‘Jabberwocky constructions’ experiment is quite prone to several potential confounds that need to be explored in more detail in order to ensure that the current set of results truly hints at ‘the neural reality of argument structure constructions’. The fact that the contextualised embeddings of verbs in the same syntactic configuration is highly similar isn’t that surprising in itself (as is noted by the authors as well). The authors decided to drop the ‘priming’ component of the original paper in order to adapt the experiment to LMs, but there are other options that can be explored to align the setup more closely to the original (see section below for some ideas).
### Comments / Questions - Could the results of the Sentence Sorting be driven by the fact that sentence embeddings are obtained by averaging over word embeddings? It seems that this procedure would be quite prone to simply cluster based on features stemming from individual tokens, instead of a more general abstract signal. I could imagine that in a BERT-like architecture the representation at the [CLS] position might serve as a sentence representation as well.
- Alternatively, would it be possible to set up the sentence sorting experiment in such a way that the lexical overlap in between sentences is limited? This is common in structural priming experiments as well, and models are known to rely heavily on lexical heuristics. ,
- Did you consider different measures of similarity in the Jabberwocky experiment? Euclidean distance might not be the most perfect measure for expressing similarity, and I would suggest looking into alternatives as well, like cosine similarity. - A bit pedantic, but Jabberwocky words are non-existing nonce words, whereas the setup that the authors arrived at is only semantically nonsensical, yet still made up of existing words (a la ‘Colorless green ideas’). Referring to them as Jabberwocky (L.458) would give the impression of actually using nonce words.
- How many ASCs have been argued to exist (within English)? Is there a reason why the 4 constructions used in Case Study 1 (_transitive, ditransitive, caused-motion, resultative_; L.165), are slightly different from Case Study 2 (_ditransitive, resultative, caused-motion, removal_; Table 2)?
--- ### Suggestions: - L.490: “we take the embedding of the first subword token as the verb embedding.” It is also quite common in cases like that to average over the subword representations, which is done e.g. by [Hewitt and Manning (2019, footnote 4)](https://aclanthology.org/N19-1419.pdf).
- I suggest not phrasing the Jabberwocky experiment as “probing” (L.444 ‘method to probe LMs’, L.465 ‘probing strategy’, etc.), given the connotation this term has with training small classifiers on top of a model’s hidden state representations.
- Could the ‘priming’ aspect of Johnson and Goldberg (2013) in the Jabberwocky experiment perhaps be emulated more closely by framing it as a “Targeted Syntactic Evaluation” task (akin to Marvin & Linzen (2018), a.o.). In the context of priming, a similar setup has recently been utilised by [Sinclair et al. (2021)](https://arxiv.org/pdf/2109.14989.pdf). One could compare the probability of _P(gave | She traded her the epicenter. He)_ to that of _P(gave | He cut it seasonal. She)_, and likewise for the other 2 constructions. This way you wouldn’t run into the confounding issues that stem from using the contextualisation of ‘gave’. - An additional experiment that might be interesting to explore is by probing for construction type across layers at the position of the verb. In the ‘Jabberwocky’ setup one would expect that at the word embedding level construction information can’t be present yet, but as it is contextualised more and more in each layer the ASC information is likely to increase gradually. Would also be interesting than to see how the curve of a jabberwocky verb compares to that of a sensical/prototypical verb (like _gave_): there is probably _some_ degree of argument structure already encoded in the word embedding there (as a lexicalist would argue), so I would expect probing performance for such verbs to be much higher at lower levels already. - Adding to the previous point: probing in itself would not even be necessary to gain insight into the layerwise contextualisation; some of the current experiments could be conducted in such a fashion as well.
--- ### Typos/Style: Very well written paper, no remarks here.","['1', '1', '4', '2']",1.0,silver,3,"['2', '4', '5', '5']",5.0,silver,"['5', '5', '5', '5']",5,gold,"['2', '3', '4', '5']",,,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,3,"the review point identifies an alternative approach to taking the embedding of the first subword token, which could be an area of improvement for the authors. it references an existing method by another paper, providing a source for the authors to explore. however, the comment is somewhat helpful because it lacks detailed guidance on how implementing the suggested approach (averaging over subword representations) would impact their work or improve their draft. the feedback could be expanded by explaining the potential benefits or implications of considering the alternative method, making it more actionable and beneficial for the authors."
"1. Although these tensor networks can be used to represent PMF of discrete variables. How these results are useful to machine learning algorithms or analyze the algorithm is not clear. Hence, the significance of this paper is poor.",NIPS_2019_134,NIPS_2019,"Weakness: 1. Although these tensor networks can be used to represent PMF of discrete variables. How these results are useful to machine learning algorithms or analyze the algorithm is not clear. Hence, the significance of this paper is poor. 2. The two experiments are all based on very small dataset either generated or realistic data. The evaluation is performed on KL-divergence or NLL, which only show how good the model can fit the data, rather than generalization performance. How these results are useful for machine learning? In addition, MPS, BM, LPS are quite similar in the structure. There are many well known tensor models, CP, Tucker, Hirachical Tucker are not compared. There are also more complicated models like MERA, PEPS. I have read the authors' rebuttal, they addressed some of questions well. But the generalization is not considered, thus it becomes a standard non-negative tensor factorization problem on the PMF data. Hence, I will remain the original score.","['2', '3', '1', '2']",2.0,silver,3,"['5', '3', '1', '4']",,,"['3', '2', '1', '1']",1,silver,"['2', '3', '1', '2']",2.0,silver,"['1', '1', '1', '0']",1.0,gold,"['1', '0', '0', '1']",1.0,silver,2,"the review point acknowledges a potential issue regarding the unclear significance of the paper but is vague and lacks specific guidance on how the authors could address this concern. while it identifies an area for improvement, it does not provide detailed suggestions or insights that would guide the authors in clarifying the significance of their results for machine learning algorithms. therefore, it is only slightly beneficial for authors looking to improve their draft."
"- Using integrated gradients to measure the attribution has been studied in existing papers. The paper also proposes post-processing steps to filter out the “false-positive” neurons, however, the paper doesn’t show how important these post-processing steps are. I think an ablation study may be needed.",ARR_2022_82_review,ARR_2022,"- In the “Updating Facts” section, although the results seem to show that modifying the neurons using the word embeddings is effective, the paper lacks a discussion on this. It is not intuitive to me that there is a connection between a neuron at a middle layer and the word embeddings (which are used at the input layer). - Using integrated gradients to measure the attribution has been studied in existing papers. The paper also proposes post-processing steps to filter out the “false-positive” neurons, however, the paper doesn’t show how important these post-processing steps are. I think an ablation study may be needed.
- The paper lacks details of experimental settings. For example, how are those hyperparameters ($t$, $p$, $\lambda_1$, etc.) tuned? In table 5, why do “other relations” have a very different scale of perplexity compared to “erased relation” before erasing? Are “other relations” randomly selected?
- The baseline method (i.e., using activation values as the attribution score) is widely used in previous studies. Although the paper empirically shows that the baseline is not as effective as the proposed method, - I expect more discussion on why using activation values is not a good idea.
- One limitation of this study is that the paper only focuses on single-word cloze queries (as discussed in the paper).
- Figure 3: The illustration is not clear to me. Why are there two “40%” in the figure?
- I was confused that the paper targets single-token cloze queries or multi-token ones. I did not see a clear clarification until reading the conclusion.","['2', '5', '4', '5', '1', '3', '1', '3']",5.0,silver,2,"['2', '5', '4', '5', '1', '2', '1', '2']",2.0,gold,"['2', '5', '1', '3', '1', 'X', '1', '2']",1,gold,"['3', '5', '2', '4', '1', '4', '1', '1']",1.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['0', '0', '0', '0', '0', '0', '0']",0.0,gold,4,"the review point is mostly helpful as it clearly identifies a specific weakness in the manuscript: the lack of demonstration or evidence of the importance of the proposed post-processing steps for filtering out 'false-positive' neurons. the reviewer suggests an actionable and concrete method to address this weakness by recommending an ablation study. this guidance provides a clear path for the authors to enhance their draft. however, the comment could be refined by including more details on how the ablation study should be designed or what aspects should be focused on, which would make the feedback fully comprehensive and push it to a score of 5."
"- Although the method is presented nicely and the experiments are rather good and complete, a bit of analysis on what the model does, which can be extremely interesting, is missing (check the feedback/suggestions).",NIPS_2020_1817,NIPS_2020,"There are a few points that are not clear from the paper, which I list below: - As far as I understood in the clustered attention (not the improved one), the value of the i-th query becomes the value of the centroid of the cluster that the query belongs to. So after one round of applying the clustered attention, we have a set C distinct values in N nodes. I wonder what is the implication of this for the next round of the clustered attention, because there is no way to have two nodes that were in the same cluster in the previous round to be in different clusters in the next round (as their values will be the same after round 1) and the only change in the clustering that makes sense is merging clusters (which is not the case as apparently the number of clusters stays the same). Isn’t this too restrictive? What if the initial clustering is not good, then the model has no chance to recover? If the number of clusters stays the same, does the clustering in the layer after layer 1 does anything different than the clustering in the layer 1 (if not they're removable)? - It’s a bit unclear if LSH-X is the Reformer, or a simpler version of the reformer (LSH Transformer). The authors mentioned that the Reformer can’t be used in a setup with heterogeneous queries and keys. First of all, I think it shouldn't be that hard to modify Reformer to support this case. Besides, authors don’t have any task in that setup to see how well the clustered attention does when the clustered queries are not the projections of the inputs that the keys are projected from. - The experiments that are done in the setup that the model has to deal with long sequences is limited to a single modality. Would be nice to have the model evaluated on large inputs in vision/text/algorithmic tasks as well. - Although the method is presented nicely and the experiments are rather good and complete, a bit of analysis on what the model does, which can be extremely interesting, is missing (check the feedback/suggestions). - The authors only consider vanilla transformer and (I think an incomplete version of) Reformer, while there are obvious baselines, e.g. Longformer, sparse transformer, or even Local attention (check the feedback/suggestions).","['2', '3', '3']",3.0,silver,4,"['3', '2', '3']",3.0,silver,"['2', '1', 'X']",,,"['2', '2', '3']",2.0,silver,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,3,"the review point identifies a weakness in the draft regarding the lack of analysis on what the model does, which is an area that could be further explored. however, the feedback is somewhat vague, as it does not specify what kind of analysis would be beneficial or provide detailed suggestions on how to incorporate this missing element. this makes the comment somewhat helpful, as the authors can gain an insight but would need more detailed guidance to address the identified issue effectively."
"2). The proposed method looks stronger at high bitrate but close to the baselines at low bitrate. What is the precise bitrate range used for BD-rate comparison? Besides, a related work about implementing content adaptive algorithm in learned video compression is suggested for discussion or comparison: Guo Lu, et al., ""Content Adaptive and Error Propagation Aware Deep Video Compression."" ECCV 2020.",ICLR_2022_1522,ICLR_2022,"Weakness:
The overall novelty seems limited since the instance-adaptive method is from existing work with no primary changes. Here are some main questions and concerns:
1). How many optimization steps are used to produce the final reported performance in Figure.1 as well as in some other figs and tables?
2). The proposed method looks stronger at high bitrate but close to the baselines at low bitrate. What is the precise bitrate range used for BD-rate comparison?
Besides, a related work about implementing content adaptive algorithm in learned video compression is suggested for discussion or comparison:
Guo Lu, et al., ""Content Adaptive and Error Propagation Aware Deep Video Compression."" ECCV 2020.","['5', '5', '5']",5.0,gold,4,"['5', '5', '3']",5.0,silver,"['5', '5', 'X']",5,silver,"['5', '5', '3']",5.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,4,"the review point is mostly helpful because it identifies a specific area (bitrate range for bd-rate comparison) where additional information is needed for clarity and accuracy. it also suggests related work that could enhance the discussion or comparison in the draft, guiding the authors toward improving their analysis. however, the comment could be expanded by explaining how discussing or comparing with the suggested related work might benefit the draft, thus making it even more comprehensive and impactful."
"- The bounded noise assumption, while common, is somewhat restrictive in stochastic optimization literature. There have been several efforts to extend these noise conditions: [A. Khaled and P. Richt´arik]. Better theory for sgd in the nonconvex world. TMLR 2023. [R. Gower, O. Sebbouh, and N. Loizou] Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. AISTATS 2021.",nE1l0vpQDP,ICLR_2025,"- Given the existing literature on the implicit bias of optimization methods, the primary concern is the significance of the results presented. For instance, the classic result by [Z. Ji and M. Telgarsky] demonstrates a convergence rate $\log\log n/\log n$ of GD to the L2-margin solution, which is faster than the rate shown in this submission. Moreover, [C. Zhang, D. Zou, and Y. Cao] have shown much faster rates for Adam converging to the L-infinity margin solution. This submission also lacks citations to these papers and other relevant works:
[Z. Ji and M. Telgarsky] The implicit bias of gradient descent on nonseparable data, COLT 2019.
[C. Zhang, D. Zou, and Y. Cao] The Implicit Bias of Adam on Separable Data. 2024.
[S. Xie and Z. Li] Implicit Bias of AdamW: l_\infty-Norm Constrained Optimization. ICML 2024
[M. Nacson, N. Srebro, and D. Soudry] Stochastic gradient descent on separable data: Exact convergence with a fixed learning rate. AISTATS 2019.
- Since AdaGrad-Norm has the same implicit bias as GD, the advantages of using AdaGrad-Norm over GD are unclear.
- The bounded noise assumption, while common, is somewhat restrictive in stochastic optimization literature. There have been several efforts to extend these noise conditions:
[A. Khaled and P. Richt´arik]. Better theory for sgd in the nonconvex world. TMLR 2023.
[R. Gower, O. Sebbouh, and N. Loizou] Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. AISTATS 2021.","['1', '3', '1']",1.0,silver,4,"['5', '3', '3']",3.0,silver,"['5', '5', '5']",5,gold,"['3', '4', '2']",,,"['1', '1', '1']",1.0,gold,"['1', '0', '0']",0.0,silver,2,"the comment highlights a potential weakness in the manuscript concerning the bounded noise assumption in stochastic optimization. however, it does not provide clear or actionable feedback for the authors to address this issue. the mention of related work suggests areas of improvement but lacks specificity and guidance on how to incorporate these insights into the draft. thus, it is barely helpful as it leaves the authors with only a vague idea of how to enhance their work."
- The restriction to triplets (or a sliding window of length 3) is quite limiting. Is this a fundamental limitation of the approach or is an extension to longer subsequences (without a sliding window) straightforward?,NIPS_2016_321,NIPS_2016,"======================== Positive aspects: + The paper is well written and has a clear and coherent structure. The discussion of related work is comprehensive. + Non-parametric emission distributions add flexibility to the general HMM framework and reduce bias due to wrong modeling assumptions. Progress in this area should have theoretical and practical impact. + The paper builds upon existing spectral methods for parametric HMMs but introduces novel techniques to extend those approaches to the non-parametric case. + The theoretical bounds (section 5) are interesting, even though most of the results are special cases or straightforward extensions of known results. Negative aspects: - The restriction to triplets (or a sliding window of length 3) is quite limiting. Is this a fundamental limitation of the approach or is an extension to longer subsequences (without a sliding window) straightforward? - Since the paper mentions the possibility to use Chebyshev polynomials to achieve a speed-up, it would have been interesting to see a runtime comparison at test time. - The presentation is at times too equation-driven and the notation, especially in chapter 3, quite convoluted and hard to follow. An illustrative figure of the key concepts in section 3 would have been helpful. - The experimental evaluation compares the proposed approach to 4 other HMM baselines. Even though NP-SPEC-HMM outperforms those baselines, the experimental evaluation has only toy character (simple length 6 conditional distributions, only one training/test sequence in case of the real datasets). Minor points ============ * l.22: Only few parametric distributions allow for tractable exact inference in an HMM. * l.183: Much faster approximations than Chebyshev polynomials exist for the evaluation of kernel density estimates, especially in low-dimensional spaces (e.g., based on fast multipole methods). * Figure 1: There is probably a âx 10^3â missing in the plot on the bottom right. Questions ========= * Eq. (3): Why the restriction to an isotropic bandwidth and a product kernel? Especially a diagonal bandwidth matrix could have been helpful. Would the approximation with Chebyshev polynomials still work? * The paper focuses on learning HMMs with non-parametric emission distributions, but it does not become clear how those emission distributions affect inference. Which of the common inference tasks in a discrete HMM (filtering, smoothing, marginal observation likelihood) can be computed exactly/approximately with an NP-SPEC-HMM? * Is it computationally feasible to use the proposed model in a more realistic application, e.g., action recognition from motion capture sequences? Conclusion ========== The paper is well written and, from a theoretical perspective, interesting to read. However, the experiments are weak and it remains unclear how practical the proposed model would be in real applications. Iâm tending towards accept, but the authors should comment in their rebuttal on the above points.","['2', '3', '5']",,,4,"['2', '5', '3']",,,"['2', 'X', 'X']",X,silver,"['3', '4', '4']",4.0,silver,"['1', '1', '1']",1.0,gold,"['0', '0', '0']",0.0,gold,3,"the comment identifies a potential limitation in the approach regarding the restriction to triplets, suggesting it might be a weakness in the methodology. however, it lacks depth and detail, as it does not provide specific suggestions or explanations on how the authors might address or investigate this limitation. while it poses a relevant question that could guide authors in considering extensions to their method, the feedback isn't fully fleshed out, thereby offering only some insights for improvement."
"4. I understand what it's trying to say but I believe this needs to be changed to be mathematically correct, unless that makes a bunch of other equations messy. Also, why is it L_l instead of just L? That notation should be introduced beforehand. Fig.",ICLR_2022_1842,ICLR_2022,"weakness, right?
Sec. 4.2: just for clarity, is each object's bounding box (for ray intersection) computation axis-aligned with the object coordinate system or the world/scene coordinate system?
Is there anything that constrains (in a soft or hard manner) the outgoing fractions to sum up/integrate to 1 or at most 1 for a given incoming light direction?
Fig. 10: What exactly is N in this figure? N is used in the main text to refer to the number of objects and to the number of point samples along a ray, neither of which seems like the right parameter here.
Minor suggestions for improvements:
Fig. 7: I currently cannot see much in this figure, a comparison to a white/grey environment map would make it easier to tell that there is an effect.
I'm not a fan of the equation two lines after Eq. 4. I understand what it's trying to say but I believe this needs to be changed to be mathematically correct, unless that makes a bunch of other equations messy. Also, why is it L_l instead of just L? That notation should be introduced beforehand.
Fig. 8: Switching out columns 2 and 3 would make the difficult comparison between No Indirect and Full Model easier.
There's a typo at the end of page 2: from from","['2', '2', '5', '3']",2.0,silver,3,"['1', '2', '5', '3']",,,"['X', '2', 'X', 'X']",X,gold,"['1', '2', '5', '2']",2.0,silver,"['1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0']",0.0,gold,3,"the review comment identifies a mathematical inconsistency and a notation issue, which is helpful to a certain extent. however, it lacks specific guidance on how to correct the mathematical aspect and does not provide a detailed explanation of why addressing these points is important for the draft. the lack of clarity on how the equations might be affected if changed and the passing reference to a figure ('fig.') that is cut off also detract from its helpfulness, leaving some ambiguity for the authors."
"- The explanations for features in Section 3.2 are somewhat intertwined and thus confusing. The section would be more coherently organized with more separate paragraphs dedicated to each of lexical features and sentence-level features, by:",ACL_2017_31_review,ACL_2017,"] See below for details of the following weaknesses: - Novelties of the paper are relatively unclear.
- No detailed error analysis is provided.
- A feature comparison with prior work is shallow, missing two relevant papers.
- The paper has several obscure descriptions, including typos.
[General Discussion:] The paper would be more impactful if it states novelties more explicitly. Is the paper presenting the first neural network based approach for event factuality identification? If this is the case, please state that.
The paper would crystallize remaining challenges in event factuality identification and facilitate future research better if it provides detailed error analysis regarding the results of Table 3 and 4. What are dominant sources of errors made by the best system BiLSTM+CNN(Att)? What impacts do errors in basic factor extraction (Table 3) have on the overall performance of factuality identification (Table 4)? The analysis presented in Section 5.4 is more like a feature ablation study to show how useful some additional features are.
The paper would be stronger if it compares with prior work in terms of features. Does the paper use any new features which have not been explored before? In other words, it is unclear whether main advantages of the proposed system come purely from deep learning, or from a combination of neural networks and some new unexplored features. As for feature comparison, the paper is missing two relevant papers: - Kenton Lee, Yoav Artzi, Yejin Choi and Luke Zettlemoyer. 2015 Event Detection and Factuality Assessment with Non-Expert Supervision. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1643-1648.
- Sandeep Soni, Tanushree Mitra, Eric Gilbert and Jacob Eisenstein. 2014.
Modeling Factuality Judgments in Social Media Text. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 415-420.
The paper would be more understandable if more examples are given to illustrate the underspecified modality (U) and the underspecified polarity (u). There are two reasons for that. First, the definition of 'underspecified' is relatively unintuitive as compared to other classes such as 'probable' or 'positive'.
Second, the examples would be more helpful to understand the difficulties of Uu detection reported in line 690-697. Among the seven examples (S1-S7), only S7 corresponds to Uu, and its explanation is quite limited to illustrate the difficulties.
A minor comment is that the paper has several obscure descriptions, including typos, as shown below: - The explanations for features in Section 3.2 are somewhat intertwined and thus confusing. The section would be more coherently organized with more separate paragraphs dedicated to each of lexical features and sentence-level features, by: - (1) stating that the SIP feature comprises two features (i.e., lexical-level and sentence-level) and introduce their corresponding variables (l and c) *at the beginning*; - (2) moving the description of embeddings of the lexical feature in line 280-283 to the first paragraph; and - (3) presenting the last paragraph about relevant source identification in a separate subsection because it is not about SIP detection.
- The title of Section 3 ('Baseline') is misleading. A more understandable title would be 'Basic Factor Extraction' or 'Basic Feature Extraction', because the section is about how to extract basic factors (features), not about a baseline end-to-end system for event factuality identification.
- The presented neural network architectures would be more convincing if it describes how beneficial the attention mechanism is to the task.
- Table 2 seems to show factuality statistics only for all sources. The table would be more informative along with Table 4 if it also shows factuality statistics for 'Author' and 'Embed'.
- Table 4 would be more effective if the highest system performance with respect to each combination of the source and the factuality value is shown in boldface.
- Section 4.1 says, ""Aux_Words can describe the *syntactic* structures of sentences,"" whereas section 5.4 says, ""they (auxiliary words) can reflect the *pragmatic* structures of sentences."" These two claims do not consort with each other well, and neither of them seems adequate to summarize how useful the dependency relations 'aux' and 'mark' are for the task.
- S7 seems to be another example to support the effectiveness of auxiliary words, but the explanation for S7 is thin, as compared to the one for S6. What is the auxiliary word for 'ensure' in S7?
- Line 162: 'event go in S1' should be 'event go in S2'.
- Line 315: 'in details' should be 'in detail'.
- Line 719: 'in Section 4' should be 'in Section 4.1' to make it more specific.
- Line 771: 'recent researches' should be 'recent research' or 'recent studies'. 'Research' is an uncountable noun.
- Line 903: 'Factbank' should be 'FactBank'.","['5', '5', '4', '4', '4', '3', '5', '5']",5.0,gold,2,"['4', '5', '5', '5', '5', '5', '5', '5']",5.0,gold,"['1', '5', '3', '4', '5', '5', '5', '5']",5,gold,"['4', '5', '4', '5', '5', '5', '5', '5']",5.0,gold,"['1', '1', '1', '1', '1', '1', '1', '1']",1.0,gold,"['1', '0', '0', '0', '0', '0', '0']",0.0,gold,4,"the review point is mostly helpful because it identifies a specific weakness in section 3.2 related to the organization and clarity of explanations for features. it offers actionable feedback by suggesting that the section would benefit from being reorganized into separate paragraphs for lexical features and sentence-level features. however, the feedback could be more comprehensive by providing specific examples of where the confusion occurs or additional guidance on how to implement the suggested changes effectively."
"- The Related Work section is lacking details. The paragraph on long-context language models should provide a more comprehensive overview of existing methods and their limitations, positioning SSMs appropriately. This includes discussing sparse-attention mechanisms [1, 2], segmentation-based approaches [3, 4, 5], memory-enhanced segmentation strategies [6], and recursive methods [7] for handling very long documents.",NJUzUq2OIi,ICLR_2025,"I found the proposed idea, experiments, and analyses conducted by the authors to be valuable, especially in terms of their potential impact on low-resource scenarios. However, for the paper to fully meet the ICLR standards, there are still areas that need additional work and detail. Below, I outline several key points for improvement. I would be pleased to substantially raise my scores if the authors address these suggestions and enhance the paper accordingly.
**General Feedback**
- I noticed that the title of the paper does not match the one listed on OpenReview.
- The main text should indicate when additional detailed discussions are deferred to the Appendix for better reader guidance. **Introduction**
- The Introduction lacks foundational references to support key claims. Both the second and third paragraphs would benefit from citations to strengthen the arguments. For instance, the statement: ""This method eliminates the need for document chunking, *a common limitation in current retrieval systems that often results in loss of context and reduced accuracy*"" needs a supporting citation to substantiate this point.
- The sentence: ""Second, to be competitive with embedding approaches, a retrieval language model needs to be small"" requires further justification. The authors should include in the paper a complexity analysis comparison discussing time and GPU memory consumption to support this assertion.
**Related Work**
- The sentence ""Large Language Models are found to be inefficient processing long-context documents"" should be rewritten for clarity, for example: ""Large Language Models are inefficient when processing long-context documents.""
- The statements ""Transformer models suffer from quadratic computation during training and linear computation during inference"" and ""However, transformer-based models are infeasible to process extremely long documents due to their linear inference time"" are incorrect. Transformers, as presented in ""Attention is All You Need,"" scale quadratically in both training and inference.
- The statement regarding State Space Models (SSMs) having ""linear scaling during training and constant scaling during inference"" is inaccurate. SSMs have linear complexity for both training and inference. The term ""constant scaling"" implies no dependence on sequence length, which is incorrect.
- The Related Work section is lacking details. The paragraph on long-context language models should provide a more comprehensive overview of existing methods and their limitations, positioning SSMs appropriately. This includes discussing sparse-attention mechanisms [1, 2], segmentation-based approaches [3, 4, 5], memory-enhanced segmentation strategies [6], and recursive methods [7] for handling very long documents.
- Similarly, the paragraph on Retrieval-Augmented Generation should specify how prior works addressed different long document tasks. Examples include successful applications of RAG in long-document summarization [8, 9] and query-focused multi-document summarization [10, 11], which are closely aligned with the present work. **Figures**
- Figures 1 and 2 are clear but need aesthetic improvements to meet the conference's standard presentation quality.
**Model Architecture**
- The description ""a subset of tokens are specially designated, and the classification head is applied to these tokens. In the current work, the classification head is applied to the last token of each sentence, giving sentence-level resolution"" is ambiguous. Clarify whether new tokens are added to the sequence or if existing tokens (e.g., periods) are used to represent sentence ends.
**Synthetic Data Generation**
- The ""lost in the middle"" problem when processing long documents [12] is not explicitly discussed. Have the authors considered the position of chunks during synthetic data generation? Ablation studies varying the position and distance between linked chunks would provide valuable insights into Mamba’s effectiveness in addressing this issue.
- More details are needed regarding the data decontamination pipeline, chunk size, and the relative computational cost of the link-based method versus other strategies.
- The authors claim that synthetic data generation is computationally expensive but provide no supporting quantitative evidence. Information such as time estimates and GPU demand would strengthen this argument and assess feasibility.
- There is no detailed evaluation of the synthetic data’s quality. An analysis of correctness and answer factuality would help validate the impact on retrieval performance beyond benchmark metrics. **Training**
- This section is too brief. Consider merging it with Section 3, ""Model Architecture,"" for a more cohesive presentation.
- What was the training time for the 130M model?
**Experimental Method**
- Fix minor formatting issues, such as adding a space after the comma in "",LVeval.""
- Specify in Table 1 which datasets use free-form versus multiple-choice answers, including the number of answers and average answer lengths.
- Consider experimenting with GPT-4 as a retriever.
- Expand on ""The accuracy of freeform answers is judged using GPT-4.""
- Elaborate on the validation of the scoring pipeline, particularly regarding ""0.942 macro F1."" Clarify the data and method used for validation.
- Justify the selection of ""50 sentences"" for Mamba retrievers and explain chunk creation methods for embedding models. Did the chunks consist of 300 fixed-length segments, or was semantic chunking employed [3, 5]? Sentence-level embedding-based retrieval could be explored to align better with the Mamba setting.
- The assertion that ""embedding models were allowed to retrieve more information than Mamba"" implies an unfair comparison, but more context can sometimes degrade performance [12].
- Clarify the use of the sliding window approach for documents longer than 128k tokens, especially given the claim that Mamba could process up to 256K tokens directly. **Results**
- Remove redundancy in Section 7.1.2, such as restating the synthetic data generation strategies.
- Expand the ablation studies to cover different input sequence lengths during training and varying the number of retrieved sentences to explore robustness to configuration changes.
- Highlight that using fewer training examples (500K vs. 1M) achieved comparable accuracy (i.e., 59.4 vs. 60.0, respectively).
- Why not train both the 130M and 1.3B models on a dataset size of 500K examples, but compare using 1M and 400K examples, respectively? **Limitations**
- The high cost of generating synthetic training data is mentioned but lacks quantification. How computationally expensive is it in terms of time or resources? **Appendix**
- Note that all figures in Appendices B and C are the same, suggesting an error that needs correcting.
**Missing References**
[1] Longformer: The Long-Document Transformer. arXiv 2020.
[2] LongT5: Efficient Text-To-Text Transformer for Long Sequences. NAACL 2022.
[3] Semantic Self-Segmentation for Abstractive Summarization of Long Documents in Low-Resource Regimes. AAAI 2022.
[4] Summ^n: A Multi-Stage Summarization Framework for Long Input Dialogues and Documents. ACL 2022.
[5] Align-Then-Abstract Representation Learning for Low-Resource Summarization. Neurocomputing 2023.
[6] Efficient Memory-Enhanced Transformer for Long-Document Summarization in Low-Resource Regimes. Sensors 2023.
[7] Recursively Summarizing Books with Human Feedback. arXiv 2021.
[8] DYLE: Dynamic Latent Extraction for Abstractive Long-Input Summarization. ACL 2022.
[9] Towards a Robust Retrieval-Based Summarization System. arXiv 2024.
[10] Discriminative Marginalized Probabilistic Neural Method for Multi-Document Summarization of Medical Literature. ACL 2022.
[11] Retrieve-and-Rank End-to-End Summarization of Biomedical Studies. SISAP 2023.
[12] Lost in the Middle: How Language Models Use Long Contexts. TACL 2024.","['5', '5', '5']",5.0,gold,4,"['5', '5', '5']",5.0,gold,"['5', '5', '5']",5,gold,"['5', '5', '5']",5.0,gold,"['1', '1', '1']",1.0,gold,"['0', '0', '1']",0.0,silver,5,"the review point is highly helpful as it identifies a specific weakness in the related work section and provides detailed guidance on how to improve it. it suggests the inclusion of specific topics and methods, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. additionally, it directs the authors to substantiate their discussion with citations, offering actionable and comprehensive feedback that empowers the authors to make significant improvements to their draft."
