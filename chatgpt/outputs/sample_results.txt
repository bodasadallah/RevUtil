Aspect: verifiability_extraction
Review Point: 8. Eq. 12 is confusing. Where does the reward come from at each trial? Is one of the r_i taken from Eq. 11? Explaining the network model in Sec. 4.2 with equations would greatly improve clarity. [1] https://www.sciencedirect.com/science/article/pii/S0893608019301741 [2] https://www.frontiersin.org/articles/10.3389/fnins.2018.00608/full [3] https://proceedings.neurips.cc/paper/2020/hash/1abb1e1ea5f481b589da52303b091cbb-Abstract.html

Rationale: The review point contains a request for clarification regarding Eq. 12 and suggests that explaining the network model with equations would improve clarity. This includes a suggestion for improvement, which qualifies it as a claim. Therefore, it should be labeled as "Yes."


Aspect: grounding_specificity
Review Point: 2. Experimental Evaluation 2.1. Ablations 2.1.1. The paper claims that âAnother distinction of our approach is the âpickingâ step â. However, this aspect is not ablated. 2.2. Experiments on CIFAR. The comparison on CIFAR is not convincing 2.2.1. The continual learning literature has extensive experiments on this dataset and the paper only compares to one approach (DEN). 2.2.2. It is unclear if DEN is correctly used/evaluated. It would have been more convincing if the authors used the same setup as in the DEN paper to make sure the comparison is fair/correct.

Rationale: The review point is divided into several sub-points, each addressing specific issues within the experimental evaluation section of the paper. 1. **Grounding:** The comment is fully grounded as it explicitly mentions the "Experimental Evaluation" section and further specifies sub-sections like "Ablations" and "Experiments on CIFAR." This allows the authors to accurately identify the parts of the paper being addressed.2. **Specificity:** The comment is specific in detailing what needs to be addressed:   - It points out that the "picking" step, claimed as a distinction of the approach, is not ablated.   - It critiques the comparison on CIFAR, noting that the paper only compares to one approach (DEN) despite extensive experiments in the continual learning literature.   - It questions the correctness of the DEN evaluation and suggests using the same setup as in the DEN paper for a fair comparison.The comment provides clear guidance on what the authors need to address in their experimental evaluation, making it both fully grounded and specific.


Aspect: actionability
Review Point: 7. A discussion on the prompt dataset (for the few-shot case) creation together with its source should be discussed.

Rationale: The review point explicitly states that a discussion on the prompt dataset creation, along with its source, should be included. This provides a clear directive for the authors to add a specific section or expand an existing one to cover these aspects. However, the comment does not provide detailed guidance on what specific elements of the dataset creation or source should be discussed, leaving some ambiguity in how to execute the action. Therefore, while the action is explicit, it lacks concrete details on implementation, making the comment somewhat actionable.


Aspect: helpfulness
Review Point: 3. Since ternary potential seems to be the main factor in the performance improvement of the proposed model, I would like the authors to compare the proposed model with existing models where answers are also used as inputs such as Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).

Rationale: The review comment identifies a key factor in the performance improvement of the proposed model—ternary potential—and suggests a comparison with existing models that also use answers as inputs, specifically referencing a relevant work (Jabri et al., ECCV16). This feedback is clear and actionable, providing the authors with a specific direction for enhancing their paper by benchmarking their model against established baselines. However, while it offers a valuable suggestion, it could be more comprehensive by explaining why this comparison is important or how it might impact the paper's conclusions. Overall, the comment is mostly helpful as it provides a concrete step for improvement, but it could be further refined with additional context or guidance. Therefore, it aligns with a score of 4.


Aspect: verifiability
Review Point: - the required implicit call to the Witness oracle is confusing.

Rationale: The review point claims that "the required implicit call to the Witness oracle is confusing," but it does not provide any supporting evidence, examples, or detailed explanations to substantiate this claim. Without further elaboration or justification, the authors may find it challenging to understand the specific issue or how to address it. Therefore, the claim is unverifiable.


