{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_venue</th>\n",
       "      <th>venue</th>\n",
       "      <th>review_point</th>\n",
       "      <th>actionability_label</th>\n",
       "      <th>chatgpt_actionability_score</th>\n",
       "      <th>grounding_specificity_label</th>\n",
       "      <th>chatgpt_grounding_specificity_score</th>\n",
       "      <th>verifiability_label</th>\n",
       "      <th>chatgpt_verifiability_score</th>\n",
       "      <th>helpfulness_label</th>\n",
       "      <th>chatgpt_helpfulness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACL</td>\n",
       "      <td>ACL_2017</td>\n",
       "      <td>- In section 2.3 the authors use Lample et al....</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>X</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACL</td>\n",
       "      <td>ACL_2017</td>\n",
       "      <td>- The concept of energy is mentioned for the f...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ICLR</td>\n",
       "      <td>ICLR_2022</td>\n",
       "      <td>2 The technical contribution is limited, i.e.,...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ICLR</td>\n",
       "      <td>ICLR_2021</td>\n",
       "      <td>4. In Section 4.1, \\epsilon is not used in equ...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NIPS</td>\n",
       "      <td>NIPS_2018</td>\n",
       "      <td>- The paper opens that learning long-range dep...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NIPS</td>\n",
       "      <td>NIPS_2016</td>\n",
       "      <td>2. On line 205, it should be Fig. 1 instead of...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ARR</td>\n",
       "      <td>ARR_2022</td>\n",
       "      <td>- Table 4 and 5 would be more readable if they...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARR</td>\n",
       "      <td>ARR_2022</td>\n",
       "      <td>6. Lines 170 to 171, “unreliable neighbors” an...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>X</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   main_venue      venue                                       review_point  \\\n",
       "0         ACL   ACL_2017  - In section 2.3 the authors use Lample et al....   \n",
       "2         ACL   ACL_2017  - The concept of energy is mentioned for the f...   \n",
       "13       ICLR  ICLR_2022  2 The technical contribution is limited, i.e.,...   \n",
       "14       ICLR  ICLR_2021  4. In Section 4.1, \\epsilon is not used in equ...   \n",
       "21       NIPS  NIPS_2018  - The paper opens that learning long-range dep...   \n",
       "24       NIPS  NIPS_2016  2. On line 205, it should be Fig. 1 instead of...   \n",
       "0         ARR   ARR_2022  - Table 4 and 5 would be more readable if they...   \n",
       "2         ARR   ARR_2022  6. Lines 170 to 171, “unreliable neighbors” an...   \n",
       "\n",
       "    actionability_label  chatgpt_actionability_score  \\\n",
       "0                     5                            4   \n",
       "2                     5                            5   \n",
       "13                    1                            1   \n",
       "14                    5                            5   \n",
       "21                    2                            2   \n",
       "24                    5                            5   \n",
       "0                     5                            5   \n",
       "2                     5                            5   \n",
       "\n",
       "    grounding_specificity_label  chatgpt_grounding_specificity_score  \\\n",
       "0                             5                                    5   \n",
       "2                             5                                    5   \n",
       "13                            2                                    3   \n",
       "14                            5                                    5   \n",
       "21                            5                                    5   \n",
       "24                            5                                    5   \n",
       "0                             5                                    5   \n",
       "2                             5                                    5   \n",
       "\n",
       "    verifiability_label chatgpt_verifiability_score  helpfulness_label  \\\n",
       "0                     5                           X                  5   \n",
       "2                     5                           3                  5   \n",
       "13                    2                           2                  2   \n",
       "14                    0                           4                  5   \n",
       "21                    4                           3                  3   \n",
       "24                    0                           X                  5   \n",
       "0                     5                           1                  5   \n",
       "2                     0                           X                  5   \n",
       "\n",
       "    chatgpt_helpfulness_score  \n",
       "0                           4  \n",
       "2                           4  \n",
       "13                          1  \n",
       "14                          5  \n",
       "21                          3  \n",
       "24                          5  \n",
       "0                           5  \n",
       "2                           4  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "\n",
    "# Load the Excel file\n",
    "file_path = '/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/outputs/main_data_batch_gold_results.xlsx'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Load Excel file\n",
    "aspects = ['actionability', 'grounding_specificity', 'verifiability', 'helpfulness']\n",
    "sheets = {aspect: pd.read_excel(file_path, sheet_name=aspect) for aspect in aspects}\n",
    "\n",
    "# Step 1: Get common review_points across all sheets\n",
    "common_review_points = set(sheets[aspects[0]]['review_point'])\n",
    "for aspect in aspects[1:]:\n",
    "    common_review_points &= set(sheets[aspect]['review_point'])\n",
    "\n",
    "# Step 2: Filter to rows with common review_points\n",
    "for aspect in aspects:\n",
    "    sheets[aspect] = sheets[aspect][sheets[aspect]['review_point'].isin(common_review_points)]\n",
    "\n",
    "# Step 3: Merge all sheets on 'review_point'\n",
    "merged_df = sheets[aspects[0]][['review_point', 'venue', f'{aspects[0]}_label', f'chatgpt_{aspects[0]}_score']]\n",
    "for aspect in aspects[1:]:\n",
    "    merged_df = pd.merge(\n",
    "        merged_df,\n",
    "        sheets[aspect][['review_point', f'{aspect}_label', f'chatgpt_{aspect}_score']],\n",
    "        on='review_point',\n",
    "        how='inner'\n",
    "    )\n",
    "\n",
    "# Step 4: Normalize venue (e.g. ICLR_2024 → ICLR)\n",
    "merged_df['main_venue'] = merged_df['venue'].apply(lambda v: v.split('_')[0] if isinstance(v, str) else v)\n",
    "\n",
    "# Step 5: Preprocess verifiability: replace 'X' with 0 and cast all labels to float\n",
    "label_cols = [f\"{aspect}_label\" for aspect in aspects]\n",
    "merged_df['verifiability_label'] = merged_df['verifiability_label'].replace('X', 0)\n",
    "\n",
    "for col in label_cols:\n",
    "    merged_df[col] = pd.to_numeric(merged_df[col], errors='coerce')\n",
    "\n",
    "# Step 6: Compute custom variance as sum of absolute pairwise differences\n",
    "def custom_score_diversity(row):\n",
    "    values = [row[col] for col in label_cols if pd.notnull(row[col])]\n",
    "    return sum(abs(a - b) for a, b in itertools.combinations(values, 2))\n",
    "\n",
    "merged_df['score_diversity'] = merged_df.apply(custom_score_diversity, axis=1)\n",
    "\n",
    "# Step 7: Select one low-diversity and one high-diversity example per main venue (ensuring true diversity)\n",
    "\n",
    "selected_rows = []\n",
    "\n",
    "for main_venue in merged_df['main_venue'].unique():\n",
    "    venue_df = merged_df[merged_df['main_venue'] == main_venue].copy()\n",
    "\n",
    "    if len(venue_df) < 2:\n",
    "        continue\n",
    "\n",
    "    # Sort by custom diversity score\n",
    "    venue_df = venue_df.sort_values(by='score_diversity', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    # Filter out rows where actionability, grounding_specificity, and helpfulness are all the same\n",
    "    def is_uniform_main_scores(row):\n",
    "        vals = [row[f\"{aspect}_label\"] for aspect in ['actionability', 'grounding_specificity', 'helpfulness']]\n",
    "        return len(set(vals)) == 1\n",
    "\n",
    "    venue_df['uniform_main_scores'] = venue_df.apply(is_uniform_main_scores, axis=1)\n",
    "\n",
    "    # Try to find a low-diversity example that is NOT fully uniform\n",
    "    non_uniform_df = venue_df[~venue_df['uniform_main_scores']]\n",
    "    \n",
    "    if not non_uniform_df.empty:\n",
    "        low_div_row = non_uniform_df.iloc[0]\n",
    "    else:\n",
    "        # Fallback: allow a uniform one if necessary\n",
    "        low_div_row = venue_df.iloc[0]\n",
    "\n",
    "    # High diversity example (last row)\n",
    "    high_div_row = venue_df.iloc[-1]\n",
    "    if high_div_row['review_point'] == low_div_row['review_point'] and len(venue_df) > 1:\n",
    "        high_div_row = venue_df.iloc[-2]\n",
    "\n",
    "    # Final check: only keep if they're different\n",
    "    if low_div_row['review_point'] != high_div_row['review_point']:\n",
    "        selected_rows.extend([low_div_row, high_div_row])\n",
    "\n",
    "\n",
    "# Step 8: Final output\n",
    "summary_columns = ['main_venue', 'venue', 'review_point']\n",
    "for aspect in aspects:\n",
    "    summary_columns += [f\"{aspect}_label\", f\"chatgpt_{aspect}_score\"]\n",
    "\n",
    "summary_df = pd.DataFrame(selected_rows)[summary_columns]\n",
    "\n",
    "# Output\n",
    "summary_df\n",
    "# summary_df.to_csv(\"main_venue_uniform_and_diverse_examples.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Summary of Selected Rows}\n",
      "\\label{tab:summary_table}\n",
      "\\begin{tabular}{lllrrrrrlrr}\n",
      "\\toprule\n",
      "main_venue & venue & review_point & actionability_label & chatgpt_actionability_score & grounding_specificity_label & chatgpt_grounding_specificity_score & verifiability_label & chatgpt_verifiability_score & helpfulness_label & chatgpt_helpfulness_score \\\\\n",
      "\\midrule\n",
      "ACL & ACL_2017 & - In section 2.3 the authors use Lample et al. Bi-LSTM-CRF model, it might be beneficial to add that the input is word embeddings (similarly to Lample et al.) - Figure 3, KNs in source language or in English? ( since the mentions have been translated to English). In the authors' response, the authors stated that they will correct the figure. & 5 & 4 & 5 & 5 & 5 & X & 5 & 4 \\\\\n",
      "ACL & ACL_2017 & - The concept of energy is mentioned for the first time in Section 3.1. Even though the explanation provided is enough at that point, it would be nice to refresh the idea of energy in Section 5.2 (where it is used several times) and providing some hints about how to interpret it: a high energy on a character would be indicating that the current morpheme should be split at that point? In addition, the concept of peak (in Figure 5) is not described. & 5 & 5 & 5 & 5 & 5 & 3 & 5 & 4 \\\\\n",
      "ICLR & ICLR_2022 & 2 The technical contribution is limited, i.e., there is no significant technical contribution and extension based on a typical model for the cross-domain recommendation setting. & 1 & 1 & 2 & 3 & 2 & 2 & 2 & 1 \\\\\n",
      "ICLR & ICLR_2021 & 4. In Section 4.1, \\epsilon is not used in equation (10), but in equation (11). It might be more clear to introduce \\epsilon when (11) is discussed. & 5 & 5 & 5 & 5 & 0 & 4 & 5 & 5 \\\\\n",
      "NIPS & NIPS_2018 & - The paper opens that learning long-range dependencies is important for powerful predictors. In the example of semantic segmentation I can see that this is actually happening, e.g., in the visualisations in table 3; but I am not sure if it is fully required. Probably the truth lies somewhere in between and I miss a discussion about this. If no form of locality with respect to the 2d image space is encoded in the graph structure, I suspect that prediction suddenly depends on the image size. & 2 & 2 & 5 & 5 & 4 & 3 & 3 & 3 \\\\\n",
      "NIPS & NIPS_2016 & 2. On line 205, it should be Fig. 1 instead of Fig. 5.1. In latex, please put '\\label' after the '\\caption', and the bug will be solved. & 5 & 5 & 5 & 5 & 0 & X & 5 & 5 \\\\\n",
      "ARR & ARR_2022 & - Table 4 and 5 would be more readable if they were split into two tables each, to have one table per measure. E.g. first put the 8 SFII columns and then the 8 SPDI columns rather than alternating between them. & 5 & 5 & 5 & 5 & 5 & 1 & 5 & 5 \\\\\n",
      "ARR & ARR_2022 & 6. Lines 170 to 171, “unreliable neighbors” any examples of “unreliable neighbors”? & 5 & 5 & 5 & 5 & 0 & X & 5 & 4 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "summary_df\n",
    "# Convert the summary_df DataFrame into a LaTeX table\n",
    "latex_table = summary_df.to_latex(index=False, caption=\"Summary of Selected Rows\", label=\"tab:summary_table\")\n",
    "print(latex_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
