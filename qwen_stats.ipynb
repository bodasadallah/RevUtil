{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import *\n",
    "data = pd.read_excel('/home/abdelrahman.sadallah/mbzuai/review_rewrite/chatgpt/outputs/deepseek-r1-qwen-32b_gold_human_annotations_results.xlsx', sheet_name=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      yes\n",
       "1      yes\n",
       "2      yes\n",
       "3      yes\n",
       "4      yes\n",
       "      ... \n",
       "139    yes\n",
       "140    yes\n",
       "141    yes\n",
       "142    yes\n",
       "143    yes\n",
       "Name: predicted_score, Length: 144, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['verifiability_extraction']['predicted_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_point</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>focused_review</th>\n",
       "      <th>actionability</th>\n",
       "      <th>actionability_label</th>\n",
       "      <th>actionability_label_type</th>\n",
       "      <th>batch</th>\n",
       "      <th>grounding_specificity</th>\n",
       "      <th>grounding_specificity_label</th>\n",
       "      <th>...</th>\n",
       "      <th>professional_tone</th>\n",
       "      <th>professional_tone_label</th>\n",
       "      <th>professional_tone_label_type</th>\n",
       "      <th>valid_point</th>\n",
       "      <th>valid_point_label</th>\n",
       "      <th>valid_point_label_type</th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>generation</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2) it only compares with some weak baselines i...</td>\n",
       "      <td>ARR_2022_123_review</td>\n",
       "      <td>ARR_2022</td>\n",
       "      <td>1) it uses different experiment settings (e.g....</td>\n",
       "      <td>['3', '5', '1']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>['4', '5', '5']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>silver</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate this review point ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. The evaluation on the word analogy task see...</td>\n",
       "      <td>ACL_2017_318_review</td>\n",
       "      <td>ACL_2017</td>\n",
       "      <td>1. Presentation and clarity: important details...</td>\n",
       "      <td>['1', '4', '1', '4', '2', '1', '2']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gold</td>\n",
       "      <td>2</td>\n",
       "      <td>['4', '5', '5', '4', '1', '1', '5']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1', '1', '1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['1', '0', '1', '0', '0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate the verifiability ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Also, since the dataset is artificially crea...</td>\n",
       "      <td>ARR_2022_236_review</td>\n",
       "      <td>ARR_2022</td>\n",
       "      <td>- My main criticism is that the \"mismatched\" i...</td>\n",
       "      <td>['2', '3', '3', '4', '5', '3', '2', '5']</td>\n",
       "      <td>3.0</td>\n",
       "      <td>gold</td>\n",
       "      <td>2</td>\n",
       "      <td>['2', '4', '4', '4', '5', '5', '2', '3']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1', '1', '1', '1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate this review point ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1) The paper does not dig into the theory prof...</td>\n",
       "      <td>ACL_2017_554_review</td>\n",
       "      <td>ACL_2017</td>\n",
       "      <td>1) The paper does not dig into the theory prof...</td>\n",
       "      <td>['1', '2', '3', '2', '3', '1', '1', '2']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gold</td>\n",
       "      <td>2</td>\n",
       "      <td>['2', '2', '4', '2', '2', '1', '1', '1']</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1', '1', '1', '1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate the verifiability ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- 261&amp;272: any reason you did not consider the...</td>\n",
       "      <td>ACL_2017_516_review</td>\n",
       "      <td>ACL_2017</td>\n",
       "      <td>Missing related work on anchor words Evaluatio...</td>\n",
       "      <td>['1', '5', '4', '1', '5', '3', '1', '5']</td>\n",
       "      <td>1.0</td>\n",
       "      <td>gold</td>\n",
       "      <td>2</td>\n",
       "      <td>['5', '5', '5', '5', '5', '5', '5', '5']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1', '1', '1', '1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['0', '0', '0', '0', '0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate the verifiability ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>- I wonder what is the total computational com...</td>\n",
       "      <td>NIPS_2020_486</td>\n",
       "      <td>NIPS_2020</td>\n",
       "      <td>- I wonder what is the total computational com...</td>\n",
       "      <td>['4', '3', '4']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silver</td>\n",
       "      <td>6</td>\n",
       "      <td>['2', '4', '3']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>140</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate this review point ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>- The authors write “In the base IOI circuit, ...</td>\n",
       "      <td>FbZSZEIkEU</td>\n",
       "      <td>ICLR_2025</td>\n",
       "      <td>- The experimental reports are lacking in many...</td>\n",
       "      <td>['4', '1', '2']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>['5', '5', '5']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>141</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate the verifiability ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>- L15: Again, too vague, certain RNNs work wel...</td>\n",
       "      <td>NIPS_2018_917</td>\n",
       "      <td>NIPS_2018</td>\n",
       "      <td>- Results on bAbI should be taken with a huge ...</td>\n",
       "      <td>['4', '4', '1']</td>\n",
       "      <td>4.0</td>\n",
       "      <td>silver</td>\n",
       "      <td>6</td>\n",
       "      <td>['5', '5', '5']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>142</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate the verifiability ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>104 it is said that every kernel can be descri...</td>\n",
       "      <td>NIPS_2021_895</td>\n",
       "      <td>NIPS_2021</td>\n",
       "      <td>The description of the method is somewhat uncl...</td>\n",
       "      <td>['5', '4', '5']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>silver</td>\n",
       "      <td>6</td>\n",
       "      <td>['5', '5', '5']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>gold</td>\n",
       "      <td>['0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>143</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate the verifiability ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>* The proposed method is not well-positioned i...</td>\n",
       "      <td>f5juXkyorf</td>\n",
       "      <td>ICLR_2024</td>\n",
       "      <td>* The proposed method is not well-positioned i...</td>\n",
       "      <td>['5', '3', '1']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>['3', '5', '5']</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>['1', '1']</td>\n",
       "      <td>1</td>\n",
       "      <td>silver</td>\n",
       "      <td>['0', '0', '0']</td>\n",
       "      <td>0</td>\n",
       "      <td>gold</td>\n",
       "      <td>144</td>\n",
       "      <td>&lt;｜begin▁of▁sentence｜&gt;&lt;｜User｜&gt;\\nYou are an expe...</td>\n",
       "      <td>Okay, so I need to evaluate this review point ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          review_point             paper_id  \\\n",
       "0    2) it only compares with some weak baselines i...  ARR_2022_123_review   \n",
       "1    2. The evaluation on the word analogy task see...  ACL_2017_318_review   \n",
       "2    - Also, since the dataset is artificially crea...  ARR_2022_236_review   \n",
       "3    1) The paper does not dig into the theory prof...  ACL_2017_554_review   \n",
       "4    - 261&272: any reason you did not consider the...  ACL_2017_516_review   \n",
       "..                                                 ...                  ...   \n",
       "139  - I wonder what is the total computational com...        NIPS_2020_486   \n",
       "140  - The authors write “In the base IOI circuit, ...           FbZSZEIkEU   \n",
       "141  - L15: Again, too vague, certain RNNs work wel...        NIPS_2018_917   \n",
       "142  104 it is said that every kernel can be descri...        NIPS_2021_895   \n",
       "143  * The proposed method is not well-positioned i...           f5juXkyorf   \n",
       "\n",
       "         venue                                     focused_review  \\\n",
       "0     ARR_2022  1) it uses different experiment settings (e.g....   \n",
       "1     ACL_2017  1. Presentation and clarity: important details...   \n",
       "2     ARR_2022  - My main criticism is that the \"mismatched\" i...   \n",
       "3     ACL_2017  1) The paper does not dig into the theory prof...   \n",
       "4     ACL_2017  Missing related work on anchor words Evaluatio...   \n",
       "..         ...                                                ...   \n",
       "139  NIPS_2020  - I wonder what is the total computational com...   \n",
       "140  ICLR_2025  - The experimental reports are lacking in many...   \n",
       "141  NIPS_2018  - Results on bAbI should be taken with a huge ...   \n",
       "142  NIPS_2021  The description of the method is somewhat uncl...   \n",
       "143  ICLR_2024  * The proposed method is not well-positioned i...   \n",
       "\n",
       "                                actionability  actionability_label  \\\n",
       "0                             ['3', '5', '1']                  NaN   \n",
       "1         ['1', '4', '1', '4', '2', '1', '2']                  1.0   \n",
       "2    ['2', '3', '3', '4', '5', '3', '2', '5']                  3.0   \n",
       "3    ['1', '2', '3', '2', '3', '1', '1', '2']                  1.0   \n",
       "4    ['1', '5', '4', '1', '5', '3', '1', '5']                  1.0   \n",
       "..                                        ...                  ...   \n",
       "139                           ['4', '3', '4']                  4.0   \n",
       "140                           ['4', '1', '2']                  NaN   \n",
       "141                           ['4', '4', '1']                  4.0   \n",
       "142                           ['5', '4', '5']                  5.0   \n",
       "143                           ['5', '3', '1']                  NaN   \n",
       "\n",
       "    actionability_label_type  batch                     grounding_specificity  \\\n",
       "0                        NaN      1                           ['4', '5', '5']   \n",
       "1                       gold      2       ['4', '5', '5', '4', '1', '1', '5']   \n",
       "2                       gold      2  ['2', '4', '4', '4', '5', '5', '2', '3']   \n",
       "3                       gold      2  ['2', '2', '4', '2', '2', '1', '1', '1']   \n",
       "4                       gold      2  ['5', '5', '5', '5', '5', '5', '5', '5']   \n",
       "..                       ...    ...                                       ...   \n",
       "139                   silver      6                           ['2', '4', '3']   \n",
       "140                      NaN      6                           ['5', '5', '5']   \n",
       "141                   silver      6                           ['5', '5', '5']   \n",
       "142                   silver      6                           ['5', '5', '5']   \n",
       "143                      NaN      6                           ['3', '5', '5']   \n",
       "\n",
       "     grounding_specificity_label  ...  \\\n",
       "0                            5.0  ...   \n",
       "1                            5.0  ...   \n",
       "2                            4.0  ...   \n",
       "3                            2.0  ...   \n",
       "4                            5.0  ...   \n",
       "..                           ...  ...   \n",
       "139                          NaN  ...   \n",
       "140                          5.0  ...   \n",
       "141                          5.0  ...   \n",
       "142                          5.0  ...   \n",
       "143                          5.0  ...   \n",
       "\n",
       "                            professional_tone professional_tone_label  \\\n",
       "0                             ['1', '1', '1']                       1   \n",
       "1         ['1', '1', '1', '1', '1', '1', '1']                       1   \n",
       "2    ['1', '1', '1', '1', '1', '1', '1', '1']                       1   \n",
       "3    ['1', '1', '1', '1', '1', '1', '1', '1']                       1   \n",
       "4    ['1', '1', '1', '1', '1', '1', '1', '1']                       1   \n",
       "..                                        ...                     ...   \n",
       "139                           ['1', '1', '1']                       1   \n",
       "140                           ['1', '1', '1']                       1   \n",
       "141                           ['1', '1', '1']                       1   \n",
       "142                           ['1', '1', '1']                       1   \n",
       "143                                ['1', '1']                       1   \n",
       "\n",
       "    professional_tone_label_type                               valid_point  \\\n",
       "0                           gold                                ['0', '0']   \n",
       "1                           gold       ['1', '0', '1', '0', '0', '0', '0']   \n",
       "2                           gold       ['0', '0', '0', '0', '0', '0', '0']   \n",
       "3                           gold  ['0', '0', '0', '0', '0', '0', '0', '0']   \n",
       "4                           gold       ['0', '0', '0', '0', '0', '0', '0']   \n",
       "..                           ...                                       ...   \n",
       "139                         gold                           ['0', '0', '0']   \n",
       "140                         gold                           ['0', '0', '0']   \n",
       "141                         gold                           ['0', '0', '0']   \n",
       "142                         gold                           ['0', '0', '0']   \n",
       "143                       silver                           ['0', '0', '0']   \n",
       "\n",
       "    valid_point_label  valid_point_label_type   id  \\\n",
       "0                   0                  silver    1   \n",
       "1                   0                    gold    2   \n",
       "2                   0                    gold    3   \n",
       "3                   0                    gold    4   \n",
       "4                   0                    gold    5   \n",
       "..                ...                     ...  ...   \n",
       "139                 0                    gold  140   \n",
       "140                 0                    gold  141   \n",
       "141                 0                    gold  142   \n",
       "142                 0                    gold  143   \n",
       "143                 0                    gold  144   \n",
       "\n",
       "                                                prompt  \\\n",
       "0    <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "1    <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "2    <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "3    <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "4    <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "..                                                 ...   \n",
       "139  <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "140  <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "141  <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "142  <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "143  <｜begin▁of▁sentence｜><｜User｜>\\nYou are an expe...   \n",
       "\n",
       "                                            generation predicted_score  \n",
       "0    Okay, so I need to evaluate this review point ...               5  \n",
       "1    Okay, so I need to evaluate the verifiability ...               3  \n",
       "2    Okay, so I need to evaluate this review point ...               3  \n",
       "3    Okay, so I need to evaluate the verifiability ...               1  \n",
       "4    Okay, so I need to evaluate the verifiability ...               3  \n",
       "..                                                 ...             ...  \n",
       "139  Okay, so I need to evaluate this review point ...               2  \n",
       "140  Okay, so I need to evaluate the verifiability ...               5  \n",
       "141  Okay, so I need to evaluate the verifiability ...               3  \n",
       "142  Okay, so I need to evaluate the verifiability ...               5  \n",
       "143  Okay, so I need to evaluate this review point ...               4  \n",
       "\n",
       "[144 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['verifiability_verification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_score\n",
       "3    105\n",
       "4     55\n",
       "2     13\n",
       "5     12\n",
       "1      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['helpfulness']['predicted_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = [ 'actionability', 'grounding_specificity', 'helpfulness', 'verifiability_verification']\n",
    "\n",
    "\n",
    "with open(f'qwen_r1_outputs.txt', 'w') as f:\n",
    "    for aspect in aspects:\n",
    "\n",
    "        label_column =  'verifiability' if aspect == 'verifiability_verification' else aspect\n",
    "        ## remove rows with nan values\n",
    "        data[aspect] = data[aspect].dropna(subset=['predicted_score'])\n",
    "        f.write('*' * 20 + f'{aspect}'+ '*' * 20 + '\\n')\n",
    "        f.write('number of samples: ' + str(len(data[aspect])) + '\\n')\n",
    "\n",
    "        predcts = data[aspect]['predicted_score'].values\n",
    "        labels = data[aspect][f'{label_column}_label'].values\n",
    "\n",
    "        stat_dict = get_stats(predcts, labels, label_column)\n",
    " \n",
    "\n",
    "        ## remove the acc from the dict, and for spearman, only include the correlation\n",
    "\n",
    "        for k,v in stat_dict.items():\n",
    "            if 'accuracy' in k:\n",
    "                continue\n",
    "            if 'spearman' in k:\n",
    "                v = v[0]\n",
    "            ## round the values\n",
    "            if isinstance(v, float):\n",
    "                v = round(v, 3)\n",
    "            f.write(f'{k}: {v}\\n')\n",
    "        f.write('-'*50+'\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
