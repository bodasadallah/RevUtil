review_id,source,focused_review,review_point,human_actionability,human_specificity,human_verifiability,human_politeness,Notes,llm_actionability,llm_politeness,llm_verifiability,llm_specificity
905,ICLR_2023_2312,"Weaknesses
1. Literature Review
The paper regrettably fails to acknowledge a vast body of related literature, on (i) intention-conditioned trajectory prediction, (ii) variational graph methods for trajectory prediction, and (iii) models that explicitly model social interactions for forecasting. At the very least, these references ought to be mentioned and discussed for a diligent representation of the research space, even if the methods are not directly compared against.
(i) Intention-Conditioned Trajectory Prediction:
[R1, R2, R3] talk about intention-conditioned trajectory prediction for autonomous vehicles. Apart from the data the methods are applied to, the architectures can be applicable to, and are relevant for, the problem being addressed here. Crucially, the DROGON paper defines intention explicitly (more on this in Weakness 2. below).
(ii) Variational Graph Methods:
[R4] from the Neurips I Can't Believe It's Not Better Workshop explicitly deals with graph conditional variational methods for multi-agent trajectory prediction. The results in that paper are very relevant for this research area and should be included.
(iii) Encoding Social Interactions:
Graph and other stochastic methods that encode social interactions between agents have been long applied to trajectory and behavior forecasating problems. [R5] explicitly incorporates a spatiotemporal graph for incorporating social interactions between agents. [R6] more recently explicitly takes a meta-learning approach for modeling the dynamics unique to a group for probabilistic forecasting. A sports team is a group, and if each team is viewed as having unique social dynamics resulting from the team's strategy then [R6]'s core modeling idea is directly applicable. The cue in [R6] terms is simply player location here. Their modeling of social influence of other agents is also permutation invariant, a limitation this paper claims about existing methods. References:
[R1] DROGON: A Trajectory Prediction Model based on Intention-Conditioned Behavior Reasoning - Choi et al.
[R2] Intention-Driven Trajectory Prediction for Autonomous Driving - Fan et al.
[R3] LOKI: Long Term and Key Intentions for Trajectory Prediction - Girase et al.
[R4] Graph Conditional Variational Models: Too Complex for Multiagent Trajectories? - Rudolph et al.
[R5] Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction - Mohamed et al.
[R6] Social Processes: Self-Supervised Meta-Learning over Conversational Groups for Forecasting Nonverbal Social Cues - Raman et al.
2. Unsupported claims and definitions
The paper doesn't actually define agent intentions and causality in the specific setting, so there is no reasonable way to evaluate whether the proposed method actually models intentions. The intention-conditioned trajectory works I've mentioned talk about intention over long- and short- time horizons, where e.g. the former is in terms of goal destinations. Here the paper is talking about team sports with player intentions but simply states that this results from communication. What does intention mean here? Also, the paper claims to model causal relationships, but I can't see any explicit causal factors modeled of learned in the graph structure. There might be other exogenous variables explaining trajectory behavior.
3. Notation
There are a few notational errors. For instance, the variable used for the sequence cannot be the same as the individual elements: x < t = [ x 1 , . . . ]
. See [R4] for this. In many places there exist grammatical errors and incomplete sentences. Please do a pass to fix these.","2. Unsupported claims and definitions The paper doesn't actually define agent intentions and causality in the specific setting, so there is no reasonable way to evaluate whether the proposed method actually models intentions. The intention-conditioned trajectory works I've mentioned talk about intention over long- and short- time horizons, where e.g. the former is in terms of goal destinations. Here the paper is talking about team sports with player intentions but simply states that this results from communication. What does intention mean here? Also, the paper claims to model causal relationships, but I can't see any explicit causal factors modeled of learned in the graph structure. There might be other exogenous variables explaining trajectory behavior.",-1.0,1.0,1.0,0.0,Do we need to include the full review as well?,-1,-1,-1,1
4732,NIPS_2020_1809,"- Note sure whether the authors intend to release code also upon acceptance but the statement in line 270 is a little unclear. If code is only available during the review phase, this is a clear minus. - The degree of novelty is pretty small as the framework is well known and only a tiny aspect is changed. - The paper contains a lot of known material on the one hand but has a lot of references to the Appendix which makes the paper a little hard to digest. I would suggest to remove textbook material on EP in favor of including some more material on the Wasserstein distance. - That said, I'm not sure whether the page on the locality property is enlightning and really surprising. This could in principle be part of the Appendix and leave more space for an algorithmic discussion of the required computations for the variance update. - EP suffers from stability problems when the moment updates are not numerically accurate e.g. as a result of quadrature approximations. I'm missing a discussion on the numerical aspects of the L2 Wasserstein distance computations. - I'm missing a discussion on the marginal likelihood and its accuracy. - I'm missing a discussion of whether and how further derivatives of the site update can be computed in order to perform marginal likelihood hyperparameter optimization. - I'm missing a discussion why values for p different from 2 are not interesting to consider. - The manuscript does not provide evidence whether the proposed divergence measure is better suited in cases where EP has ""deficiencies"" according to the authors. MCMC experiments have shown that EP with KL is surprisingly accurate. The paper lacks a comparison in this respect. The missing convergence proof for EP is clearly an issue but the 2nd and 3rd paragraph seem as if EP is a buggy approach per se. Please provide concise and concrete examples where EP with KL is problematic and demonstrate that EP with WD is any better.",- I'm missing a discussion why values for p different from 2 are not interesting to consider.,-1.0,1.0,0.0,0.0,nan,-1,1,-1,-1
612,ICLR_2021_971,"Weaknesses
The proposed algorithm is not parameter-free (unlike SNIP, which is virtually parameter-free), is quite complicated (and I imagine difficult to implement), and there is little justification for certain components of the method, e.g., the dynamic scaling function (and choices of lambda), whether the simplification of m_{t-1} = … = m_{T} is mild enough. It is not clear to me how a practitioner can run the proposed algorithm in a parameter-free way without having to conduct ablation studies of their own first, especially since, as the authors note, “We observed that the penalty parameter was difficult to tune properly, either being too aggressive at pruning, or too passive” as the justification for the dynamic scaling function
Parts of the paper are too dense and notation-heavy, and this hurts readability and understanding significantly, e.g., Lemma 1, paragraph regarding the introduction of the saliency function on pg. 2.
The presented experimental results are not very compelling. For example, in Table 3, we see that BEP 1e-4 achieves a ~.4% improvement over SNIP and GRASP, at the cost of ~7-8.4 more hours of training time. This calls into question the effectiveness of the proposed approach -- which is, at the end of the day, meant to speed up training + pruning by removing unnecessary components of the network early on. Clarity
The paper is reasonably well-written and organized overall. It was clear that the authors compressed some of the mathematical expressions/lemmas (e.g., statement of Lemma 1), which is somewhat understandable given the page limit, but this hurt readability and understandability.","2. The presented experimental results are not very compelling. For example, in Table 3, we see that BEP 1e-4 achieves a ~.4% improvement over SNIP and GRASP, at the cost of ~7-8.4 more hours of training time. This calls into question the effectiveness of the proposed approach -- which is, at the end of the day, meant to speed up training + pruning by removing unnecessary components of the network early on. Clarity The paper is reasonably well-written and organized overall. It was clear that the authors compressed some of the mathematical expressions/lemmas (e.g., statement of Lemma 1), which is somewhat understandable given the page limit, but this hurt readability and understandability.",-1.0,1.0,1.0,-1.0,nan,-1,0,1,1
3649,NIPS_2020_791,There are several issues here which I would like the authors to address: * Could the authors comment on the use percentile rank? I understand the reasoning behind it more or less but this is not explained in the paper at all. * What is the relationship between the CDF and percentile rank in this case? is there a way to express one with the other? * The experiments show that in a controlled setting (where a clear target patch and template patch are defined) it is possible to explain several illusions. One thing which is common to all the illusions is that the target patch is flat - what about cases where the patch to explain may have some structure? like the Kanitze triangle? this would make a much more convincing case for the method. * The authors show that the percentile rank correlates with the perceived *relative* lightness (for example) but they do not show if this is actually at the same scale of perception - do subjects report the same change in lightness perception? (I'm sure these numbers can be found in literature). * Only one generative model is tested here - do results change with other models? say a simple GMM or a sparse coding based one?,* What is the relationship between the CDF and percentile rank in this case? is there a way to express one with the other?,1.0,1.0,0.0,0.0,nan,0,0,0,0
4288,NIPS_2020_251,"* The NF assumption was not discussed as compared to a standard SSM which uses additive measurement noise. Placing the emission noise *before* the nonlinearity is a crucial move; otherwise filtering is not tractable. I would have appreciated further discussion of the impact of this. It's possible that this technique can be applied as a drop-in replacement in many models to avoid awkward approximations such as EKF, UKF and PF; however this conclusion is not immediate from the work presented in this paper. * As a simple example, consider a univariate example where $f$ is a sigmoid, and the true $z = -5$, hence $\E[y] ≈ 0$. If $y$ is observed with additive noise of +0.2, the inferred $z = f^{-1}(0.2) ≈ -1.4$, which may cause substantial problems for inference and learning. * The qualitative experiments seemed particularly artificial; I did not learn much here beyond the fact that the implementation broadly seems to work. If these are indicative of a real-world problem, it would be helpful to make this clearer. * NKF does not show markedly better performance than the GP-Copula model in the main experiments.",* NKF does not show markedly better performance than the GP-Copula model in the main experiments.,0.0,1.0,0.0,0.0,nan,-1,0,-1,-1
5529,NIPS_2020_1796,"While the result is interesting, many of the design decisions behind the models and training procedures seemed poorly motivated and discussion on their nuances lacking. - Why represent the rewards as a function of a VAE used to encode exploratory frames in the environment? How does more or less exploration impact the effect of the auxiliary rewards learned this way? - What is the impact of environment ordering during training? Are there any curriculum effects at play? Why train with such a curriculum in the first place? An ablation demonstrating the necessity of this approach would contextualize this decision. - The language stating ""the agent learns R_AUP"" was confusing (Line 138). The reviewer believes this language was meant to describe ""training the Q_i functions"" corresponding to each R_i. This confusing language was used in the caption for the reward learning curves in the supplementary materials, which seems supported by the statement starting on Line 202: ""In the supplementary material..."" - Some key concepts are not defined, for example ""initial state reachability"" (Line 42). - It seems the claim that safe reinforcement learning focuses on just avoiding negative side effects during training is inaccurate. As stated in the abstract of a paper the authors cite (García et al, 2015), safe RL is also concerned with safety at deployment. - The language is often unclear, e.g. Line 211: ""AUP stops moving entirely."" The reviewer believes this is referring to the AUP learning a policy in which the agent remains immobile. - The discussion around the theoretical results (3.2) does not add much insight to the experiments and results presented in the paper. - The contribution is not very novel, as it is simply applying AUP as presented in Turner et al, 2020 to another environment, with little to no modification. - Not clear why Lines 55-57 are included in the related work, as they do not seem particularly relevant to safe RL.","- The language is often unclear, e.g. Line 211: ""AUP stops moving entirely."" The reviewer believes this is referring to the AUP learning a policy in which the agent remains immobile.",-1.0,1.0,1.0,-1.0,nan,1,1,-1,1
3368,NIPS_2020_1285,- Only one constraint value is selected for each environment (50% of the speed attained by an unconstrained PPO agent - how and why was 50% chosen?). I would be interested in seeing whether FOCOPS consistently exceeds performance and satisfies constraints compared to other methods for different constraint levels. - Only one constraint is used for the experiments. How would FOCOPS perform empirically when there are multiple constraints?,- Only one constraint is used for the experiments. How would FOCOPS perform empirically when there are multiple constraints?,1.0,1.0,0.0,0.0,nan,1,1,-1,1
2693,NIPS_2019_436,"Weaknesses 1. Proposed method is relatively simple extension - involves using typical prototype for class in addition to transformation of class word-embeddings. 2. The benefit of incorporating semantic information is largely in the 5-class, 1-shot learning case (3.5% Mini-Imagenet and 2.75% Tiered-Imagenet accuracy gain compared to state-of-the-art LEO applied to regular few-shot learning scenario) and there seems to be very little gain beyond that number of shots. Comments The proposed setting and method requires that word embeddings are known for all train and test classes. Is it a more realistic scenario for few-shot learning that word-embeddings are only available for train classes, as this removes requirement that model that can only be used to learn about concepts that we already have word-embeddings for? Is semantic information as defined in paper applicable to few-shot settings beyond image-classification?","2. The benefit of incorporating semantic information is largely in the 5-class, 1-shot learning case (3.5% Mini-Imagenet and 2.75% Tiered-Imagenet accuracy gain compared to state-of-the-art LEO applied to regular few-shot learning scenario) and there seems to be very little gain beyond that number of shots. Comments The proposed setting and method requires that word embeddings are known for all train and test classes. Is it a more realistic scenario for few-shot learning that word-embeddings are only available for train classes, as this removes requirement that model that can only be used to learn about concepts that we already have word-embeddings for? Is semantic information as defined in paper applicable to few-shot settings beyond image-classification?",-1.0,1.0,1.0,0.0,nan,-1,1,0,1
4026,NIPS_2020_159,"UPDATE: Thank you for your response, which addressed most of my concerns. The only issue is that only controlling the number of leaves can still be problematic since the depth of the also matters [1]. [1] Reyzin L, Schapire RE. How boosting the margin can also boost classifier complexity, ICML 2006. ============================= I have several concerns and questions: 1. Line 97: what does “same size” mean? We know that in order to make a fair comparison, we must make sure that the model complexity of base learners is the same. For decision trees, does it mean the same number of leaves? To me, the best way could be just using a decision stump as a base learner. 2. The empirical results are also not convincing to me: 1) the results are only averaged over three runs, which is insufficient to me. 2) I would also like to see the standard deviations of the average accuracies. 3) The experiments are only evaluated on one data set. To make the conclusion more convicting, the author should make a comparison on more data sets. 4) I was also wondering if the conclusion still holds with other base learners. 3. We know that AdaBoost is just a special case of gradient boosting with the exponential loss. Therefore, my feeling is that the analysis is just about the gradient boosting with different loss functions, not the behavior of gradient boosting itself.","1. Line 97: what does “same size” mean? We know that in order to make a fair comparison, we must make sure that the model complexity of base learners is the same. For decision trees, does it mean the same number of leaves? To me, the best way could be just using a decision stump as a base learner.",1.0,1.0,1.0,1.0,nan,1,-1,-1,1
1193,ICLR_2023_1294,"weaknesses:
1: The best feature of CLIP is the generality, that is, being able to recognize any image without pre-defined/fixed classes. MUST adapt the CLIP model to a specific dataset (which is the main purpose of this paper). A simple solution is claimed by authors in the limitation section: ""There exists a simple way to address this concern: gather unlabeled image from all the domains of interest, and perform MUST to learn a single model that can generalize to multiple domains."" It would be really great to have 1-2 such experiments to verify this hypothesis.
Minor weaknesses:
2: The paper does not reach out to theoretical backup to explain why MUST works.
3: Adding results on ImageNet-Sketch will further strengthen this paper.
4: A related work [1] is worth discussing.
[1]: Test-time training with masked autoencoders, NeurIPS 2022","4: A related work [1] is worth discussing. [1]: Test-time training with masked autoencoders, NeurIPS 2022",1.0,1.0,1.0,1.0,nan,-1,1,1,-1
2578,NIPS_2019_1348,"Weaknesses: 0. My first concern is the assumption that a human risk measure is gold standard when it comes to fairness. There are many reasons to question this assumption. First, humans are the worst random number generators, e.g. the distribution over random integers from 1 to 10 is highly skewed in the center. Similarly, if humans perceive a higher risk in the tails of a distribution, it doesn't necessarily mean that minimizing such risk makes the model fair. This still needs to be discussed and proven. 1. The paper suggests that using EHRM has fairness implications. These fairness implications are obtained as a side effect of using different hyperparameter setting for the skewness of the human risk distribution. There is no direct relationship between fairness consideration and the risk metric used. 2. In the Introduction, the authors choose to over-sell their work by presenting their work as a ""very natural if simple solution to addressing these varied desiderata"" where the desiderata include ""fairness, safety, and robustness"". This is a strong statement but incorrect at the same time. The paper lacks any connection between these objectives and the proposed risk metric. One could try to investigate these connections before claiming to address them. 3. One example of connection would be the definition of Calibration used in, for example, Kleinberg et al. and connect it to a human calibration measure and derive a Human risk objective from there as well. It is a straightforward application but the work lacks that. 4. There are no comparison baselines even when applying to a fairness problem which has a number of available software to get good results. Agarwal 2018: ""A Reductions Approach to Fair Classification"" is seemingly relevant as it reduces fairness in classification to cost-sensitive learning. In this case, the weighting is done on the basis of the loss and not the group identities or class values, but it may be the reason why there is a slight improvement in fairness outcomes. Since the EHRM weights minorities higher, it might be correlated to the weights under a fair classification reduction and hence giving you slight improvements in fairness metrics. 5. There were a few typos and some other mistakes: - doomed -> deemed (Line50) - Line 74: Remove hence. The last line doesn't imply this sentence. It seems independent. ",1. The paper suggests that using EHRM has fairness implications. These fairness implications are obtained as a side effect of using different hyperparameter setting for the skewness of the human risk distribution. There is no direct relationship between fairness consideration and the risk metric used.,0.0,1.0,-1.0,0.0,nan,-1,1,0,-1
2606,NIPS_2019_1408,"Weaknesses: - The paper is not that original given the amount of work in learning multimodal generative models:   â For example, from the perspective of the model, the paper builds on top of the work by Wu and Goodman (2018) except that they learn a mixture of experts rather than a product of experts variational posterior.   â In addition, from the perspective of the 4 desirable attributes for multimodal learning that the authors mention in the introduction, it seems very similar to the motivation in the paper by Tsai et al. Learning Factorized Multimodal Representations, ICLR 2019, which also proposed a multimodal factorized deep generative model that performs well for discriminative and generative tasks as well as in the presence of missing modalities. The authors should have cited and compared with this paper. ****************************Quality**************************** Strengths: - The experimental results are nice. The paper claims that their MMVAE modal fulfills all four criteria including (1) latent variables that decompose into shared and private subspaces, (2) be able to generate data across all modalities, (3) be able to generate data across individual modalities, and (4) improve discriminative performance in each modality by leveraging related data from other modalities. Let's look at each of these 4 in detail:   â (1) Yes, their model does indeed learn factorized variables which can be shown by good conditional generation on MNIST+SVHN dataset.   â (2) Yes, joint generation (which I assume to mean generation from a single modality) is performed on vision -> vision and language -> language for CUB,   â (3) Yes, conditional generation can be performed on CUB via language -> vision and vice versa.  Weaknesses: - (continuing on whether the model does indeed achieve the 4 properties that the authors describe)   â (3 continued) However, it is unclear how significant the performance is for both 2) and 3) since the authors report no comparisons with existing generative models, even simple ones such as a conditional VAE from language to vision. In other words, what if I forgo with the complicated MoE VAE, and all the components of the proposed model, and simply use a conditional VAE from language to vision. There are many ablation studies that are missing from the paper especially since the model is so complicated.   â (4) The authors have not seemed to perform extensive experiments for this criteria since they only report the performance of a simple linear classifier on top of the latent variables. There has been much work in learning discriminative models for multimodal data involving aligning or fusing language and vision spaces. Just to name a few involving language and vision:     - Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding, EMNLP 2016     - DeViSE: A Deep Visual-Semantic Embedding Model, NeurIPS 2013 Therefore, it is important to justify why I should use this MMVAE model when there is a lot of existing work on fusing multimodal data for prediction. ****************************Clarity**************************** Strengths: - The paper is generally clear. I particularly liked the introduction of the paper especially motivation Figures 1 and 2. Figure 2 is particularly informative given what we know about multimodal data and multimodal information. - The table in Figure 2 nicely summarizes some of the existing works in multimodal learning and whether they fulfill the 4 criteria that the authors have pointed out to be important. Weaknesses: - Given the authors' great job in setting up the paper via Figure 1, Figure 2, and the introduction, I was rather disappointed that section 2 did not continue on this clear flow. To begin, a model diagram/schematic at the beginning of section 2 would have helped a lot. Ideally, such a model diagram could closely resemble Figure 2 where you have already set up a nice 'Venn Diagram' of multimodal information. Given this, your model basically assigns latent variables to each of the information overlapping spaces as well as arrows (neural network layers) as the inference and generation path from the variables to observed data. Showing such a detailed model diagram in an 'expanded' or 'more detailed' version of Figure 2 would be extremely helpful in understanding the notation (which there are a lot), how MMVAE accomplishes all 4 properties, as well as the inference and generation paths in MMVAE. - Unfortunately, the table in Figure 2 it is not super complete given the amount of work that has been done in latent factorization (e.g. Learning Factorized Multimodal Representations, ICLR 2019) and purely discriminative multimodal fusion (i.e. point d on synergy) - There are a few typos and stylistic issues: 1. line 18: ""Given the lack explicit labels availableâ -> âGiven the lack of explicit labels availableâ 2. line 19: âcan provided importantâ -> âcan provide importantâ 3. line 25: âbetween (Yildirim, 2014) themâ -> âbetween them (Yildirim, 2014)â 4. and so onâ¦ ****************************Significance**************************** Strengths: - This paper will likely be a nice addition to the current models we have for processing multimodal data, especially since the results are quite interesting. - The paper did a commendable job in attempting to perform experiments to justify the 4 properties they outlined in the introduction. - I can see future practitioners using the variational MoE layers for encoding multimodal data, especially when there is missing multimodal data. Weaknesses: - That being said, there are some important concerns especially regarding the utility of the model as compared to existing work. In particular, there are some statements in the model description where it would be nice to have some experimental results in order to convince the reader that this model compares favorably with existing work: 1. line 113: You set \alpha_m uniformly to be 1/M which implies that the contributions from all modalities are the same. However, works in multimodal fusion have shown that dynamically weighting the modalities is quite important because 1) modalities might contain noise or uncertain information, 2) different modalities contribute differently to the prediction (e.g. in a video when a speaker is not saying anything then their visual behaviors are more indicative than their speech or language behaviors). Recent works therefore study, for example, gated attentions (e.g. Gated-Attention Architectures for Task-Oriented Language Grounding, AAAI 2018 or Multimodal Sentiment Analysis with Word-level Fusion and Reinforcement Learning, ICMI 2017) to learn these weights. How does your model compare to this line of related work, and can your model be modified to take advantage of these fusion methods? 2. line 145-146: ""We prefer the IWAE objective over the standard ELBO objective not just for the fact that it estimates a tighter bound, but also for the properties of the posterior when computing the multi-sample estimate."" -> Do you have experimental results that back this up? How significant is the difference? 3. line 157-158: ""needing M^2 passes over the respective decoders in total"" -> Do you have experimental runtimes to show that this is not a significant overhead? The number of modalities is quite small (2 or 3), but when the decoders are large recurrent of deconvolutional layers then this could be costly. ****************************Post Rebuttal**************************** The author response addressed some of my concerns regarding novelty but I am still inclined to keep my score since I do not believe that the paper is substantially improving over (Wu and Goodmann, 2018) and (Tsai et al, 2019). The clarity of writing can be improved in some parts and I hope that the authors would make these changes. Regarding the quality of generation, it is definitely not close to SOTA language models such as GPT-2 but I would still give the authors credit since generation is not their main goal, but rather one of their 4 defined goals to measure the quality of multimodal representation learning.",- The paper is generally clear. I particularly liked the introduction of the paper especially motivation Figures 1 and 2. Figure 2 is particularly informative given what we know about multimodal data and multimodal information.,0.0,1.0,0.0,1.0,nan,0,1,0,1
44,ICLR_2022_1016,"Weaknesses: 1. In this paper, Matrix Taylor Polynomial or Matrix Pade Approximation are used for forward propagations, while approximate Lyapunov equation is used for backward propagation. Although Table 1 and Table 2 show MTP/MPA and Lya require less matrix multiplication than NS iteration, which one is most important for fast matrix square root? To verify it, MTP/MPA+NS based BP and NS baed FP + Lya are suggested to be compared in terms of accuracy and running time. 2. For previous SVD-based and NS-based methods, computation processes for forward and backward propagations are consistent. However, this work adopts Matrix Taylor Polynomial or Matrix Pade Approximation for forward propagations and uses approximate Lyapunov equation for backward propagation, leading variance in forward and backward propagations. The authors would better make some discussions about this issue. 3. The authors claimed BP of MPA is both time and memory-consuming. [r1] tries to respectively use SVD and MTP/MPA as forward and backward propagations, where the authors show BP of MPA is efficient (as shown in Table 6). The authors would better make some discussions about it.
[r1] Why Approximate Matrix Square Root Outperforms Accurate SVD in Global Covariance Pooling? ICCV, 2021.
Other comments: 1. It is clear that MPA involves matrix inverse, which is very GPU-unfriendly. As stated in the paper: ""Moreover, we note that the matrix inverse can be avoided, as Eq. (13) can be more efficiently and numerically stably computed by solving the linear system"". The authors would better provide more detailed computation and analysis. 2. How to compute the coefficients of p m and q n
for the Matrix Pade Approximation in equation (12)? Do forward operations of MPA in Table 1 contain computation of coefficients p m and q n
? 3. Does Equation (2) lack a (·){sym} operation for / f r a c l U
? 4. Is equation (11) missing a term z^{k} in the left side? 5. I am not sure why sign(B) in equation (21) can be calculated as identity matrix? 6. P{M} and Q_{N} are used to approximate the Taylor series. If I am not misunderstanding, does I- Q_{N}^{-1}P_{M} replace Q_{N}^{-1}P_{M} in Eqn. (13)? and do the terms I-X replace X in Eqn. (12)?","3. The authors claimed BP of MPA is both time and memory-consuming. [r1] tries to respectively use SVD and MTP/MPA as forward and backward propagations, where the authors show BP of MPA is efficient (as shown in Table 6). The authors would better make some discussions about it. [r1] Why Approximate Matrix Square Root Outperforms Accurate SVD in Global Covariance Pooling? ICCV, 2021. Other comments:",1.0,1.0,1.0,1.0,nan,-1,0,1,-1
4854,NIPS_2020_653,"The key issue is in Eq. 6, which appears to indicate that the normalising flow transformation is applied at each timepoint independently. This renders the model somewhat trivial (a Kalman filter with nonlinear outputs), extensively studied (e.g. in the EKF literature). It is well known that linear dynamics in a Kalman filter is a discretisation of an underlying continuous dynamical system, and you could use unevenly spaced observations if desired. Here are some possible claims that would render the work more interesting: 1.) Inclusion of the Jacobean in the output transformation renders the ML solution a better characterisation of the Bayesian solution. 2.) Having a normalising flow that depends on the value of the Weiner process at all past time steps (which allows much richer temporal dependencies). 3.) Arguing that the presently described process is surprisingly effective, by looking at a more empirical examples, and comparing to SOTA performance from referenced papers. Eq 12 might do some of this, but it is extremely unclear.",1.) Inclusion of the Jacobean in the output transformation renders the ML solution a better characterisation of the Bayesian solution.,1.0,1.0,-1.0,1.0,nan,-1,0,-1,-1
4349,NIPS_2020_1636,"While the general idea of the paper is appealing and has been evaluated extensively, the presentation of the methodology is lacking in clarity at times. After reading section 3, some issues could have been addressed more clearly: • Regarding line 171/172: what do the authors mean by “regret reaches the plateau”? Can this be quantified? • If the tree is constructed as described, it is questionable that the leftmost leave is actually the ‘best’ leave. Can this be shown? • How is the problem treated that SVM can lead to many distinct areas in the described methodology? Consider the case of the 1D sine function and we have data points only at increments of pi. K-means would result in two clusters, i.e., the points with values +1 and -1, respectively. Then, SVM would potentially cluster the domain in the two classes resulting in alternating regions for each class. What would be the resulting domain for TuRBO then? In the very beginning, the authors mention that only deterministic objective functions are considered. It is not clear how this statement fits to the the main result: the optimization of policies on the MuJoCo tasks which are known to be inherently stochastic objectives. Does LA-MCTS depend on the deterministic assumption? If yes: why does it work well in practice on stochastic functions, and if not: Why assume it then? The empirical performance of LA-MCTS is impressive. However, the method combines many different building blocks and as such introduces many additional hyperparameters. Though an ablation study was performed, the performance of the method depends drastically on the choice of hyperparameters. As such, the practicability of the approach is limited as an additional layer of parameters needs to be tuned in addition to the BO parameters. It is not exactly clear, why the authors call their method ‘latent actions’ as these are just the decision boundaries from the SVM classifier. No theoretical work is presented. ------------------------------ After reading the authors response: Thank you for the detailed response to the raised concerns as well as the additional experiments. Tree construction: Being the best node in expectation is something different then being the best node. This should be made more clear in the main paper. Further, Figure 10 does not really help to make this issue more clear as for example the evaluated points are missing in the plot. How's the initial purple region selected when no data is available? Also, using a contour-plot to visualize the objective function would help to understand the figure better. Deterministic assumption: if no component depends on being deterministic, than I'd highly recommend removing this from the main paper in the beginning. Also, just using a sample mean of 5 rollouts does not lead to a deterministic function but just reduces the variance by a factor of 5, which can still be relatively high for RL tasks especially as the outcome does not necessarily follow a uni-modal distribution. Also, please make the use of multiple rollouts more transparent as this simplifies the RL problem drastically. Minor: Appendix A.1: Hit-and-Run and Gibbs sampling do not require the region to be a convex polytope. Overall: The approach presented in this paper shows great potential but the quality of the paper is not yet at the level of a top-tier conference.","• If the tree is constructed as described, it is questionable that the leftmost leave is actually the ‘best’ leave. Can this be shown?",1.0,1.0,1.0,1.0,nan,-1,-1,-1,1
4495,NIPS_2020_1367,"1) In my experience, it is commonly collapsed when training the network with BN directly normalized by moving statistics. Batch renormalization technique [1] can address this problem. If you have used batch renormalization in the experiments, it is better to cite it in the experimental part. If you used a new technique to avoid training from collapse, please give the details. [1] Ioffe,S. Batch renormalization: Towards reducing minibatch dependence in batch-normalized models. In Advances in neural information processing systems, pp. 1945–1953, 2017. 2) I think it might need more comparison/ablation experiments to show the characteristics of StochNorm. There are no experiments of comparing stochastic normalization to each branch batch normalization with the current mini-batch statistics or the moving statistics. The parameter selection probability $p$ is significant, and it is better to offer the parameter sensitivity analysis in the experiments. 3) StochNorm is orthogonal to other fine-tuning methods, which is claimed to be an advantage. However, when observing Table 3 and Table 4, I find the performances of L^2_SP + StochNorm and DETAL + StochNorm on dataset Stanford Cars is even inferior to that of single StochNorm, which might be inconsistent with the claim. 4) A typical NeurIPS paper commonly offers us insights with theoretically grounded analysis. This work is relatively weak in this aspect.",4) A typical NeurIPS paper commonly offers us insights with theoretically grounded analysis. This work is relatively weak in this aspect.,-1.0,-1.0,0.0,1.0,nan,0,0,-1,0
5529,NIPS_2020_1796,"While the result is interesting, many of the design decisions behind the models and training procedures seemed poorly motivated and discussion on their nuances lacking. - Why represent the rewards as a function of a VAE used to encode exploratory frames in the environment? How does more or less exploration impact the effect of the auxiliary rewards learned this way? - What is the impact of environment ordering during training? Are there any curriculum effects at play? Why train with such a curriculum in the first place? An ablation demonstrating the necessity of this approach would contextualize this decision. - The language stating ""the agent learns R_AUP"" was confusing (Line 138). The reviewer believes this language was meant to describe ""training the Q_i functions"" corresponding to each R_i. This confusing language was used in the caption for the reward learning curves in the supplementary materials, which seems supported by the statement starting on Line 202: ""In the supplementary material..."" - Some key concepts are not defined, for example ""initial state reachability"" (Line 42). - It seems the claim that safe reinforcement learning focuses on just avoiding negative side effects during training is inaccurate. As stated in the abstract of a paper the authors cite (García et al, 2015), safe RL is also concerned with safety at deployment. - The language is often unclear, e.g. Line 211: ""AUP stops moving entirely."" The reviewer believes this is referring to the AUP learning a policy in which the agent remains immobile. - The discussion around the theoretical results (3.2) does not add much insight to the experiments and results presented in the paper. - The contribution is not very novel, as it is simply applying AUP as presented in Turner et al, 2020 to another environment, with little to no modification. - Not clear why Lines 55-57 are included in the related work, as they do not seem particularly relevant to safe RL.","- It seems the claim that safe reinforcement learning focuses on just avoiding negative side effects during training is inaccurate. As stated in the abstract of a paper the authors cite (García et al, 2015), safe RL is also concerned with safety at deployment.",-1.0,1.0,1.0,1.0,nan,-1,1,1,-1
2297,ACL_2017_71_review.json,"Weaknesses:  -The explanation of methods in some paragraphs is too detailed and there is no mention of other work and it is repeated in the corresponding method sections, the authors committed to address this issue in the final version. 
  -README file for the dataset [Authors committed to add README file] - General Discussion:  - Section 2.2 mentions examples of DBpedia properties that were used as features. Do the authors mean that all the properties have been used or there is a subset? If the latter please list them. In the authors' response, the authors explain in more details this point and I strongly believe that it is crucial to list all the features in details in the final version for clarity and replicability of the paper. 
  - In section 2.3 the authors use Lample et al. Bi-LSTM-CRF model, it might be beneficial to add that the input is word embeddings (similarly to Lample et al.)  - Figure 3, KNs in source language or in English? ( since the mentions have been translated to English). In the authors' response, the authors stated that they will correct the figure. 
  - Based on section 2.4 it seems that topical relatedness implies that some features are domain dependent. It would be helpful to see how much domain dependent features affect the performance. In the final version, the authors will add the performance results for the above mentioned features, as mentioned in their response. 
  - In related work, the authors make a strong connection to Sil and Florian work where they emphasize the supervised vs. unsupervised difference. The proposed approach is still supervised in the sense of training, however the generation of training data doesn’t involve human interference ","- Section 2.2 mentions examples of DBpedia properties that were used as features. Do the authors mean that all the properties have been used or there is a subset? If the latter please list them. In the authors' response, the authors explain in more details this point and I strongly believe that it is crucial to list all the features in details in the final version for clarity and replicability of the paper.",1.0,1.0,1.0,1.0,nan,1,1,1,1
3735,NIPS_2020_1660,"- The work heavily builds on the previous work of Cutkosky and Orabona [10]. In particular, the power of the proposed BCO method really relies on the paramter-free nature of the scale learning interface in ""Interface 3"". So this diminishes its significance from the side of technical contributions. - In line 72, the authors argue two new ideas ""appropriate surrogate loss function"" and ""a new one-point gradient estimator with time-varying parameters"". I admit that the design of surrogate loss is clever, while the gradient estimator seems standard, with only a slight and nature twist for the problem. So it is not appropriate to emphasize much on that.","- In line 72, the authors argue two new ideas ""appropriate surrogate loss function"" and ""a new one-point gradient estimator with time-varying parameters"". I admit that the design of surrogate loss is clever, while the gradient estimator seems standard, with only a slight and nature twist for the problem. So it is not appropriate to emphasize much on that.",1.0,1.0,1.0,1.0,nan,-1,-1,-1,1
1353,ICLR_2023_3031,"Weaknesses: - The technique seems to be in its early stages and it seems as if tuning needs to be performed for every new dynamical system and setting. First, the different training phases are difficult to follow and makes me wondering if the pipeline is robust enough. Also, please explain how was chosen to use a 4-layer U-Net for the Lorenz-63 and only a 3-layer U-Net for the Lorenz-96. - Network structure: it is not clear which losses are minimized at the different phases, in particular, the perturbator+flow operator is not clear. From eq. 11, it looks as if the dynamics and the data fidelity losses were applied on the same current state x_hat, while my understanding was that L_rec was calculated on the perturbator's output while L_dyn was calculated on the flow operator's output. If the hybrid loss is calculated on the final output of the 2 blocks, I don't se how we can enforce the decoupling of the two goals as stated. - It is difficult to understand the size of the input data and latent data. In particular, please give axis labels on Figure 1 images, as it first looks like a 2D spatial problem, while later it is explained that the input is of size time and location. Please also clarify what does T represent in Figure 2: I guess the time dimension, and in this case where is the location dimension? - Please explain best the following sentence: 'For the case in which the prior dynamics are unbiased': in a real setting, how can we know if the prior dynamics are biased or not? - 'espilon(t) represents the white Gaussian noise.' --> isn't it reductive? - Why stopping at 8 and 10 blocks for the experiments, while it looks as if the results are always improving with more blocks?
Typos: Specifically, The perturbator
The perturbator uses the observations and labels it has learned to perturb the reconstructed states to make it deviate from the original flow --> please rephrase
Figure 3: the color do not match Figure 1, as here the colors are also linked to training/no training. Maybe use another sign to indicate training/no training, as a red line surrounding the box.",- 'espilon(t) represents the white Gaussian noise.' --> isn't it reductive?,-1.0,1.0,-1.0,-1.0,nan,-1,-1,-1,-1
1451,ICLR_2023_2368,"Weaknesses: 1. There is no theoretical guarantee that the discoveries resulting from the sparse network architecture are unique. 2. The paper missed the description of how to quantify the top-k frequent interaction pairs, which is discussed in section 5.4. As the paper claims, one advantage of this framework is novel discovery. However, very limited results and discussions are presented here. 3. It lacks model complexity analysis and comparison. Given different levels of biological entities' intra and inter interactions, I am worried about the model's real applicability.","2. The paper missed the description of how to quantify the top-k frequent interaction pairs, which is discussed in section 5.4. As the paper claims, one advantage of this framework is novel discovery. However, very limited results and discussions are presented here.",1.0,1.0,1.0,1.0,nan,1,1,-1,1
4223,NIPS_2020_1003,"1. The study among different adversarially trained models is missing, thus the trade-off is unclear among robust trained models. For example, the TRADES model may improve both the robustness and back-door robustness. 2. Following the point above, it is unclear whether the trade-off still holds when the models that are partially adversarial robust. Since the results are present in two extreme without the middle results. For example, models with 10%,20%, 30% adversarial robustness accuracy. A curve with some reasonable resolution is needed to show the trade-off. 3. Experiment details missing. It is unclear to the reviewer whether the data for the adversarial training is poisoned or not. Would adversarial training still work under poison data? Would that mean successful backdoor attack (weak back-door robustness) also reduce the adversarial robustness? Maybe a figure showing the trade-off under this setting is missing. 4. Too few steps of attack for adversairal attack (only 5 to 10 steps), it is may not access the true adversarial robustness.","1. The study among different adversarially trained models is missing, thus the trade-off is unclear among robust trained models. For example, the TRADES model may improve both the robustness and back-door robustness.",1.0,1.0,1.0,1.0,nan,-1,1,-1,-1
5339,NIPS_2020_1039,"1) It could be better if a more comprehensive comparison of the asymptotic performances among on/off-policy methods. Off policy methods enjoy better sample efficiency at the cost of higher computation burden. Maybe an additional table could be provided in the appendix. Personally, I don’t actually expect a gap between the on/off-policy methods. 2) Although the usage of current f-function in the f-divergence is justified, it will still be interesting to see a comparison if the alternative f-functions were adopted. An empirical comparison would further justify the usage of the author’s current choice. Minor: 1) In eq. 12 (the proof of Lemma 2), in the third from the last line, the integration should be over \mathcal{S} \times \mathcal{S} instead of \mathcal{S} \times \mathcal{A} \times \mathcal{S}. 2) Notations in sec. 8.6 are inconsistent: sampling from \pi is switching back and forth between $a \sim \pi(s)$ and $a \sim \pi(\cdot | s)$. 3) At the end of Algorithm box 1, does J_{\nabla \theta} J_{reg} (\pi_{\theta}) intends to mean that the gradient of \theta on J_{reg}? 4) Can the authors slightly justify the first equation in sec. 3.2? Why is that an equality instead of an inequality?","1) In eq. 12 (the proof of Lemma 2), in the third from the last line, the integration should be over \mathcal{S} \times \mathcal{S} instead of \mathcal{S} \times \mathcal{A} \times \mathcal{S}.",1.0,1.0,1.0,1.0,nan,1,0,1,1
4364,NIPS_2020_285,"- In Section 2, it is assumed that the state and action spaces are finite. Is this assumption really necessary? It might be quite limiting since policy gradient methods are typically employed when dealing with continuous state-action spaces. Moreover, the transition model is defined as deterministic. Is this assumption necessary? - Proposition 6: I am a little confused about the notation. Equation (13) employs the improvement operator for the value-based case, but the remark in the subsequent line is stated for the improvement operator for the trajectory-based case. - Proposition 5: This is more curiosity than an issue. Are there some sufficient conditions to enforce that Var(R) > 0 along the whole learning process? It seems to me that as we get close to the optimum we are going to prefer less stochastic policies, thus we slow down convergence. Do you think we can still converge asymptotically if deterministic policies are allowed? Anyway, in policy search, we could even limit to stochastic policies. Maybe in such a case, we can have a non-zero guaranteed improvement and, consequently, converge in a finite number of iterations. I think the paper would greatly benefit from a discussion on these points. - Proposition 2: This is also a curiosity. The optimal policy, in the considered policy space, is a fixed point of the operator. There can be other fixed points? If so, do the authors think that is possible to characterize the space of fixed-points? Are there some conditions under which the fixed point is unique? ***Minor*** - lines 50 and 62: s_{t_1} -> s_{t+1} - Equation (3) goes beyond margins - line 64: reporting the formal definition of d^\pi might help - Equation (24) there should be a \propto instead of = - Proposition 5: there should be a statement, not just a formula - The notation of Proposition 9 does not match that used in the proof (z vs f(R)) - Figure 2: not very readable in grayscale, I suggest using different linestyles or markers","- Proposition 6: I am a little confused about the notation. Equation (13) employs the improvement operator for the value-based case, but the remark in the subsequent line is stated for the improvement operator for the trajectory-based case.",0.0,1.0,1.0,0.0,nan,-1,1,1,1
4874,NIPS_2020_62,"- The paper's narrative is based around POMDPs, but the experimental evaluation does not really stress the capability of the method in that respect. Evaluation is done on pixel-based control, which is PO of course, but we have know that a lagged observation of a few time-steps can make the state fully observable quickly. (See the appendix of [1]). Hence, we do not know how the method fares in environments where the state uncertainty has to be actively reduced by the agent. Therefore I think the paper overstates the results. It is easy to get out of this, however, since one can just drop the POMDP claim. - The justification of the overall approach could have been improved. For me personally (and the optimal control community) it is obvious that we want some kind of state estimation when we use control, as most–if not all–practical problems are PO. But the paper could have done a much better job at its justification. E.g. a very noisy sensor that requires a few time steps waiting to correctly estimate a quantity makes such approaches necessary. The authors suffer from the fact that the RL community is somewhat focused on Mujoco-like benchmarks, which are representative of only a very small fraction of practical optimal control problems. But the authors could have chosen to use a different suite of environments, such as EscapeRoomba or MountainHike, which would illustrate this. If the authors had chosen to conduct experiments that tackle much more relevant POMDP problems, I'd have given an increased score. - I would have enjoyed an ablation whether AISOC/MaxEnt is necessary. [1] **CURL: Contrastive Unsupervised Representations for Reinforcement Learning** Michael Laskin*, Aravind Srinivas*, Pieter Abbeel. Thirty-seventh International Conference Machine Learning (ICML), 2020.","- The justification of the overall approach could have been improved. For me personally (and the optimal control community) it is obvious that we want some kind of state estimation when we use control, as most–if not all–practical problems are PO. But the paper could have done a much better job at its justification. E.g. a very noisy sensor that requires a few time steps waiting to correctly estimate a quantity makes such approaches necessary. The authors suffer from the fact that the RL community is somewhat focused on Mujoco-like benchmarks, which are representative of only a very small fraction of practical optimal control problems. But the authors could have chosen to use a different suite of environments, such as EscapeRoomba or MountainHike, which would illustrate this. If the authors had chosen to conduct experiments that tackle much more relevant POMDP problems, I'd have given an increased score.",1.0,1.0,1.0,1.0,nan,-1,1,-1,-1
4732,NIPS_2020_1809,"- Note sure whether the authors intend to release code also upon acceptance but the statement in line 270 is a little unclear. If code is only available during the review phase, this is a clear minus. - The degree of novelty is pretty small as the framework is well known and only a tiny aspect is changed. - The paper contains a lot of known material on the one hand but has a lot of references to the Appendix which makes the paper a little hard to digest. I would suggest to remove textbook material on EP in favor of including some more material on the Wasserstein distance. - That said, I'm not sure whether the page on the locality property is enlightning and really surprising. This could in principle be part of the Appendix and leave more space for an algorithmic discussion of the required computations for the variance update. - EP suffers from stability problems when the moment updates are not numerically accurate e.g. as a result of quadrature approximations. I'm missing a discussion on the numerical aspects of the L2 Wasserstein distance computations. - I'm missing a discussion on the marginal likelihood and its accuracy. - I'm missing a discussion of whether and how further derivatives of the site update can be computed in order to perform marginal likelihood hyperparameter optimization. - I'm missing a discussion why values for p different from 2 are not interesting to consider. - The manuscript does not provide evidence whether the proposed divergence measure is better suited in cases where EP has ""deficiencies"" according to the authors. MCMC experiments have shown that EP with KL is surprisingly accurate. The paper lacks a comparison in this respect. The missing convergence proof for EP is clearly an issue but the 2nd and 3rd paragraph seem as if EP is a buggy approach per se. Please provide concise and concrete examples where EP with KL is problematic and demonstrate that EP with WD is any better.",- EP suffers from stability problems when the moment updates are not numerically accurate e.g. as a result of quadrature approximations. I'm missing a discussion on the numerical aspects of the L2 Wasserstein distance computations.,1.0,1.0,1.0,1.0,nan,-1,1,-1,-1
3549,NIPS_2020_1360,"The idea of the paper is simple and the motivation of the approach is well justified. However i have some concerns on the novelty of the work and the comparison with existing results. In particular I have the following concerns: Main Issues: I am concern regarding two of the main contributions of this work. I believe that some of the claims on the main contributions section are not novel. 1) The fact that the stochastic EG did not converge was shown with a counterexample in Chavdarova et al. [2]. However, in line 82, the authors mentioned that their approach on counterexample is an improvement because they show that the non-convergence persists for any error distribution with positive variance. In my opinion the proposal counterexample is not really a main contribution of this work. This work builds upon the counterexample of Chavdarova et al. [2] and use it to propose a convergent variant of the EG. 2) In line 55 the authors claim: ""Prior to our work, last-iterate convergence rate for bilinear min-max games had only been studied in the deterministic setting."" This is not true. In ICML 2020 Loizou et. al proposed the analysis of stochastic Hamiltonian methods showing last-iterate convergence for stochastic bilinear games and some classes of non-convex non-concave games. They also proposed a variance reduced method showing linear convergence (which is much faster then the O(1/t) rate of the DSEG in this setting). Other Issues: 3) The authors mentioned that the error bound condition is satisfied for two large classes of problems: Strongly monotone operators and Affine operators. However the definitions of the above two problems were never explicitly given. In addition for the affine operators it is mentioned that $\tau$ is the minimum non-zero singular value of the matrix. Which matrix? the authors need to be more rigorous. 4) In line 116 the authors start using capital letters for the notation (see $X_t$). until this point everything was lower case. 5) In experiments the only method presented is the DSEG with different values for $r_\gamma$ and $r_eta$. This is not adequate. The method should compare with other methods that guarantee convergence for the classes of games under study, like the stochastic Hamiltonian methods mentioned above. Even if the DSEG will be slower it will be really helpful for the reader. In addition the indicators of the lines in the Figure 3 are not distinguished (for colour-blind readers)",4) In line 116 the authors start using capital letters for the notation (see $X_t$). until this point everything was lower case.,0.0,1.0,0.0,0.0,nan,1,1,1,1
4732,NIPS_2020_1809,"- Note sure whether the authors intend to release code also upon acceptance but the statement in line 270 is a little unclear. If code is only available during the review phase, this is a clear minus. - The degree of novelty is pretty small as the framework is well known and only a tiny aspect is changed. - The paper contains a lot of known material on the one hand but has a lot of references to the Appendix which makes the paper a little hard to digest. I would suggest to remove textbook material on EP in favor of including some more material on the Wasserstein distance. - That said, I'm not sure whether the page on the locality property is enlightning and really surprising. This could in principle be part of the Appendix and leave more space for an algorithmic discussion of the required computations for the variance update. - EP suffers from stability problems when the moment updates are not numerically accurate e.g. as a result of quadrature approximations. I'm missing a discussion on the numerical aspects of the L2 Wasserstein distance computations. - I'm missing a discussion on the marginal likelihood and its accuracy. - I'm missing a discussion of whether and how further derivatives of the site update can be computed in order to perform marginal likelihood hyperparameter optimization. - I'm missing a discussion why values for p different from 2 are not interesting to consider. - The manuscript does not provide evidence whether the proposed divergence measure is better suited in cases where EP has ""deficiencies"" according to the authors. MCMC experiments have shown that EP with KL is surprisingly accurate. The paper lacks a comparison in this respect. The missing convergence proof for EP is clearly an issue but the 2nd and 3rd paragraph seem as if EP is a buggy approach per se. Please provide concise and concrete examples where EP with KL is problematic and demonstrate that EP with WD is any better.",- I'm missing a discussion of whether and how further derivatives of the site update can be computed in order to perform marginal likelihood hyperparameter optimization.,1.0,1.0,0.0,1.0,nan,-1,1,-1,-1
1261,ICLR_2023_4259,"Weaknesses
Linear latent dynamics have been used in object-centric models before
No quantitative evaluation with respect to object tracking
Several baselines missing
No ablations whether all the complex components are necessary
1. Novelty
I have some concerns about novelty here. Linearizing the latent dynamics is not a new idea. It's one of the main ideas behind Contrastive Predictive Coding (van den Oord 2018) and has been used in the context of object-centric video models in VideoMONet (Weis et al., JMLR 2021) for predicting the next frame. Although these works don't frame it in the language of Koopman operator theory, the main idea seems very similar. Thus, the novel idea in this work seems to me the interpretation and manipulation of the eigenvalues of the linear transition matrix. Shouldn't this also be possible with previous methods like VideoMONet?
2. Evaluation
The authors evaluate only with respect to reconstruction and all further demonstrations of manipulating the dynamics are only qualitative based on individual examples. However, object-centric models have problems tracking objects properly through occlusions (Weis et al. 2021). Thus, we don't know whether and how well the approach actually works except for individual hand-picked examples.
3. Ablations missing
The authors framework is a mix and match of components proposed in earlier works, such as object masks, occlusion modeling, separating appearance from pose, tracking objects and modeling their interactions. However, to what extent each of these components actually do what they promise and whether they are necessary for the problems studied by the authors remains unclear. Wouldn't a substantially simpler approach accomplish the same on such simple datasets? I think it would make much more sense to modify existing approaches by replacing only the component that models the latent dynamics and showing that performance can be retained while gaining interpretability or -- if this is not possible -- showing which other components are necessary to make the linear latent dyanmics possible.
4. Baselines
Several strong baselines for object-centric dynamic models like OP3 (Veerapaneni et al. 2020), VideoMONet (Weis et al. 2021) or SAVi (Kipf et al. 2022) seem to be missing.","4. Baselines Several strong baselines for object-centric dynamic models like OP3 (Veerapaneni et al. 2020), VideoMONet (Weis et al. 2021) or SAVi (Kipf et al. 2022) seem to be missing.",1.0,1.0,1.0,1.0,nan,-1,1,1,-1
2297,ACL_2017_71_review.json,"Weaknesses:  -The explanation of methods in some paragraphs is too detailed and there is no mention of other work and it is repeated in the corresponding method sections, the authors committed to address this issue in the final version. 
  -README file for the dataset [Authors committed to add README file] - General Discussion:  - Section 2.2 mentions examples of DBpedia properties that were used as features. Do the authors mean that all the properties have been used or there is a subset? If the latter please list them. In the authors' response, the authors explain in more details this point and I strongly believe that it is crucial to list all the features in details in the final version for clarity and replicability of the paper. 
  - In section 2.3 the authors use Lample et al. Bi-LSTM-CRF model, it might be beneficial to add that the input is word embeddings (similarly to Lample et al.)  - Figure 3, KNs in source language or in English? ( since the mentions have been translated to English). In the authors' response, the authors stated that they will correct the figure. 
  - Based on section 2.4 it seems that topical relatedness implies that some features are domain dependent. It would be helpful to see how much domain dependent features affect the performance. In the final version, the authors will add the performance results for the above mentioned features, as mentioned in their response. 
  - In related work, the authors make a strong connection to Sil and Florian work where they emphasize the supervised vs. unsupervised difference. The proposed approach is still supervised in the sense of training, however the generation of training data doesn’t involve human interference ","-The explanation of methods in some paragraphs is too detailed and there is no mention of other work and it is repeated in the corresponding method sections, the authors committed to address this issue in the final version. -README file for the dataset [Authors committed to add README file] - General Discussion:",1.0,1.0,1.0,0.0,nan,-1,0,NO_LABEL,-1
5776,NIPS_2018_600,"weakness of the non-local (NL) module [31] that the correlations across channels are less taken into account, and then formulate the compact generalized non-local (CGNL) module to remedy the issue through summarizing the previous methods of NL and bilinear pooling [14] in a unified manner. The CGNL is evaluated on thorough experiments for action and fine-grained classification tasks, exhibiting promising performance competitive to the state-of-the-arts. Positives: + The paper is well organized and easy to follow. + The generalized formulation (8,9) to unify bilinear pooling and non-local module is theoretically sound. + Good performance. Negatives: - Less discussion on the linear version of CGNL using dot product for f. - Missing fundamental comparison to the simple ResBlock. The authors nicely present the generalized formulation toward CGNL by unifying the two previous works of bilinear pooling and non-local module. Though the kernelized (non-linear) correlation function f is well theoretically motivated, the actual form of f that achieves the better empirical performance is a âlinearâ form (dot product). In this regard, the reviewer has the following concerns. - Less discussion about the linear form. If the reviewer correctly understands the CGNL formulation, the linear function f of dot product f (line 204) can greatly simplify the CGNL into Y = X * W_theta * tr[(X*W_phi)â * (X*W_g)] = X * W_theta * tr[(XâX)* W_g* W_phiâ]  = s * X * W_theta, where s = tr[(XâX) * W_g * W_phiâ]= tr[(XâX)* W] is just a scalar and W = W_g*W_phiâ. This reformulation would be beneficial from the following viewpoints. > It reduces the parameters from {W_theta, W_phi, W_g} to {W_theta, W}, which facilitates the implementation. > It is closely related to squeeze-and-excitation (SE) module [9]. The above formulation can be regarded as a bilinear extension of SE from âsqueezeâ viewpoint since it âsqueezesâ the feature map X into the bilinear form of XâX while SE simply employs an average-pooling.  Such discussions as above would help the readers to further understand the methods and to further extend the method. - Missing comparison. Based on the above discussion, one can think that the baseline for the linear CGNL is a simple ResBlock of Z = BatchNorm( X * W_z ) + X, while the linear CGNL is Z = BatchNorm( s * X * W_theta * W_z ) + X  = BatchNorm( s * X * W_tz ) + X. The only difference is the scaling factor s that is also build on X. Through batch normalization, such a scaling might be less effective (during the training) and thus by comparing these closely-related methods, the authors have to clarify its effectiveness of CGNL empirically. Due to this concern, the reviewer can not fairly evaluate the impact of the method on classification performance. [After Rebuttal] The reviewer appreciates the authorsâ efforts to perform the comparison experiments in such a short rebuttal period. The comparison with the standard ResBlock clarifies the effectiveness of the proposed method as well as helps us to further understand how it works. ",+ The paper is well organized and easy to follow.,0.0,0.0,0.0,0.0,nan,0,1,0,0
2297,ACL_2017_71_review.json,"Weaknesses:  -The explanation of methods in some paragraphs is too detailed and there is no mention of other work and it is repeated in the corresponding method sections, the authors committed to address this issue in the final version. 
  -README file for the dataset [Authors committed to add README file] - General Discussion:  - Section 2.2 mentions examples of DBpedia properties that were used as features. Do the authors mean that all the properties have been used or there is a subset? If the latter please list them. In the authors' response, the authors explain in more details this point and I strongly believe that it is crucial to list all the features in details in the final version for clarity and replicability of the paper. 
  - In section 2.3 the authors use Lample et al. Bi-LSTM-CRF model, it might be beneficial to add that the input is word embeddings (similarly to Lample et al.)  - Figure 3, KNs in source language or in English? ( since the mentions have been translated to English). In the authors' response, the authors stated that they will correct the figure. 
  - Based on section 2.4 it seems that topical relatedness implies that some features are domain dependent. It would be helpful to see how much domain dependent features affect the performance. In the final version, the authors will add the performance results for the above mentioned features, as mentioned in their response. 
  - In related work, the authors make a strong connection to Sil and Florian work where they emphasize the supervised vs. unsupervised difference. The proposed approach is still supervised in the sense of training, however the generation of training data doesn’t involve human interference ","- In related work, the authors make a strong connection to Sil and Florian work where they emphasize the supervised vs. unsupervised difference. The proposed approach is still supervised in the sense of training, however the generation of training data doesn’t involve human interference",-1.0,1.0,1.0,0.0,nan,-1,1,-1,-1
4170,NIPS_2020_490,"I think more details and discussion are needed to justify and evaluate some claims in the paper. 1. In Figure 5, it is said that ""two children spawned at an early time t_s in the chaotic training regime arrive at two different loss basins"", while ""two children spawned at a later time t_s in the stable training regime arrive at the same loss basin"". While I do agree with this claim, a simple explanation for it may just be that as t_s becomes larger, the distance between a child and its spawning parent becomes smaller and smaller. To see this, note that as the risk decreases, the gradient norm also becomes smaller, and the child is trained for T-t_s epochs, which also shrinks as t_s becomes larger since T seems to be fixed. Therefore we can expect the child and parent to eventually lie in the same basin as t_s becomes larger, and I wonder what is the new conclusion we can draw from this experiment. 2. In Figure 6, at the last points of the curves, is \tilde{t} equal to T? If so the green curves should meet the red curves since there is no additional training, while if not I wonder the details. Regarding the claim that the learned NTK can outperform full deep learning, it seems that the kernel can indeed drives the training error smaller, but the improvement in test error is very small and may be negative as in Figure 12. I also wonder if the curves in Figures 6, 11 and 12 represent the average of multiple parent and child runs?","2. In Figure 6, at the last points of the curves, is \tilde{t} equal to T? If so the green curves should meet the red curves since there is no additional training, while if not I wonder the details. Regarding the claim that the learned NTK can outperform full deep learning, it seems that the kernel can indeed drives the training error smaller, but the improvement in test error is very small and may be negative as in Figure 12. I also wonder if the curves in Figures 6, 11 and 12 represent the average of multiple parent and child runs?",1.0,1.0,1.0,0.0,nan,1,1,1,1
3649,NIPS_2020_791,There are several issues here which I would like the authors to address: * Could the authors comment on the use percentile rank? I understand the reasoning behind it more or less but this is not explained in the paper at all. * What is the relationship between the CDF and percentile rank in this case? is there a way to express one with the other? * The experiments show that in a controlled setting (where a clear target patch and template patch are defined) it is possible to explain several illusions. One thing which is common to all the illusions is that the target patch is flat - what about cases where the patch to explain may have some structure? like the Kanitze triangle? this would make a much more convincing case for the method. * The authors show that the percentile rank correlates with the perceived *relative* lightness (for example) but they do not show if this is actually at the same scale of perception - do subjects report the same change in lightness perception? (I'm sure these numbers can be found in literature). * Only one generative model is tested here - do results change with other models? say a simple GMM or a sparse coding based one?,* The authors show that the percentile rank correlates with the perceived *relative* lightness (for example) but they do not show if this is actually at the same scale of perception - do subjects report the same change in lightness perception? (I'm sure these numbers can be found in literature).,1.0,1.0,-1.0,-1.0,nan,-1,1,1,1
3556,NIPS_2020_936,"Weaknesses: - the paper could gain of having a thorough discussion on the generalization properties of the proposed learning procedure (and if no gain, that should be stated as well); - is is not clear how (not) stringent is Assumption 3 regarding the hypothesis classes, whereas it is key for the results provided; in addition the finite class claim related to floating point arithmetic could be developed a bit more; - it is not clear to me what the main strength of MixBoost is: -- is it related to the computational savings? -- is it related to the generalization performances of the method? -- is it related to the use of Random Fourier Features? - regarding Random Fourier Feature: wouldn't an even accelerated method such as Fastfood (Le et al. 2013) preferable to the sampling proposed here?","- the paper could gain of having a thorough discussion on the generalization properties of the proposed learning procedure (and if no gain, that should be stated as well); - is is not clear how (not) stringent is Assumption 3 regarding the hypothesis classes, whereas it is key for the results provided; in addition the finite class claim related to floating point arithmetic could be developed a bit more; - it is not clear to me what the main strength of MixBoost is: -- is it related to the computational savings? -- is it related to the generalization performances of the method? -- is it related to the use of Random Fourier Features?",1.0,1.0,1.0,1.0,nan,-1,1,1,-1
1707,ICLR_2023_1914,"Weaknesses (1) The framing of synergies and their neuroscientific context is somewhat lacking. The premise of the paper is that muscle synergies can be predicted from the cortical inputs, e.g. We applied our method to the corticomuscular system, which is made up of corticospinal pathways between the primary motor cortex and muscles in the body and creates muscle synergies that enable efficient connections between the brain and muscles.”, however synergies are thought to be generated in the spinal cord and some of their first characterization was in frogs, a species without a motor cortex. One reason this is problematic is that the paper is framed as revealing new synergies, e.g. “However, the conventional approach uses only muscle activities (observed phenomena) to capture the muscle synergies, and there may still be unexplored muscle synergies that remain hidden” However, based on the model design it seems like it should be detecting a subset of the muscle-only synergies. Moreover, synergies is largely defined in a muscle-centric way. It is certainly the case that discovering cortico-muscular shared synergies is interesting, but the framing is very different. (2) There are no details provided on the TCN training, and importantly how data was split up for train and test splits. This is especially important for the SCI experiments. (3) There are multiple alternative models that could be considered, for instance performing NNMF on a linear or nonlinear prediction of EMG from ecog activity. The specific motivation for the increased number of parameters and model structure of the TCN is not provided. One of the appeals of NNMF is its simplicity, allowing it to be used across paradigms and contexts, and this TCN introduces a lot of added complexity, with only minimal gains in VAF at high numbers of syneries. (4) For the SCI experiments – there is no ground truth present and so it is impossible to evaluate which technique is ‘correct’. As noted above, without knowledge of how much data is required for model training, it is hard to know if the increase in number of synergies observed is a result of
Nits: - ‘connectivity’ is misleading, as it isn’t using the structural connections between the brain and body. - Figure 6: would help to have an estimate of variance for the number of synergies, e.g. from using different subsets of data to train/test.","- ‘connectivity’ is misleading, as it isn’t using the structural connections between the brain and body.",-1.0,1.0,1.0,0.0,nan,-1,1,-1,1
2606,NIPS_2019_1408,"Weaknesses: - The paper is not that original given the amount of work in learning multimodal generative models:   â For example, from the perspective of the model, the paper builds on top of the work by Wu and Goodman (2018) except that they learn a mixture of experts rather than a product of experts variational posterior.   â In addition, from the perspective of the 4 desirable attributes for multimodal learning that the authors mention in the introduction, it seems very similar to the motivation in the paper by Tsai et al. Learning Factorized Multimodal Representations, ICLR 2019, which also proposed a multimodal factorized deep generative model that performs well for discriminative and generative tasks as well as in the presence of missing modalities. The authors should have cited and compared with this paper. ****************************Quality**************************** Strengths: - The experimental results are nice. The paper claims that their MMVAE modal fulfills all four criteria including (1) latent variables that decompose into shared and private subspaces, (2) be able to generate data across all modalities, (3) be able to generate data across individual modalities, and (4) improve discriminative performance in each modality by leveraging related data from other modalities. Let's look at each of these 4 in detail:   â (1) Yes, their model does indeed learn factorized variables which can be shown by good conditional generation on MNIST+SVHN dataset.   â (2) Yes, joint generation (which I assume to mean generation from a single modality) is performed on vision -> vision and language -> language for CUB,   â (3) Yes, conditional generation can be performed on CUB via language -> vision and vice versa.  Weaknesses: - (continuing on whether the model does indeed achieve the 4 properties that the authors describe)   â (3 continued) However, it is unclear how significant the performance is for both 2) and 3) since the authors report no comparisons with existing generative models, even simple ones such as a conditional VAE from language to vision. In other words, what if I forgo with the complicated MoE VAE, and all the components of the proposed model, and simply use a conditional VAE from language to vision. There are many ablation studies that are missing from the paper especially since the model is so complicated.   â (4) The authors have not seemed to perform extensive experiments for this criteria since they only report the performance of a simple linear classifier on top of the latent variables. There has been much work in learning discriminative models for multimodal data involving aligning or fusing language and vision spaces. Just to name a few involving language and vision:     - Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding, EMNLP 2016     - DeViSE: A Deep Visual-Semantic Embedding Model, NeurIPS 2013 Therefore, it is important to justify why I should use this MMVAE model when there is a lot of existing work on fusing multimodal data for prediction. ****************************Clarity**************************** Strengths: - The paper is generally clear. I particularly liked the introduction of the paper especially motivation Figures 1 and 2. Figure 2 is particularly informative given what we know about multimodal data and multimodal information. - The table in Figure 2 nicely summarizes some of the existing works in multimodal learning and whether they fulfill the 4 criteria that the authors have pointed out to be important. Weaknesses: - Given the authors' great job in setting up the paper via Figure 1, Figure 2, and the introduction, I was rather disappointed that section 2 did not continue on this clear flow. To begin, a model diagram/schematic at the beginning of section 2 would have helped a lot. Ideally, such a model diagram could closely resemble Figure 2 where you have already set up a nice 'Venn Diagram' of multimodal information. Given this, your model basically assigns latent variables to each of the information overlapping spaces as well as arrows (neural network layers) as the inference and generation path from the variables to observed data. Showing such a detailed model diagram in an 'expanded' or 'more detailed' version of Figure 2 would be extremely helpful in understanding the notation (which there are a lot), how MMVAE accomplishes all 4 properties, as well as the inference and generation paths in MMVAE. - Unfortunately, the table in Figure 2 it is not super complete given the amount of work that has been done in latent factorization (e.g. Learning Factorized Multimodal Representations, ICLR 2019) and purely discriminative multimodal fusion (i.e. point d on synergy) - There are a few typos and stylistic issues: 1. line 18: ""Given the lack explicit labels availableâ -> âGiven the lack of explicit labels availableâ 2. line 19: âcan provided importantâ -> âcan provide importantâ 3. line 25: âbetween (Yildirim, 2014) themâ -> âbetween them (Yildirim, 2014)â 4. and so onâ¦ ****************************Significance**************************** Strengths: - This paper will likely be a nice addition to the current models we have for processing multimodal data, especially since the results are quite interesting. - The paper did a commendable job in attempting to perform experiments to justify the 4 properties they outlined in the introduction. - I can see future practitioners using the variational MoE layers for encoding multimodal data, especially when there is missing multimodal data. Weaknesses: - That being said, there are some important concerns especially regarding the utility of the model as compared to existing work. In particular, there are some statements in the model description where it would be nice to have some experimental results in order to convince the reader that this model compares favorably with existing work: 1. line 113: You set \alpha_m uniformly to be 1/M which implies that the contributions from all modalities are the same. However, works in multimodal fusion have shown that dynamically weighting the modalities is quite important because 1) modalities might contain noise or uncertain information, 2) different modalities contribute differently to the prediction (e.g. in a video when a speaker is not saying anything then their visual behaviors are more indicative than their speech or language behaviors). Recent works therefore study, for example, gated attentions (e.g. Gated-Attention Architectures for Task-Oriented Language Grounding, AAAI 2018 or Multimodal Sentiment Analysis with Word-level Fusion and Reinforcement Learning, ICMI 2017) to learn these weights. How does your model compare to this line of related work, and can your model be modified to take advantage of these fusion methods? 2. line 145-146: ""We prefer the IWAE objective over the standard ELBO objective not just for the fact that it estimates a tighter bound, but also for the properties of the posterior when computing the multi-sample estimate."" -> Do you have experimental results that back this up? How significant is the difference? 3. line 157-158: ""needing M^2 passes over the respective decoders in total"" -> Do you have experimental runtimes to show that this is not a significant overhead? The number of modalities is quite small (2 or 3), but when the decoders are large recurrent of deconvolutional layers then this could be costly. ****************************Post Rebuttal**************************** The author response addressed some of my concerns regarding novelty but I am still inclined to keep my score since I do not believe that the paper is substantially improving over (Wu and Goodmann, 2018) and (Tsai et al, 2019). The clarity of writing can be improved in some parts and I hope that the authors would make these changes. Regarding the quality of generation, it is definitely not close to SOTA language models such as GPT-2 but I would still give the authors credit since generation is not their main goal, but rather one of their 4 defined goals to measure the quality of multimodal representation learning.","3. line 157-158: ""needing M^2 passes over the respective decoders in total"" -> Do you have experimental runtimes to show that this is not a significant overhead? The number of modalities is quite small (2 or 3), but when the decoders are large recurrent of deconvolutional layers then this could be costly. ****************************Post Rebuttal**************************** The author response addressed some of my concerns regarding novelty but I am still inclined to keep my score since I do not believe that the paper is substantially improving over (Wu and Goodmann, 2018) and (Tsai et al, 2019). The clarity of writing can be improved in some parts and I hope that the authors would make these changes. Regarding the quality of generation, it is definitely not close to SOTA language models such as GPT-2 but I would still give the authors credit since generation is not their main goal, but rather one of their 4 defined goals to measure the quality of multimodal representation learning.",1.0,1.0,1.0,1.0,nan,-1,1,-1,1
4026,NIPS_2020_159,"UPDATE: Thank you for your response, which addressed most of my concerns. The only issue is that only controlling the number of leaves can still be problematic since the depth of the also matters [1]. [1] Reyzin L, Schapire RE. How boosting the margin can also boost classifier complexity, ICML 2006. ============================= I have several concerns and questions: 1. Line 97: what does “same size” mean? We know that in order to make a fair comparison, we must make sure that the model complexity of base learners is the same. For decision trees, does it mean the same number of leaves? To me, the best way could be just using a decision stump as a base learner. 2. The empirical results are also not convincing to me: 1) the results are only averaged over three runs, which is insufficient to me. 2) I would also like to see the standard deviations of the average accuracies. 3) The experiments are only evaluated on one data set. To make the conclusion more convicting, the author should make a comparison on more data sets. 4) I was also wondering if the conclusion still holds with other base learners. 3. We know that AdaBoost is just a special case of gradient boosting with the exponential loss. Therefore, my feeling is that the analysis is just about the gradient boosting with different loss functions, not the behavior of gradient boosting itself.","3) The experiments are only evaluated on one data set. To make the conclusion more convicting, the author should make a comparison on more data sets.",1.0,-1.0,-1.0,0.0,nan,1,1,-1,-1
4568,NIPS_2020_812,"Significance and novelty of the contribution. Some of the assumptions that the authors then chose to make made the paper a less interestsing than I had hoped. making the investigation very deep, but narrow: * ...that mapping means creating some form of quantized top-down view of the environment. I don't see why a human readable map should be in any way optimal for a learnt system. Other work indeed shows you can decode a such a map from a hidden representation, but the choice of representation / architecture is very important for agent performance. * using MapNet as the one example of fully learn system. I appreciate that this choice might be motivated by the fact that the agent uses a mapping represenation compatible with the others leveraged in the paper. At the same time I think it is fair to say thatt the conclusions the authors derive from the experiments are not warranted. * the unusual reward structure using r_closer - what happens without this signal, in a setting that is less artificial? Overall I think the overall impact of the paper is limited by the artifically rescricted scope of the experiments. In particular, the conclusions about the learnt system are not convincing, because of the choice of agent design and representation, and lack of comparisons with baselines in the literature - that is, I think the results we see are like this because of the choice of agent, rather that something fundamental you have found. I would love if the authors could convince me otherwise in the rebutttal.",* using MapNet as the one example of fully learn system. I appreciate that this choice might be motivated by the fact that the agent uses a mapping represenation compatible with the others leveraged in the paper. At the same time I think it is fair to say thatt the conclusions the authors derive from the experiments are not warranted.,-1.0,1.0,-1.0,0.0,nan,-1,-1,-1,-1
5616,NIPS_2018_232,"weaknesses - Strengths: the paper is well-written and well-organized. It clearly positions the main idea and proposed approach related to existing work and experimentally demonstrates the effectiveness of the proposed approach in comparison with the state-of-the-art. - Weaknesses: the research method is not very clearly described in the paper or in the abstract. The paper lacks a clear assessment of the validity of the experimental approach, the analysis, and the conclusions. Quality - Your definition of interpretable (human simulatable) focuses on to what extent a human can perform and describe the model calculations. This definition does not take into account our ability to make inferences or predictions about something as an indicator of our understanding of or our ability to interpret that something. Yet, regarding your approach, you state that you are ânot trying to find causal structure in the data, but in the modelâs responseâ and that âwe can freely manipulate the input and observe how the model response changesâ. Is your chosen definition of interpretability too narrow for the proposed approach? Clarity - Overall, the writing is well-organized, clear, and concise. - The abstract does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what was the outcome. Minor language issues p. 95: âfrom fromâ -> âfromâ p. 110: âto toâ -> âhow toâ p. 126: âas wayâ -> âas a wayâ p. 182 âcan sortedâ -> âcan be sortedâ p. 197: âon directly onâ -> âdirectly onâ p. 222: âwhere wantâ -> âwhere we wantâ p. 245: âas accurateâ -> âas accurate asâ Tab. 1: âsquareâ -> âsquared errorâ p. 323: âthis are featuresâ -> âthis is featuresâ Originality - the paper builds on recent work in IML and combines two separate lines of existing work; the work by Bloniarz et al. (2016) on supervised neighborhood selection for local linear modeling (denoted SILO) and the work by Kazemitabar et al. (2017) on feature selection (denoted DStump). The framing of the problem, combination of existing work, and empirical evaluation and analysis appear to be original contributions. Significance - the proposed method is compared to a suitable state-of-the-art IML approach (LIME) and outperforms it on seven out of eight data sets. - some concrete illustrations on how the proposed method makes explanations, from a user perspective, would likely make the paper more accessible for researchers and practitioners at the intersection between human-computer interaction and IML. You propose a âcausal metricâ and use it to demonstrate that your approach achieves âgood local explanationsâ but from a user or human perspective it might be difficult to get convinced about the interpretability in this way only. - the experiments conducted demonstrate that the proposed method is indeed effective with respect to both accuracy and interpretability, at least for a significant majority of the studied datasets. - the paper points out two interesting directions for future work, which are likely to seed future research.",- Strengths: the paper is well-written and well-organized. It clearly positions the main idea and proposed approach related to existing work and experimentally demonstrates the effectiveness of the proposed approach in comparison with the state-of-the-art.,0.0,0.0,0.0,0.0,nan,-1,1,-1,1
493,ICLR_2022_1823,"Weaknesses
The main weakness is that the relationship between ADU and constituency tree is not clearly described. Is it true that ADU are often phrases that occur in the constituency tree? How often does this happen? Does the new BERT-based model adhere to constituency constraints? Is the BENEPAR parser appropriate for this data? Based on Trautmann et al.’s comments on grammaticality and clauses, my intuition is that an ADU is almost always a phrase in the tree, in which case it is somewhat less surprising that it helps this task (and maybe it should be helping even more). If this is the case, it’s worth considering related work in distant supervision to include.
The treatment of constituency trees is haphazard. 1) At times it is not clear if dependency or constituency trees are being used; 2) Table 1 should be made more clear, what do the percentage values indicate, and why not use the full tree at all; 3) It is worth adding to the related work more work in constituency tree representation, such as but not limited to Yang and Deng 2020 that also use GNN to represent constituency tree.
(low priority) Some technical details are concerning as described. For example, it is true that batching heterogeneous graphs may be somewhat more challenging than batching similar length sequences, but it is hard to believe this is one of the “major difficulties” of this work. If it is such a challenge, then it may have warranted further discussion about tradeoffs in architecture selection and impact on speed or performance.","3) It is worth adding to the related work more work in constituency tree representation, such as but not limited to Yang and Deng 2020 that also use GNN to represent constituency tree. (low priority) Some technical details are concerning as described. For example, it is true that batching heterogeneous graphs may be somewhat more challenging than batching similar length sequences, but it is hard to believe this is one of the “major difficulties” of this work. If it is such a challenge, then it may have warranted further discussion about tradeoffs in architecture selection and impact on speed or performance.",1.0,1.0,1.0,1.0,nan,-1,1,-1,-1
5616,NIPS_2018_232,"weaknesses - Strengths: the paper is well-written and well-organized. It clearly positions the main idea and proposed approach related to existing work and experimentally demonstrates the effectiveness of the proposed approach in comparison with the state-of-the-art. - Weaknesses: the research method is not very clearly described in the paper or in the abstract. The paper lacks a clear assessment of the validity of the experimental approach, the analysis, and the conclusions. Quality - Your definition of interpretable (human simulatable) focuses on to what extent a human can perform and describe the model calculations. This definition does not take into account our ability to make inferences or predictions about something as an indicator of our understanding of or our ability to interpret that something. Yet, regarding your approach, you state that you are ânot trying to find causal structure in the data, but in the modelâs responseâ and that âwe can freely manipulate the input and observe how the model response changesâ. Is your chosen definition of interpretability too narrow for the proposed approach? Clarity - Overall, the writing is well-organized, clear, and concise. - The abstract does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what was the outcome. Minor language issues p. 95: âfrom fromâ -> âfromâ p. 110: âto toâ -> âhow toâ p. 126: âas wayâ -> âas a wayâ p. 182 âcan sortedâ -> âcan be sortedâ p. 197: âon directly onâ -> âdirectly onâ p. 222: âwhere wantâ -> âwhere we wantâ p. 245: âas accurateâ -> âas accurate asâ Tab. 1: âsquareâ -> âsquared errorâ p. 323: âthis are featuresâ -> âthis is featuresâ Originality - the paper builds on recent work in IML and combines two separate lines of existing work; the work by Bloniarz et al. (2016) on supervised neighborhood selection for local linear modeling (denoted SILO) and the work by Kazemitabar et al. (2017) on feature selection (denoted DStump). The framing of the problem, combination of existing work, and empirical evaluation and analysis appear to be original contributions. Significance - the proposed method is compared to a suitable state-of-the-art IML approach (LIME) and outperforms it on seven out of eight data sets. - some concrete illustrations on how the proposed method makes explanations, from a user perspective, would likely make the paper more accessible for researchers and practitioners at the intersection between human-computer interaction and IML. You propose a âcausal metricâ and use it to demonstrate that your approach achieves âgood local explanationsâ but from a user or human perspective it might be difficult to get convinced about the interpretability in this way only. - the experiments conducted demonstrate that the proposed method is indeed effective with respect to both accuracy and interpretability, at least for a significant majority of the studied datasets. - the paper points out two interesting directions for future work, which are likely to seed future research.","- the experiments conducted demonstrate that the proposed method is indeed effective with respect to both accuracy and interpretability, at least for a significant majority of the studied datasets.",0.0,0.0,0.0,0.0,nan,-1,1,-1,-1
1212,ICLR_2023_4249,"Weaknesses: • The novelty of this paper might be slightly insufficient. My understanding is that the proposed model can be considered as an extension of previous GraphCL. Despite the introduction of cross-view reconstruction, it seems that cross-view reconstruction exists in previous graph representation learning studies. • The performance might be still somewhat limited. The authors compared many methods under different settings with GraphCV on multiple datasets. However, it can be found that GraphCV is comparable to or even underperforms the best baseline in many cases. While GraphCV has better performance than baselines in some cases, the advantages are not significant enough. Other questions: • Why are two data augmentation graphs needed? • The proposed model is involved in multiple losses. How to determine the weight values of different losses? Could the fixed weight values be generalized to different datasets?","• The performance might be still somewhat limited. The authors compared many methods under different settings with GraphCV on multiple datasets. However, it can be found that GraphCV is comparable to or even underperforms the best baseline in many cases. While GraphCV has better performance than baselines in some cases, the advantages are not significant enough. Other questions:",-1.0,1.0,1.0,0.0,nan,-1,0,-1,-1
4732,NIPS_2020_1809,"- Note sure whether the authors intend to release code also upon acceptance but the statement in line 270 is a little unclear. If code is only available during the review phase, this is a clear minus. - The degree of novelty is pretty small as the framework is well known and only a tiny aspect is changed. - The paper contains a lot of known material on the one hand but has a lot of references to the Appendix which makes the paper a little hard to digest. I would suggest to remove textbook material on EP in favor of including some more material on the Wasserstein distance. - That said, I'm not sure whether the page on the locality property is enlightning and really surprising. This could in principle be part of the Appendix and leave more space for an algorithmic discussion of the required computations for the variance update. - EP suffers from stability problems when the moment updates are not numerically accurate e.g. as a result of quadrature approximations. I'm missing a discussion on the numerical aspects of the L2 Wasserstein distance computations. - I'm missing a discussion on the marginal likelihood and its accuracy. - I'm missing a discussion of whether and how further derivatives of the site update can be computed in order to perform marginal likelihood hyperparameter optimization. - I'm missing a discussion why values for p different from 2 are not interesting to consider. - The manuscript does not provide evidence whether the proposed divergence measure is better suited in cases where EP has ""deficiencies"" according to the authors. MCMC experiments have shown that EP with KL is surprisingly accurate. The paper lacks a comparison in this respect. The missing convergence proof for EP is clearly an issue but the 2nd and 3rd paragraph seem as if EP is a buggy approach per se. Please provide concise and concrete examples where EP with KL is problematic and demonstrate that EP with WD is any better.",- I'm missing a discussion on the marginal likelihood and its accuracy.,1.0,1.0,-1.0,0.0,nan,-1,1,-1,-1
2578,NIPS_2019_1348,"Weaknesses: 0. My first concern is the assumption that a human risk measure is gold standard when it comes to fairness. There are many reasons to question this assumption. First, humans are the worst random number generators, e.g. the distribution over random integers from 1 to 10 is highly skewed in the center. Similarly, if humans perceive a higher risk in the tails of a distribution, it doesn't necessarily mean that minimizing such risk makes the model fair. This still needs to be discussed and proven. 1. The paper suggests that using EHRM has fairness implications. These fairness implications are obtained as a side effect of using different hyperparameter setting for the skewness of the human risk distribution. There is no direct relationship between fairness consideration and the risk metric used. 2. In the Introduction, the authors choose to over-sell their work by presenting their work as a ""very natural if simple solution to addressing these varied desiderata"" where the desiderata include ""fairness, safety, and robustness"". This is a strong statement but incorrect at the same time. The paper lacks any connection between these objectives and the proposed risk metric. One could try to investigate these connections before claiming to address them. 3. One example of connection would be the definition of Calibration used in, for example, Kleinberg et al. and connect it to a human calibration measure and derive a Human risk objective from there as well. It is a straightforward application but the work lacks that. 4. There are no comparison baselines even when applying to a fairness problem which has a number of available software to get good results. Agarwal 2018: ""A Reductions Approach to Fair Classification"" is seemingly relevant as it reduces fairness in classification to cost-sensitive learning. In this case, the weighting is done on the basis of the loss and not the group identities or class values, but it may be the reason why there is a slight improvement in fairness outcomes. Since the EHRM weights minorities higher, it might be correlated to the weights under a fair classification reduction and hence giving you slight improvements in fairness metrics. 5. There were a few typos and some other mistakes: - doomed -> deemed (Line50) - Line 74: Remove hence. The last line doesn't imply this sentence. It seems independent. ",- doomed -> deemed (Line50) - Line 74: Remove hence. The last line doesn't imply this sentence. It seems independent.,1.0,1.0,1.0,0.0,nan,1,0,0,1
44,ICLR_2022_1016,"Weaknesses: 1. In this paper, Matrix Taylor Polynomial or Matrix Pade Approximation are used for forward propagations, while approximate Lyapunov equation is used for backward propagation. Although Table 1 and Table 2 show MTP/MPA and Lya require less matrix multiplication than NS iteration, which one is most important for fast matrix square root? To verify it, MTP/MPA+NS based BP and NS baed FP + Lya are suggested to be compared in terms of accuracy and running time. 2. For previous SVD-based and NS-based methods, computation processes for forward and backward propagations are consistent. However, this work adopts Matrix Taylor Polynomial or Matrix Pade Approximation for forward propagations and uses approximate Lyapunov equation for backward propagation, leading variance in forward and backward propagations. The authors would better make some discussions about this issue. 3. The authors claimed BP of MPA is both time and memory-consuming. [r1] tries to respectively use SVD and MTP/MPA as forward and backward propagations, where the authors show BP of MPA is efficient (as shown in Table 6). The authors would better make some discussions about it.
[r1] Why Approximate Matrix Square Root Outperforms Accurate SVD in Global Covariance Pooling? ICCV, 2021.
Other comments: 1. It is clear that MPA involves matrix inverse, which is very GPU-unfriendly. As stated in the paper: ""Moreover, we note that the matrix inverse can be avoided, as Eq. (13) can be more efficiently and numerically stably computed by solving the linear system"". The authors would better provide more detailed computation and analysis. 2. How to compute the coefficients of p m and q n
for the Matrix Pade Approximation in equation (12)? Do forward operations of MPA in Table 1 contain computation of coefficients p m and q n
? 3. Does Equation (2) lack a (·){sym} operation for / f r a c l U
? 4. Is equation (11) missing a term z^{k} in the left side? 5. I am not sure why sign(B) in equation (21) can be calculated as identity matrix? 6. P{M} and Q_{N} are used to approximate the Taylor series. If I am not misunderstanding, does I- Q_{N}^{-1}P_{M} replace Q_{N}^{-1}P_{M} in Eqn. (13)? and do the terms I-X replace X in Eqn. (12)?","1. In this paper, Matrix Taylor Polynomial or Matrix Pade Approximation are used for forward propagations, while approximate Lyapunov equation is used for backward propagation. Although Table 1 and Table 2 show MTP/MPA and Lya require less matrix multiplication than NS iteration, which one is most important for fast matrix square root? To verify it, MTP/MPA+NS based BP and NS baed FP + Lya are suggested to be compared in terms of accuracy and running time.",1.0,1.0,1.0,1.0,nan,1,0,1,1
2040,ARR_2022_143_review,"Weak: 1. 	More examples are preferred to understand the motivations, the novel part of the proposed method and the baselines (see “detailed questions and comments”); 2. 	Some higher level comparisons, such as between parametric and non- parametric solutions are preferred. Currently, most baselines are in the same technical line of kNN-MT which is too narrow to reflect the strength of the proposed algorithms/networks. 
Detailed questions and comments: 1. 	Table 1, what are the hardware used? Model sizes? For “speed comparison”. 
2. 	Figure 1, what are the labels for horizontal and vertical axis? 
3. 	Lines 088 to 089, hard to understand why it is “intuitively” since the figure 1 is a 2D description of high-dimension features/distributions, do you have any detailed data/experiments to support this “intuitively”? 
4. 	Can you give real-world examples and attach them to your Figure 2? 
5. 	Figure 3, can you give example real tokens, instead of “token A”, “token B”? it is a bit difficult to understand what are the “negative, positive, pivot” arrows in this figure. 
6. 	Lines 170 to 171, “unreliable neighbors” any examples of “unreliable neighbors”? 
7. 	Line 458, is “0.18 BLEU” a significant improvement? Do not understand if it is “impressive result” or not. 
8. 	Table 6 is a bit difficult to understand. Can you first give references of using SP, LTP, HTP, and RP? Also why there are quite limit number of BLEU scores achieved by your “Ours method” higher than others? Can you also give speed/decoding comparison? Since based on this table, I am not sure why we shall rank your method to be higher than the other baselines. There is a big drop of from 46.94 to 46.03 of from “CKMT*” to “CKMT*+Ours”, any detailed analysis of this or any future work plan of this direction? 
9. 	Table 11, why “adaptive kNN-MT” output so many “wrong translations”? how there examples are selected? 
10. 	Section 2 “related work and background” is hard to understand. Intuitively, can you simply give a simple example of the difficulties of cross-domain translation (such as vocabulary difference, grammar difference and technical terms) and show that cluster based methods are helpful for this cross-domain translation. In addition, besides cluster based methods, can you also briefly summarize the major directions of dealing with “domain adaption for NMT”? if there is a comparison of among the major directions (not only other cluster-based methods), this paper will be ranked even higher (e.g., non-parameter solution vs. parameter solution for “domain adaption of MT”). ","10. Section 2 “related work and background” is hard to understand. Intuitively, can you simply give a simple example of the difficulties of cross-domain translation (such as vocabulary difference, grammar difference and technical terms) and show that cluster based methods are helpful for this cross-domain translation. In addition, besides cluster based methods, can you also briefly summarize the major directions of dealing with “domain adaption for NMT”? if there is a comparison of among the major directions (not only other cluster-based methods), this paper will be ranked even higher (e.g., non-parameter solution vs. parameter solution for “domain adaption of MT”).",1.0,1.0,1.0,1.0,nan,1,-1,0,1
914,ICLR_2023_1657,"Weaknesses:
The paper starts with grandiose claims of tackling ""open-ended learning"". However, open-ended learning involves learning to perform across diverse environments. But the definition of open-ended learning in this work seems restricted only to learning different skills in a given environment. In experiments, it is mostly restricted to goal conditioned environments and learning a goal conditioned policy.
""But where do goals come from? Almost always, they are sampled from a fixed distribution over a predefined goal space; i.e. they come from an engineer."" There are numerous works where the goals are NOT generated from a fixed distribution (listed in the references below)
The previous statement makes us believe that in this work, the goals are not generated from a fixed distribution. However, a few paragraphs later, the authors note that ""In this second challenge — the one we focus on — agents must learn to organize their own learning trajectories by prioritizing goals with the objective of maximizing long-term skill mastery."" i.e, this work focuses on learning a goal conditioned policy from pre-defined goals.
""In social episodes, a social partner suggests a novel goal to the agent and decomposes it into two consecutive sub-goals: 1) a frontier goal that the agent already discovered and, if it is reached, 2) a beyond goal never achieved by the agent but just beyond the its current abilities."" The social agent keeps a list of all the goals discovered so far and a list of all the goals to be reached. This is not tractable in most environments.
One of the contributions listed is: ""an active learning mechanism allowing the agent to self-monitor its learning progress and, when it stagnates, query the social partner for a goal suggestion"". This seems like a standard active learning setting and not a novel contribution.
References: [1] Learning with AMIGo: Adversarially Motivated Intrinsic Goals. Campero et al, 2020 [2] Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play. Sukhbaatar et al, 2017 [3] Asymmetric self-play for automatic goal discovery in robotic manipulation. OpenAI et al, 2021 [4] An automatic curriculum for learning goal-reaching tasks. Zhang et al, 2021 [5] Automatic curriculum learning through value disagreement. Zhang et al, 2020 [6] Exploration via hindsight goal generation. Ren et al, 2019 [7] Automatic goal generation for reinforcement learning agents. Florensa et al, 2018","1) a frontier goal that the agent already discovered and, if it is reached, 2) a beyond goal never achieved by the agent but just beyond the its current abilities."" The social agent keeps a list of all the goals discovered so far and a list of all the goals to be reached. This is not tractable in most environments. One of the contributions listed is: ""an active learning mechanism allowing the agent to self-monitor its learning progress and, when it stagnates, query the social partner for a goal suggestion"". This seems like a standard active learning setting and not a novel contribution. References: [1] Learning with AMIGo: Adversarially Motivated Intrinsic Goals. Campero et al, 2020 [2] Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play. Sukhbaatar et al, 2017 [3] Asymmetric self-play for automatic goal discovery in robotic manipulation. OpenAI et al, 2021 [4] An automatic curriculum for learning goal-reaching tasks. Zhang et al, 2021 [5] Automatic curriculum learning through value disagreement. Zhang et al, 2020 [6] Exploration via hindsight goal generation. Ren et al, 2019 [7] Automatic goal generation for reinforcement learning agents. Florensa et al, 2018",-1.0,1.0,1.0,0.0,nan,-1,1,1,-1
3649,NIPS_2020_791,There are several issues here which I would like the authors to address: * Could the authors comment on the use percentile rank? I understand the reasoning behind it more or less but this is not explained in the paper at all. * What is the relationship between the CDF and percentile rank in this case? is there a way to express one with the other? * The experiments show that in a controlled setting (where a clear target patch and template patch are defined) it is possible to explain several illusions. One thing which is common to all the illusions is that the target patch is flat - what about cases where the patch to explain may have some structure? like the Kanitze triangle? this would make a much more convincing case for the method. * The authors show that the percentile rank correlates with the perceived *relative* lightness (for example) but they do not show if this is actually at the same scale of perception - do subjects report the same change in lightness perception? (I'm sure these numbers can be found in literature). * Only one generative model is tested here - do results change with other models? say a simple GMM or a sparse coding based one?,* Only one generative model is tested here - do results change with other models? say a simple GMM or a sparse coding based one?,1.0,1.0,1.0,0.0,nan,1,1,-1,-1
3390,NIPS_2020_875,"- Some of the claims made by the authors seem imprecise (see below), and the presentation could be more clear/streamlined. - Parts of the proposed approach seem somewhat ad-hoc, and would benefit from better empirical or theoretical motivation (see below). - Some of the baselines in the experiments seem weak or missing.",- Some of the baselines in the experiments seem weak or missing.,-1.0,-1.0,-1.0,-1.0,nan,-1,-1,-1,-1
4072,NIPS_2020_1186,"Theoretical Grounding: - Since the regret bound relies on bounding the state reconstruction error at each point in a finite-length sequence, it seems clear to me that the bound only applies to MBRL algorithms that rely exclusively on full-episode rollouts for planning (e.g. PILCO). This criticism in particular seems to apply to the practical algorithm used in the submission, since it relies on a parametric value function approximator to make the planning horizon more tractable. - In practice we don't know \beta _a priori_. How should \beta be chosen? Empirical Evaluation: - The method is not evaluated in a stochastic environment. If you have set out to solve the issue of conflation of epistemic and aleatoric uncertainty, you should evaluate your method in a stochastic environment, not deterministic Mujoco environments. As it is the experiments give the impression of a bait-and-switch. - No comparison to competing methods only an ablation of the proposed exploration strategy with greedy improvement and approximate Thompson Sampling. - No ablations of β (presumably a crucial design choice). - No demonstration that their dynamics models as implemented satisfy their calibration assumption. Significance/Impact: - Information on the specific implementation details is fairly sparse (e.g. what learning rate and batch size did you use for your dynamics models? Did you reuse a previous implementation of MPO?). Reproducing the authors' findings would likely prove very difficult. MBRL is notorious in the machine learning field for reproducibility issues. If you (the authors) had to reimplement your method from scratch tomorrow, what details would you need?",- No comparison to competing methods only an ablation of the proposed exploration strategy with greedy improvement and approximate Thompson Sampling.,1.0,1.0,-1.0,0.0,nan,-1,0,-1,-1
2482,NIPS_2021_277,"Weaknesses:
The first two rows in Table 1 show that the proposed ITC loss significantly improves the performance. I wish to hear discussions and comments on where the ITC could be useful. Is it specified to the proposed vision-transformer-related VLP models, or it could be extended to the Vilt-like structure [21] with linear projection only, or even to the conventional VLP methods [13,2,3] with detector features.
The ablation of the model architecture might be necessary to understand the source of improvements, i.e., from the proposed losses and distillation, or the change in model architecture and patch size. Specifically, it might be necessary to ablate 1) different model sizes, e.g., small, base, large; 2) different patch sizes and numbers, e.g., ViT/32, /16, and input image size; 3) the influence of model initialization in Sec 3.1.
A minor concern is the comparison to SOTA in Table 4. The compared methods are the BASE version of the SOTA [3,8]. The LARGE version of [3,8] yields similar performance to the reported numbers.
A comment: The contribution of the momentum distillation and the analyses in Section 4 limit at applying the related techniques (moving average teacher in semi-supervised learning [33], the mutual information maximization perspective in NLP [A]) onto the VLP methods. Nonetheless, the proposed techniques and analyses do help the VLP study.
[A] A mutual information maximization perspective of language representation learning
The limitations and societal impacts are discussed in the conclusion section.","2) different patch sizes and numbers, e.g., ViT/32, /16, and input image size;",0.0,0.0,0.0,0.0, This needs the rest of the review to annotate,-1,0,0,1
5529,NIPS_2020_1796,"While the result is interesting, many of the design decisions behind the models and training procedures seemed poorly motivated and discussion on their nuances lacking. - Why represent the rewards as a function of a VAE used to encode exploratory frames in the environment? How does more or less exploration impact the effect of the auxiliary rewards learned this way? - What is the impact of environment ordering during training? Are there any curriculum effects at play? Why train with such a curriculum in the first place? An ablation demonstrating the necessity of this approach would contextualize this decision. - The language stating ""the agent learns R_AUP"" was confusing (Line 138). The reviewer believes this language was meant to describe ""training the Q_i functions"" corresponding to each R_i. This confusing language was used in the caption for the reward learning curves in the supplementary materials, which seems supported by the statement starting on Line 202: ""In the supplementary material..."" - Some key concepts are not defined, for example ""initial state reachability"" (Line 42). - It seems the claim that safe reinforcement learning focuses on just avoiding negative side effects during training is inaccurate. As stated in the abstract of a paper the authors cite (García et al, 2015), safe RL is also concerned with safety at deployment. - The language is often unclear, e.g. Line 211: ""AUP stops moving entirely."" The reviewer believes this is referring to the AUP learning a policy in which the agent remains immobile. - The discussion around the theoretical results (3.2) does not add much insight to the experiments and results presented in the paper. - The contribution is not very novel, as it is simply applying AUP as presented in Turner et al, 2020 to another environment, with little to no modification. - Not clear why Lines 55-57 are included in the related work, as they do not seem particularly relevant to safe RL.",- What is the impact of environment ordering during training? Are there any curriculum effects at play? Why train with such a curriculum in the first place? An ablation demonstrating the necessity of this approach would contextualize this decision.,1.0,1.0,1.0,1.0,nan,1,1,1,-1
4072,NIPS_2020_1186,"Theoretical Grounding: - Since the regret bound relies on bounding the state reconstruction error at each point in a finite-length sequence, it seems clear to me that the bound only applies to MBRL algorithms that rely exclusively on full-episode rollouts for planning (e.g. PILCO). This criticism in particular seems to apply to the practical algorithm used in the submission, since it relies on a parametric value function approximator to make the planning horizon more tractable. - In practice we don't know \beta _a priori_. How should \beta be chosen? Empirical Evaluation: - The method is not evaluated in a stochastic environment. If you have set out to solve the issue of conflation of epistemic and aleatoric uncertainty, you should evaluate your method in a stochastic environment, not deterministic Mujoco environments. As it is the experiments give the impression of a bait-and-switch. - No comparison to competing methods only an ablation of the proposed exploration strategy with greedy improvement and approximate Thompson Sampling. - No ablations of β (presumably a crucial design choice). - No demonstration that their dynamics models as implemented satisfy their calibration assumption. Significance/Impact: - Information on the specific implementation details is fairly sparse (e.g. what learning rate and batch size did you use for your dynamics models? Did you reuse a previous implementation of MPO?). Reproducing the authors' findings would likely prove very difficult. MBRL is notorious in the machine learning field for reproducibility issues. If you (the authors) had to reimplement your method from scratch tomorrow, what details would you need?","- The method is not evaluated in a stochastic environment. If you have set out to solve the issue of conflation of epistemic and aleatoric uncertainty, you should evaluate your method in a stochastic environment, not deterministic Mujoco environments. As it is the experiments give the impression of a bait-and-switch.",1.0,1.0,1.0,-1.0,nan,1,-1,-1,1
2969,NIPS_2022_1846,"Weaknesses and Questions 1. For the distribution estimation, this paper uses three Gradient flow networks to learn different parameters. According to Section 4.3, the networks learn specific parameters for each class using different inputs (i.e., x ¯ j
). That is to say, the network F 1
will output c j j = 1 n for n
classes. However, in Line 142, the authors point that the parameter c
is shared between all classes. How to unify this c
? 2. How to update F 2
, and F 3
via minimizing Eq. (16)? When the classifiers are fixed, it seems that only the network F 1
can be trained. 3. Some experimental details are missing. 3.1. What is the ratio of training data D t
to validation data D v
in the training stage. 3.2. What is the value of initial c
. 4. In Table 2, the metric-based baseline FEAT performs similar accuracy to the proposed method. It’s better to discuss the superiority of the method in terms of time consumption. According to Algorithm 2, the upper bound Eq. (14) simplifies the training of classifiers, but Eq. (16) is still difficult to compute. Typo: In Table 2, the description does not match the content, e.g., ""Euclidean Metric"" (or ""Hyperbolic Metric"") and ""Model"".",3. Some experimental details are missing. 3.1. What is the ratio of training data D t to validation data D v in the training stage. 3.2. What is the value of initial c .,1.0,1.0,0.0,0.0,nan,1,0,0,1
3661,NIPS_2020_1466,"- Regarding the comparisons in Table 1., I would have liked to see comparisons with [9], [10] and/or [11]. SMPL and ASAP are good, but they are blended with an initialization from the authors' method and a comparison with DHBC alone is not completely convincing. - The method requires the ground truth correspondences as supervision which is a strong assumption. Many related methods ([11, 13, 40] in the paper) investigated the unsupervised setting at least to some degree and therefore allow for training on non-synthetic data. - The authors decided to limit themselves to human shapes in this work, although there are no modelling assumption that clearly require this. While I can to some extent understand this decision, it would still be interesting to see some qualitative generalization results to other classes of shapes. I understand that your method requires the human template for training, but similar methods [11] also show at least some examples that are not human or only close to human shape.","- The method requires the ground truth correspondences as supervision which is a strong assumption. Many related methods ([11, 13, 40] in the paper) investigated the unsupervised setting at least to some degree and therefore allow for training on non-synthetic data.",1.0,1.0,1.0,1.0,nan,-1,1,1,1
315,ICLR_2022_2903,"Weaknesses / Questions for authors ===
""Coherence"" seems to be an important topic of the paper. It is mentioned often, and Section 3.1 provide a formal definition of epsilon-coherence. However, in the empirical results this didn't seem to be mentioned anymore. It made me wonder: what is the use of the formal definitions in Section 3.1? I was expected this to be used to evaluate the models. Maybe it did, but then it wasn't clear to me, so in any case I think the relation between the experiments and Section 3.1 can be made clearer.
I found the explanation of the newly proposed relation decoder the ""Dynamic Comparator"" too short. It was difficult for me to understand what it did. More importantly: it seems to outperform all other models very convincingly, but I could not find any discussion on why you believe this is the case. So I felt the empirical results deserve more detailed reflection. Perhaps an ablation study would be interesting?
The empirical studies by itself are also somewhat one-sided (MNIST --> BlockStack). Did you also try the other direction? I.e., train on the BlockStack domain and then evaluate on MNIST? More generally, I was wondering whether the empirical setup is actually similar to how we humans learn. Can we really learn a relation such as ""larger than"" from one domain, and can we directly apply it to another? This is actually not directly clear to me. I can imagine we learn a relation in multiple domains, after which we are able to generalize to new domains.
All appendices seem to be missing from the PDF.
=== Detailed comments for improving the paper ===
Section 2:
I liked the formalisation and I think it was well presented, also the example was helpful.
Section 3:
""Z is a latent variable, itself draw from marginal p_z"" --> ""draw"" should be ""drawn"". Also, I believe p_z is a prior instead of a marginal.
In Definition 3: ψ S ( S )
is undefined, I supposed it means ψ S ( S ) = ψ S ( s ) s ∈ S
, i.e. all encoding of S?
It could be helpful to add a sentence explaining the measure on substructures, e.g., saying that this value will be close to 1 if the soft-structure is similar to the structure.
""It is straightforward to show that ∑ S σ . . . = 1
"" --> what are we summing over here? All possible interpretations of \sigma use S? Please clarify this.
""If we have a theory \Tau over \sigma"" --> I don't get this, isn't a theory defined over the language which contains the relations?
Section 4:
Overall I found this section quite difficult to follow and I wasn't sure the details were relevant (but I could be wrong here). You could consider removing some technical details here (and moving them to the appendix), so that you have more space for possible additional experiments.
The grounding s i j k
is used but only in the next paragraph it is explained what it means, so please define it beforehand.
It is not explained what an ""atomic subformula"" is.
Section 5:
""given a domain images"" --> remove ""a""
""latent space ."" --> remove space
The explanation on the DC is extremely dense, and I'd like to understand better why you developed it this way and why you think it works well.
Section 8:
""ordinaliety"" --> ordinality",".. = 1 "" --> what are we summing over here? All possible interpretations of \sigma use S? Please clarify this. ""If we have a theory \Tau over \sigma"" --> I don't get this, isn't a theory defined over the language which contains the relations? Section 4: Overall I found this section quite difficult to follow and I wasn't sure the details were relevant (but I could be wrong here). You could consider removing some technical details here (and moving them to the appendix), so that you have more space for possible additional experiments. The grounding s i j k is used but only in the next paragraph it is explained what it means, so please define it beforehand. It is not explained what an ""atomic subformula"" is. Section 5: ""given a domain images"" --> remove ""a"" ""latent space ."" --> remove space The explanation on the DC is extremely dense, and I'd like to understand better why you developed it this way and why you think it works well. Section 8: ""ordinaliety"" --> ordinality",1.0,1.0,1.0,1.0,nan,1,0,NO_LABEL,NO_LABEL
1305,ICLR_2023_1603,"Weaknesses - 1. The main drawback of the design is that it relies heavily on a centrally available dataset. One of the two primary goals of the system is to handle non-IIDness in the data, which raises the question - how does the performance of F2L depend on the quality of the root dataset at the server. How well does the root dataset represent the non-IIDness present among the clients? How is scalability affected if the root dataset is not updated to well represent the newly joined clients? More experiments are required to convince the reader that the system can do well even when the root dataset does not exactly represent the data distribution among the clients. 2. Table 1 shows that F2L performs significantly better than Fed-Distill. The lower performance of the other benchmarks can be attributed to the fact that they do not leverage any information from a root dataset. What essentially leads to this improvement with respect to Fed-Distill? Do they both use the same root datasets? Is Fed-Distill well tuned for best performance? 3. Figure 2c shows the performance of F2L when a client is injected into the system midway during the training. F2L can be seen to perform better than vanilla FL. Can this be attributed to knowledge distillation? How would it compare with Fed-Distill? How sensitive are the observations with respect to the knowledge distillation parameters - lambda and temperature? 4. F2L relies on switching between LKD and FedAvg after sufficient convergence has happened. How is this threshold chosen? What can be a general way to choose this value for any dataset? 5. Figure 3 shows that a student can outperform a teacher in F2L. This experiment was performed on EMNIST. Does this observation hold in general, independent of the dataset? If not, what conditions does this depend on?",3. Figure 2c shows the performance of F2L when a client is injected into the system midway during the training. F2L can be seen to perform better than vanilla FL. Can this be attributed to knowledge distillation? How would it compare with Fed-Distill? How sensitive are the observations with respect to the knowledge distillation parameters - lambda and temperature?,1.0,1.0,0.0,0.0,nan,1,0,-1,1
3946,NIPS_2020_1659,"The ability of EvolveGraph to uncover known dynamic relations is not explored in as much detail as it could be. More specifically, the one synthetic experiment designed to evaluate this is somewhat simple, in that all relations change from ""active"" to ""inactive"" for all entities at the same moment in time, and this switch happens once. What happens when relations change at different times for different variables? What happens if the re-encoding gap is ""out of sync"" with the actual change in relations? How well does the model perform if relations change multiple times aperiodically? These questions are not explored here. There are a few modeling decisions which are made that are not explained or explored either. The ones that stick out to me: - The observation model has learned attentional coefficients that seem to be static across time. Do these contribute meaningfully to model performance? Also, doesn't the fact that these coefficients are static mean that they ""pre-determine"" the impact some variables have on others in a data-agnostic manner? - A different prediction mode is selected for each variable for every time step. What happens if modes are re-evaluated less often? How do the frequency of mode selection and relation re-prediction relative to each other impact final performance? - How many modes does the model predict, and how does performance vary as the number of predicted modes changes? Right now, it's difficult to understand if the performance improvements are primarily due to modeling multi-modality, modeling dynamic relations, or both. These criticisms are relatively minor, however; there is enough present in this work for it to be a worthwhile publication.",- A different prediction mode is selected for each variable for every time step. What happens if modes are re-evaluated less often? How do the frequency of mode selection and relation re-prediction relative to each other impact final performance?,1.0,1.0,0.0,0.0,nan,-1,1,-1,-1
4665,NIPS_2020_789,"- My main concern is that, I don’t see the benefits of modeling the data as a union of subspaces, where each subspace corresponds to a class, when the representation space is *learned*. In particular, since these subspaces won’t be orthogonal in practice, on real data. In an unsupervised setting, to recover the subspaces, one needs to perform subspace clustering, which is a hard problem and computationally expensive to perform. In a supervised setting, where estimation of the subspaces is easy, one needs to do nearest-subspace-classification which is more intricate than linear classification. In stark contrast, a linear head trained with a cross-entropy loss learns a representation space with approximately linearly separable regions for each class. As a consequence, classification is simple (linear) and Lp distances in representation space are meaningful (which is not necessarily the case when the classes lie on a union of subspaces). - I acknowledge the encouraging results regarding robustness of the representations learned with the proposed method. However, there are many other methods which can make neural networks with linear classification head more robust, for example [c]. Therefore I believe a union of subspace structure is not fundamentally required to achieve this. - While the theoretical analysis reveals interesting properties of the learned representation, it completely ignores the relationship between the individual data points and their representation, defined through the feature extractor. It is well-known that the structure and properties of the extractor crucially impact the learned representation, possibly even more than the loss, see e.g. [ZF14]. [c] Elsayed, Gamaleldin, et al. ""Large margin deep networks for classification."" Advances in neural information processing systems. 2018. --- Update after rebuttal: Thanks to the authors for their response. I now better see the benefits of encouraging orthogonality between class regions in the feature space, which is why I increased my rating. However, I'm still not sure whether the theoretical result is useful to explain what is going on, as I still believe the network architecture is crucial for the structure in the feature space. Furthermore, as pointed out by the other reviewers, the method seems to have many similarities with previous methods, which should be discussed more precisely.","- I acknowledge the encouraging results regarding robustness of the representations learned with the proposed method. However, there are many other methods which can make neural networks with linear classification head more robust, for example [c]. Therefore I believe a union of subspace structure is not fundamentally required to achieve this.",-1.0,1.0,-1.0,1.0,nan,-1,1,1,-1
3498,NIPS_2020_944,"1. Weighted retraining is not new. The cross-entropy method (De Boer et al., 2005; Neil et al., 2018) maximizes the expectation E_p(x)[f(x)] of the objective function f(x) when sampling from a policy p(x) by periodically retraining p(x) on the samples with the highest reward, e.g. those with a reward above a quantile cutoff (i.e. using a stepwise weighting function). Instantiations of the cross-entropy method include DbAs (Brooks et al) and FBGAN (Gupta et al). Reward weighted regression (RWR) (Hachiya et al) is another existing optimization technique that employs weighted retraining. Angermueller et al. (http://arxiv.org/abs/2006.03227) recently employed these techniques as baselines for high-dimensional discrete optimization. 2. The described rank-based weighting function is not new. See RankGAN (Lin et al. 2017) or LeakGAN (Guo et al. 2017) for an example. 3. The evaluation is missing important baselines such a DbAs, FBGAN, RWR, and model-based optimization. 4. Chemical design task: It is unclear how the optimization trajectory of ‘original’ was obtained. How were new data points sampled from JT-VAE? Why does the trajectory stop at 250? 5. In addition to JT-VAE, I would also like to see a comparison with GCPN (You et al) and reinforcement learning. 6. What do error bars represent? How often were experiments repeated with different random seeds?",6. What do error bars represent? How often were experiments repeated with different random seeds?,-1.0,1.0,0.0,-1.0,nan,1,0,-1,1
5646,NIPS_2018_809,"Weakness: - The uniqueness of connecting curves between two weights would be unclear, and there might be a gap between the curve and FGE. A natural question would be, for example, if we run the curve findings several times, we will see many different curves? Or, those curves would be nearly unique?  - The evidences are basically empirical, and it would be nice if we have some supportive explanations on why this curve happens (and whether it always happens). - The connections of the curve finding (the first part) and FGE (the second part) would be rather weak. When I read the first part and the title, I imagined that take random weights, learn curves between weights, and find nice wights to be mixed into the final ensemble, but it was not like that. (this can work, but also computationally demanding)  Comment: - Overall I liked the paper even though the evidences are empirical. It was fun to read. The reported phenomena are quite mysterious, and interesting enough to inspire some subsequent research. - To be honest, I'm not sure the first curve-finding part explains well why the FGE work. The cyclical learning rate scheduling would perturb the weight around the initial converged weight, but it cannot guarantee that weight is changing along the curve described in the first part.","- The connections of the curve finding (the first part) and FGE (the second part) would be rather weak. When I read the first part and the title, I imagined that take random weights, learn curves between weights, and find nice wights to be mixed into the final ensemble, but it was not like that. (this can work, but also computationally demanding) Comment:",-1.0,1.0,-1.0,0.0,nan,-1,-1,-1,-1
2557,NIPS_2019_220,"Weaknesses: 1. Unclear experimental methodology. The paper states that 300W-LP is used to train the model, but later it is claimed same procedure is used as was used for baselines. Most baselines do not use 300W-LP dataset in their training. Is 300W-LP used in all experiments or just some? If it is used in all this would provide an unfair advantage to the proposed method. 2. Missing link to similar work on Continuous Conditional Random Fields [Ristovski 2013] and Continuous Conditional Neural Fields [Baltrusaitis 2014] that has a similar structure of the CRF and ability to perform exact inference. 3. What is Gaussian NLL? This seems to come out of nowhere and is not mentioned anywhere in the paper, besides the ablation study? Trivia: Consider replacing ""difference mean"" with ""expected difference"" between two landmarks (I believe it would be clearer) ","3. What is Gaussian NLL? This seems to come out of nowhere and is not mentioned anywhere in the paper, besides the ablation study? Trivia: Consider replacing ""difference mean"" with ""expected difference"" between two landmarks (I believe it would be clearer)",1.0,1.0,0.0,-1.0,nan,1,1,-1,1
5336,NIPS_2020_814,"- Only applies to overdetermined least-squares (LS) problems, which is a bit uninteresting at this point. We can solve these quite well already. - Practical performance improvement by using orthogonal transforms is slight (only apparent as sketch becomes larger, where it is less useful; and in the regimes studied by numerical simulations, the decay factor rho was very small for all methods, so convergence was super fast for everything and the differences were not that great) - Everything is in the asymptotic regime, which is not obviously useful, and not very standard for sketching results - The language of the paper oversells things, since it keeps referring to things as ""optimal"" without qualifying that everything is asymptotic.","- Practical performance improvement by using orthogonal transforms is slight (only apparent as sketch becomes larger, where it is less useful; and in the regimes studied by numerical simulations, the decay factor rho was very small for all methods, so convergence was super fast for everything and the differences were not that great) - Everything is in the asymptotic regime, which is not obviously useful, and not very standard for sketching results - The language of the paper oversells things, since it keeps referring to things as ""optimal"" without qualifying that everything is asymptotic.",-1.0,1.0,1.0,-1.0,nan,-1,-1,-1,-1
5043,NIPS_2020_443,"- Apart from ridge regression, there are some regression models like lasso regression the authors might try. - For Table 1, the notation should be aligned with its description. - Overall, I am quite curious why 2v2 accuracies for all hypotheses are just slightly better than the random chance. Why is that? Correct me if I am wrong, thanks.","- For Table 1, the notation should be aligned with its description.",1.0,1.0,0.0,0.0,nan,-1,1,-1,1
3366,NIPS_2020_639,"The relevance of this paper is entirely unclear, for multiple reasons: 1. The author themselves state ""This work does not present any foreseeable societal consequence."", raising the question why we should we care about this work in the first place. 2. They don't make any detectable effort towards arguing for why their work is relevant in the paper either, rendering it a purely theoretical exercise. 3. No empirical evaluation whatsoever is provided, there is no comparison (except for on an abstract level) with other methods. It is completely unclear what the practical value of the contribution even could be. Even a theoretical paper should at least try to argue for why it matters, this is not the case with this submission. The theoretical contributions may well be significant and valuable, however, in its current form this paper is not suitable for a publication at NeurIPS.","3. No empirical evaluation whatsoever is provided, there is no comparison (except for on an abstract level) with other methods. It is completely unclear what the practical value of the contribution even could be. Even a theoretical paper should at least try to argue for why it matters, this is not the case with this submission. The theoretical contributions may well be significant and valuable, however, in its current form this paper is not suitable for a publication at NeurIPS.",-1.0,-1.0,-1.0,-1.0,nan,-1,-1,-1,-1
5592,NIPS_2018_55,"weakness of this paper lies in the evaluation. Although it is a great thing that this paper uses more datasets than MNIST, the evaluation can be much improved. 1) The statements in the MNIST experiment such as ""While results without an CAE are quite convincing, the CAE clearly improves the pertinent positives and negatives in many cases. Regarding pertinent positives, the cyan highlighted pixels in the column with CAE (CAE CEM PP) are a superset to the cyan-highlighted pixels in column without (CEM PP). While these explanations are at the same level of confidence regarding the classifier, explanations using an AE are visually more interpretable."" are problematic. These are quite subjective statements, and some form of quantitative evaluation across subjects is required for such claims. 2) In the procurement fraud experiment, it seems that the experts like everything that the algorithm shows. Risk evaluation seems a non-trivial problem. It is unclear whether these experts or humans are good at this task. Also, given the sample size, it is unclear whether the difference in Table 1 is statistically significant.  3) This paper did not provide enough information regarding how the evaluation was done in the brain functional imaging experiment. It seems that the only sentence is ""With the help of domain experts"". 4) c, \beta, and \gamma are important parameters for the proposed approach. The main paper did not discuss the choice of these parameters at all, and the supplementary material only gives procedural information. It would be great if this paper provides more thoughtful discussions on the choices of these parameters, or maybe the insensitivity of these parameters if that is the case. Overall, I really like the idea of this paper and believe that this paper should be accepted. Given the space limit of NIPS submissions, one possible way to improve the paper is to drop one experiment and make the other two experiments more solid. Minor presentation-related suggestions:   I like the introduction overall, but the first sentence seems a bit out of nowhere and statements such as ""Explanations as such are used frequently by people"" are questionable and at least requires better evidence.   line 218: an CAE -> a CAE   line 252: spend -> spending I have read the review and it would be useful if the user can clarify how some set operations in the formulation apply to continuous variables.","4) c, \beta, and \gamma are important parameters for the proposed approach. The main paper did not discuss the choice of these parameters at all, and the supplementary material only gives procedural information. It would be great if this paper provides more thoughtful discussions on the choices of these parameters, or maybe the insensitivity of these parameters if that is the case. Overall, I really like the idea of this paper and believe that this paper should be accepted. Given the space limit of NIPS submissions, one possible way to improve the paper is to drop one experiment and make the other two experiments more solid. Minor presentation-related suggestions: I like the introduction overall, but the first sentence seems a bit out of nowhere and statements such as ""Explanations as such are used frequently by people"" are questionable and at least requires better evidence. line 218: an CAE -> a CAE line 252: spend -> spending I have read the review and it would be useful if the user can clarify how some set operations in the formulation apply to continuous variables.",1.0,1.0,1.0,1.0,nan,1,1,1,1
811,ICLR_2021_1181,"Weaknesses
1.For domain adaptation in the NLP field, powerful pre-trained language models, e.g., BERT, XLNet, can overcome the domain-shift problem to some extent. Thus, the authors should be used as the base encoder for all methods and then compare the efficacy of the transfer parts instead of the simplest n-gram features.
2.The whole procedure is slightly complex. The author formulates the prototypical distribution as a GMM, which has high algorithm complexity. However, formal complexity analysis is absent. The author should provide an analysis of the time complexity and training time of the proposed SAUM method compared with other baselines. Besides, a statistically significant test is absent for performance improvements.
3.The motivation of learning a large margin between different classes is exactly discriminative learning, which is not novel when combined with domain adaptation methods and already proposed in the existing literature, e.g., Unified Deep Supervised Domain Adaptation and Generalization, Saeid et al., ICCV 2017. Contrastive Adaptation Network for Unsupervised Domain Adaptation, Kang et al., CVPR 2019 Joint Domain Alignment and Discriminative Feature Learning for Unsupervised Deep Domain Adaptation, Chen et al., AAAI 2019.
However, this paper lacks detailed discussions and comparisons with existing discriminative feature learning methods for domain adaptation.
4.The unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced, which is impractical in real-world applications. Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.
5.The paper lacks some related work about cross-domain sentiment analysis, e.g., End-to-end adversarial memory network for cross-domain sentiment classification, Li et al., IJCAI 2017 Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018 Hierarchical attention transfer network for cross-domain sentiment classification, Li et al., AAAI 18 Questions:
1.Have the authors conducted the significance tests for the improvements?
2.How fast does this algorithm run or train compared with other baselines?","3.The motivation of learning a large margin between different classes is exactly discriminative learning, which is not novel when combined with domain adaptation methods and already proposed in the existing literature, e.g., Unified Deep Supervised Domain Adaptation and Generalization, Saeid et al., ICCV 2017. Contrastive Adaptation Network for Unsupervised Domain Adaptation, Kang et al., CVPR 2019 Joint Domain Alignment and Discriminative Feature Learning for Unsupervised Deep Domain Adaptation, Chen et al., AAAI 2019. However, this paper lacks detailed discussions and comparisons with existing discriminative feature learning methods for domain adaptation.",1.0,1.0,1.0,0.0,nan,-1,1,1,-1
71,ICLR_2022_1155,"Weaknesses: 1. This work is motivated by “the common misconception that adversarial examples are high-frequency noise”; however, such an understanding has already been questioned in the literature. For example, in (Tsuzuku & Sato, 2019), it shows “adversarial perturbations do not necessarily lie in high-frequency spots” by experiments; in (Yin et al. 2020), it says “adversarial examples are not strictly a high frequency phenomenon”; particularly in Bernhard et al. (2021), it questions “some preconceived hypothesis” that “adversarial perturbations as a pure HSF phenomenon with data-agnostic spatial frequency characteristics”. Therefore, the motivation should be better justified. The contribution is more like additional evidence of the ongoing debate, but rather a new frequency-based understanding of the “common misconception”. This should not be overclaimed. 2. This work reveals that adversarial examples are dataset dependent; however, this is a commonly accepted point in the community, and therefore the idea and the conclusion do not seem new. In addition, the demonstration of this point with only CIFAR-10 and ImageNet-derived datasets does not seem sufficient. More datasets should be considered including the simplest one (MNIST), and others such as CIFAR-100, SVHN, Fashion-MNIST. 3. Only PGD attacks are investigated – it is unclear if the observations also occur with other attacks, e.g., C&W, auto-attack. 4. It claims the “observations overlap with insights from the concurrent work by Bernhard et al. (2021)”; however Bernhard et al. (2021) appeared on arXiv in April 2021. The authors may want to highlight the differences and justify this point. According to my understanding, the main messages of two papers are the same. This will dwarf the contribution of this paper. 5. When measuring the importance of different frequency components and attacking low-frequency components, how to guarantee the imperceptibility? Should not the threat models be re-defined? How to make the trade-off between imperceptibility and attack successfulness? 6. The measure of average noise gradient over the entire dataset should be further justified. Why is not the average noise gradient of a specific class, given the intuition that the frequency properties of images from different classes may be so different that the averaging may be misleading. 7. When designing adversarial training with frequency-based perturbation, how to find the frequency subspace? How is PGD attack restricted to the same frequency bands?","5. When measuring the importance of different frequency components and attacking low-frequency components, how to guarantee the imperceptibility? Should not the threat models be re-defined? How to make the trade-off between imperceptibility and attack successfulness?",1.0,1.0,1.0,0.0,nan,-1,1,-1,-1
2582,NIPS_2019_933,"weaknesses: + I liked the simplicity of the solution to divide the problem into star graphs. The domination number introduced seems to be a natural quantity for this problem. +/- To my opinion, the setting seems somewhat contrived combining feedback graphs and switching costs. The application to policy regret with counterfactual however provides a convincing example that the analysis can be useful and inspire future work. +/- The main part of the paper is rather clear and well written. Yet, I found the proofs in the appendices sometimes a bit hard to follow with sequences of unexplained equations. I would suggest to had some details. - There is a gap between the lower bound and the upper-bound (\sqrt(\beta) instead of \beta^{1/3}). In particular, for some graphs, the existing bound with the independence number may be better. This is also true for the results on the adaptive adversary and the counterfactual feedback. Other remarks: - Was the domination number already introduced for feedback graphs without switching costs? If yes, existing results for this problem should be cited. If not, it would be interesting to state what kind of results your analysis would provide without using the mini-batches. - Note that the length of the mini-batches tau_t may be non-integers. This should be clarified to be sure there are no side effects. For instance, what happens if $\tau_t << 1$? I am not sure if the analysis is still valid. - A better (more formal) definition of the independence and the domination numbers should be provided. It took me some time to understand their meaning. - Alg 1 and Thm 3.1: Since only upper-bounds on the pseudo-regret are provided, the exploration parameter gamma seems to be useless, isn't it? The choice gamma=0 seems to be optimal. A remark on high-probability upper-bounds and the role of gamma might be interesting. In particular, do you think your analysis (which is heavily based on expectations) can be extended to high-probability bounds on the regret? - I understand that this does not suit the analysis (which uses the equivalence in expectation btw Alg1 and Alg6) but it seems to be suboptimal (at least in practice) to discard all the feedbacks obtained while playing non-revealing actions. It would be nice to have practical experiments to understand better if we lose something here. It would be also nice to compare it with existing algorithms.  Typos: - p2, l86: too many )) - Thm 3.1: A constant 2 in the number of switches is missing. - p13, l457: some notations seem to be undefined (w_t, W_t). - p14, you may add a remark - p15, l458: the number of switches can be upper-bounded by **twice** the number of times the revealing action is played - p16, l514: I did not understand why Thm 3.1 implies the condition of Thm C.5 with alpha=1/2 and not 1. By the way, (rho_t) should be non-decreasing for this condition to hold. ","- There is a gap between the lower bound and the upper-bound (\sqrt(\beta) instead of \beta^{1/3}). In particular, for some graphs, the existing bound with the independence number may be better. This is also true for the results on the adaptive adversary and the counterfactual feedback. Other remarks:",-1.0,1.0,1.0,0.0,nan,NO_LABEL,1,-1,1
597,ICLR_2021_2678,"Weakness –
W0 – There is no comparison to existing metrics, e.g., IS and FID to clearly show the advantages as the authors claimed in the paper, e.g., fewer samples and low variance. I think people now are using the combination of IS and FID in their experiments to measure quality and diversity. How are these two new metrics better than the existing combination? There is a bit disconnected between the concepts of the three proposed metrics, and I think it's still fair to compare the proposed metrics (visual quality and mode diversity) with the combination of IS and FID.
W1 – The visual quality and mode diversity metrics use the face detection/verification frameworks which are quite specific to face datasets that have ground-truth labels. Can they apply to other domains rather than faces? If so, does it cause any bias?
W3 – What is X − 1
in Eq. 6. Is it the inversion of matrix determination or number the division of the number of samples?
W4 – Mistakes in Eqs. 3 and 10 and Table 3, should be gradient of ∇ x ^
instead of ∇ η .
W5 – It looks like the paper is a bit rushed in this submission, there are sufficient missing details of implementations, e.g., hyper-parameters, batch size, detail of architecture, … are not provided. These factors may also have effects on the training of GAN. It would be interesting to have studies on these in future work.
W6 – The paper's experiments are limited to one low-resolution dataset with standard GAN architectures. It's important to evaluate various GAN architectures and datasets for GAN assessment papers. It would be interesting to conduct the experiments also on state-of-the-art GAN models, e.g., SN-GAN, BigGAN, ProGAN, and StyleGAN, and with high-resolution datasets as well.
W7 - Some metrics are interesting and likely to be valuable in the future, but can be more polished on experiments and comparison. It would be great if the current measures can be developed to extend for other datasets, e.g., CIFAR, ImageNet.
W8 – The paper has derived some mathematics of turning points, but what is its meaning and how is it useful to derive this equation?","3 and 10 and Table 3, should be gradient of ∇ x ^ instead of ∇ η . W5 – It looks like the paper is a bit rushed in this submission, there are sufficient missing details of implementations, e.g., hyper-parameters, batch size, detail of architecture, … are not provided. These factors may also have effects on the training of GAN. It would be interesting to have studies on these in future work. W6 – The paper's experiments are limited to one low-resolution dataset with standard GAN architectures. It's important to evaluate various GAN architectures and datasets for GAN assessment papers. It would be interesting to conduct the experiments also on state-of-the-art GAN models, e.g., SN-GAN, BigGAN, ProGAN, and StyleGAN, and with high-resolution datasets as well. W7 - Some metrics are interesting and likely to be valuable in the future, but can be more polished on experiments and comparison. It would be great if the current measures can be developed to extend for other datasets, e.g., CIFAR, ImageNet. W8 – The paper has derived some mathematics of turning points, but what is its meaning and how is it useful to derive this equation?",1.0,1.0,1.0,1.0,nan,NO_LABEL,1,NO_LABEL,0
2582,NIPS_2019_933,"weaknesses: + I liked the simplicity of the solution to divide the problem into star graphs. The domination number introduced seems to be a natural quantity for this problem. +/- To my opinion, the setting seems somewhat contrived combining feedback graphs and switching costs. The application to policy regret with counterfactual however provides a convincing example that the analysis can be useful and inspire future work. +/- The main part of the paper is rather clear and well written. Yet, I found the proofs in the appendices sometimes a bit hard to follow with sequences of unexplained equations. I would suggest to had some details. - There is a gap between the lower bound and the upper-bound (\sqrt(\beta) instead of \beta^{1/3}). In particular, for some graphs, the existing bound with the independence number may be better. This is also true for the results on the adaptive adversary and the counterfactual feedback. Other remarks: - Was the domination number already introduced for feedback graphs without switching costs? If yes, existing results for this problem should be cited. If not, it would be interesting to state what kind of results your analysis would provide without using the mini-batches. - Note that the length of the mini-batches tau_t may be non-integers. This should be clarified to be sure there are no side effects. For instance, what happens if $\tau_t << 1$? I am not sure if the analysis is still valid. - A better (more formal) definition of the independence and the domination numbers should be provided. It took me some time to understand their meaning. - Alg 1 and Thm 3.1: Since only upper-bounds on the pseudo-regret are provided, the exploration parameter gamma seems to be useless, isn't it? The choice gamma=0 seems to be optimal. A remark on high-probability upper-bounds and the role of gamma might be interesting. In particular, do you think your analysis (which is heavily based on expectations) can be extended to high-probability bounds on the regret? - I understand that this does not suit the analysis (which uses the equivalence in expectation btw Alg1 and Alg6) but it seems to be suboptimal (at least in practice) to discard all the feedbacks obtained while playing non-revealing actions. It would be nice to have practical experiments to understand better if we lose something here. It would be also nice to compare it with existing algorithms.  Typos: - p2, l86: too many )) - Thm 3.1: A constant 2 in the number of switches is missing. - p13, l457: some notations seem to be undefined (w_t, W_t). - p14, you may add a remark - p15, l458: the number of switches can be upper-bounded by **twice** the number of times the revealing action is played - p16, l514: I did not understand why Thm 3.1 implies the condition of Thm C.5 with alpha=1/2 and not 1. By the way, (rho_t) should be non-decreasing for this condition to hold. ","- Was the domination number already introduced for feedback graphs without switching costs? If yes, existing results for this problem should be cited. If not, it would be interesting to state what kind of results your analysis would provide without using the mini-batches.",1.0,1.0,1.0,0.0,nan,1,1,1,1
2228,ACL_2017_130_review.json,"Weaknesses: The paper suffers from several drawbacks 1. The paper is hard to read due to incorrect usage of English. The current manuscript would benefit a lot from a review grammar and spellings. 
2. The main machine learning problem being addressed is poorly described. What was a single instance of classification? It seems every transcripts was classified as MCI or No MCI. If this is the case, the dataset descriptions should describe the numbers at a transcript level. Tables 1,2, and 3 should describe the data not the study that produced the transcripts. The age of the patients is irrelevant for the classification task. A lot of text (2 pages) is consumed in simply describing the datasets with details that do not affect the end classification task. Also, I was unsure why numbers did not add up. For e.g.: in section 4.1.1 the text says 326 people were involved. But the total number of males and females in Table 1 are less than 100? 
3. What is the motivation behind enriching the graph? Why not represent each word by a node in the graph and connect them by the similarity between their vectors, irrespective of co-occurrence? 
4. The datsets are from a biomedical domain. No domain specific tools have been leveraged. 
5. Since dataset class distribution is unclear, it is unclear to determine if accuracy is a good measure for evaluation. In either case, since it is a binary classification task, F1 would have been a desirable metric. 
6. Results are reported unto 4 decimal places on very small datasets (43 transcripts) without statistical tests over increments. Therefore, it is unclear if the gains are significant. ","2. The main machine learning problem being addressed is poorly described. What was a single instance of classification? It seems every transcripts was classified as MCI or No MCI. If this is the case, the dataset descriptions should describe the numbers at a transcript level. Tables 1,2, and 3 should describe the data not the study that produced the transcripts. The age of the patients is irrelevant for the classification task. A lot of text (2 pages) is consumed in simply describing the datasets with details that do not affect the end classification task. Also, I was unsure why numbers did not add up. For e.g.: in section 4.1.1 the text says 326 people were involved. But the total number of males and females in Table 1 are less than 100?",1.0,1.0,1.0,0.0,nan,1,-1,NO_LABEL,-1
5538,NIPS_2020_1623,"1. Lacking insight on setting the hyper-params: Table 2 (b) shows E_s = 60 will have the best performance but in the experiments in Section 2.4, E_s is set to 70. Is there any insight or explanation on the reason why to do such changes? 2. Not enough model structures in the experiments to support the conclusion: As mentioned by one of the baselines [24], previous works utilize a various set of different architectures, which hinders a fair comparison. And this paper only uses ResNet34@CIFAR10/100, and ResNet50@ImageNet. Although this paper reproduces some baselines in the setting above, it would be better to provide more comparison on other model structures and use the reported numbers in the baselines.","2. Not enough model structures in the experiments to support the conclusion: As mentioned by one of the baselines [24], previous works utilize a various set of different architectures, which hinders a fair comparison. And this paper only uses ResNet34@CIFAR10/100, and ResNet50@ImageNet. Although this paper reproduces some baselines in the setting above, it would be better to provide more comparison on other model structures and use the reported numbers in the baselines.",1.0,1.0,1.0,1.0,nan,1,1,1,1
4223,NIPS_2020_1003,"1. The study among different adversarially trained models is missing, thus the trade-off is unclear among robust trained models. For example, the TRADES model may improve both the robustness and back-door robustness. 2. Following the point above, it is unclear whether the trade-off still holds when the models that are partially adversarial robust. Since the results are present in two extreme without the middle results. For example, models with 10%,20%, 30% adversarial robustness accuracy. A curve with some reasonable resolution is needed to show the trade-off. 3. Experiment details missing. It is unclear to the reviewer whether the data for the adversarial training is poisoned or not. Would adversarial training still work under poison data? Would that mean successful backdoor attack (weak back-door robustness) also reduce the adversarial robustness? Maybe a figure showing the trade-off under this setting is missing. 4. Too few steps of attack for adversairal attack (only 5 to 10 steps), it is may not access the true adversarial robustness.","4. Too few steps of attack for adversairal attack (only 5 to 10 steps), it is may not access the true adversarial robustness.",-1.0,1.0,-1.0,0.0,nan,-1,-1,-1,-1
2040,ARR_2022_143_review,"Weak: 1. 	More examples are preferred to understand the motivations, the novel part of the proposed method and the baselines (see “detailed questions and comments”); 2. 	Some higher level comparisons, such as between parametric and non- parametric solutions are preferred. Currently, most baselines are in the same technical line of kNN-MT which is too narrow to reflect the strength of the proposed algorithms/networks. 
Detailed questions and comments: 1. 	Table 1, what are the hardware used? Model sizes? For “speed comparison”. 
2. 	Figure 1, what are the labels for horizontal and vertical axis? 
3. 	Lines 088 to 089, hard to understand why it is “intuitively” since the figure 1 is a 2D description of high-dimension features/distributions, do you have any detailed data/experiments to support this “intuitively”? 
4. 	Can you give real-world examples and attach them to your Figure 2? 
5. 	Figure 3, can you give example real tokens, instead of “token A”, “token B”? it is a bit difficult to understand what are the “negative, positive, pivot” arrows in this figure. 
6. 	Lines 170 to 171, “unreliable neighbors” any examples of “unreliable neighbors”? 
7. 	Line 458, is “0.18 BLEU” a significant improvement? Do not understand if it is “impressive result” or not. 
8. 	Table 6 is a bit difficult to understand. Can you first give references of using SP, LTP, HTP, and RP? Also why there are quite limit number of BLEU scores achieved by your “Ours method” higher than others? Can you also give speed/decoding comparison? Since based on this table, I am not sure why we shall rank your method to be higher than the other baselines. There is a big drop of from 46.94 to 46.03 of from “CKMT*” to “CKMT*+Ours”, any detailed analysis of this or any future work plan of this direction? 
9. 	Table 11, why “adaptive kNN-MT” output so many “wrong translations”? how there examples are selected? 
10. 	Section 2 “related work and background” is hard to understand. Intuitively, can you simply give a simple example of the difficulties of cross-domain translation (such as vocabulary difference, grammar difference and technical terms) and show that cluster based methods are helpful for this cross-domain translation. In addition, besides cluster based methods, can you also briefly summarize the major directions of dealing with “domain adaption for NMT”? if there is a comparison of among the major directions (not only other cluster-based methods), this paper will be ranked even higher (e.g., non-parameter solution vs. parameter solution for “domain adaption of MT”). ","7. Line 458, is “0.18 BLEU” a significant improvement? Do not understand if it is “impressive result” or not.",0.0,1.0,0.0,-1.0,nan,-1,-1,-1,-1
5616,NIPS_2018_232,"weaknesses - Strengths: the paper is well-written and well-organized. It clearly positions the main idea and proposed approach related to existing work and experimentally demonstrates the effectiveness of the proposed approach in comparison with the state-of-the-art. - Weaknesses: the research method is not very clearly described in the paper or in the abstract. The paper lacks a clear assessment of the validity of the experimental approach, the analysis, and the conclusions. Quality - Your definition of interpretable (human simulatable) focuses on to what extent a human can perform and describe the model calculations. This definition does not take into account our ability to make inferences or predictions about something as an indicator of our understanding of or our ability to interpret that something. Yet, regarding your approach, you state that you are ânot trying to find causal structure in the data, but in the modelâs responseâ and that âwe can freely manipulate the input and observe how the model response changesâ. Is your chosen definition of interpretability too narrow for the proposed approach? Clarity - Overall, the writing is well-organized, clear, and concise. - The abstract does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what was the outcome. Minor language issues p. 95: âfrom fromâ -> âfromâ p. 110: âto toâ -> âhow toâ p. 126: âas wayâ -> âas a wayâ p. 182 âcan sortedâ -> âcan be sortedâ p. 197: âon directly onâ -> âdirectly onâ p. 222: âwhere wantâ -> âwhere we wantâ p. 245: âas accurateâ -> âas accurate asâ Tab. 1: âsquareâ -> âsquared errorâ p. 323: âthis are featuresâ -> âthis is featuresâ Originality - the paper builds on recent work in IML and combines two separate lines of existing work; the work by Bloniarz et al. (2016) on supervised neighborhood selection for local linear modeling (denoted SILO) and the work by Kazemitabar et al. (2017) on feature selection (denoted DStump). The framing of the problem, combination of existing work, and empirical evaluation and analysis appear to be original contributions. Significance - the proposed method is compared to a suitable state-of-the-art IML approach (LIME) and outperforms it on seven out of eight data sets. - some concrete illustrations on how the proposed method makes explanations, from a user perspective, would likely make the paper more accessible for researchers and practitioners at the intersection between human-computer interaction and IML. You propose a âcausal metricâ and use it to demonstrate that your approach achieves âgood local explanationsâ but from a user or human perspective it might be difficult to get convinced about the interpretability in this way only. - the experiments conducted demonstrate that the proposed method is indeed effective with respect to both accuracy and interpretability, at least for a significant majority of the studied datasets. - the paper points out two interesting directions for future work, which are likely to seed future research.",- The abstract does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what was the outcome. Minor language issues p.,-1.0,-1.0,-1.0,0.0,nan,-1,1,-1,1
2040,ARR_2022_143_review,"Weak: 1. 	More examples are preferred to understand the motivations, the novel part of the proposed method and the baselines (see “detailed questions and comments”); 2. 	Some higher level comparisons, such as between parametric and non- parametric solutions are preferred. Currently, most baselines are in the same technical line of kNN-MT which is too narrow to reflect the strength of the proposed algorithms/networks. 
Detailed questions and comments: 1. 	Table 1, what are the hardware used? Model sizes? For “speed comparison”. 
2. 	Figure 1, what are the labels for horizontal and vertical axis? 
3. 	Lines 088 to 089, hard to understand why it is “intuitively” since the figure 1 is a 2D description of high-dimension features/distributions, do you have any detailed data/experiments to support this “intuitively”? 
4. 	Can you give real-world examples and attach them to your Figure 2? 
5. 	Figure 3, can you give example real tokens, instead of “token A”, “token B”? it is a bit difficult to understand what are the “negative, positive, pivot” arrows in this figure. 
6. 	Lines 170 to 171, “unreliable neighbors” any examples of “unreliable neighbors”? 
7. 	Line 458, is “0.18 BLEU” a significant improvement? Do not understand if it is “impressive result” or not. 
8. 	Table 6 is a bit difficult to understand. Can you first give references of using SP, LTP, HTP, and RP? Also why there are quite limit number of BLEU scores achieved by your “Ours method” higher than others? Can you also give speed/decoding comparison? Since based on this table, I am not sure why we shall rank your method to be higher than the other baselines. There is a big drop of from 46.94 to 46.03 of from “CKMT*” to “CKMT*+Ours”, any detailed analysis of this or any future work plan of this direction? 
9. 	Table 11, why “adaptive kNN-MT” output so many “wrong translations”? how there examples are selected? 
10. 	Section 2 “related work and background” is hard to understand. Intuitively, can you simply give a simple example of the difficulties of cross-domain translation (such as vocabulary difference, grammar difference and technical terms) and show that cluster based methods are helpful for this cross-domain translation. In addition, besides cluster based methods, can you also briefly summarize the major directions of dealing with “domain adaption for NMT”? if there is a comparison of among the major directions (not only other cluster-based methods), this paper will be ranked even higher (e.g., non-parameter solution vs. parameter solution for “domain adaption of MT”). ","2. Figure 1, what are the labels for horizontal and vertical axis?",0.0,1.0,0.0,0.0,nan,1,0,1,1
4364,NIPS_2020_285,"- In Section 2, it is assumed that the state and action spaces are finite. Is this assumption really necessary? It might be quite limiting since policy gradient methods are typically employed when dealing with continuous state-action spaces. Moreover, the transition model is defined as deterministic. Is this assumption necessary? - Proposition 6: I am a little confused about the notation. Equation (13) employs the improvement operator for the value-based case, but the remark in the subsequent line is stated for the improvement operator for the trajectory-based case. - Proposition 5: This is more curiosity than an issue. Are there some sufficient conditions to enforce that Var(R) > 0 along the whole learning process? It seems to me that as we get close to the optimum we are going to prefer less stochastic policies, thus we slow down convergence. Do you think we can still converge asymptotically if deterministic policies are allowed? Anyway, in policy search, we could even limit to stochastic policies. Maybe in such a case, we can have a non-zero guaranteed improvement and, consequently, converge in a finite number of iterations. I think the paper would greatly benefit from a discussion on these points. - Proposition 2: This is also a curiosity. The optimal policy, in the considered policy space, is a fixed point of the operator. There can be other fixed points? If so, do the authors think that is possible to characterize the space of fixed-points? Are there some conditions under which the fixed point is unique? ***Minor*** - lines 50 and 62: s_{t_1} -> s_{t+1} - Equation (3) goes beyond margins - line 64: reporting the formal definition of d^\pi might help - Equation (24) there should be a \propto instead of = - Proposition 5: there should be a statement, not just a formula - The notation of Proposition 9 does not match that used in the proof (z vs f(R)) - Figure 2: not very readable in grayscale, I suggest using different linestyles or markers","- Proposition 2: This is also a curiosity. The optimal policy, in the considered policy space, is a fixed point of the operator. There can be other fixed points? If so, do the authors think that is possible to characterize the space of fixed-points? Are there some conditions under which the fixed point is unique? ***Minor*** - lines 50 and 62: s_{t_1} -> s_{t+1} - Equation (3) goes beyond margins - line 64: reporting the formal definition of d^\pi might help - Equation (24) there should be a \propto instead of = - Proposition 5: there should be a statement, not just a formula - The notation of Proposition 9 does not match that used in the proof (z vs f(R)) - Figure 2: not very readable in grayscale, I suggest using different linestyles or markers",1.0,1.0,1.0,1.0,nan,NO_LABEL,1,0,-1
1822,ARR_2022_288_review,"-	While this model is one of its kind in this area, the language model’s scope is too narrow to have a wide range of applications. Other similar BERT-based models (e.g. BioBERT, SciBERT) has a wider coverage. The authors should strengthen the claim of the importance of this model by discussing important problems in this area and how this language model will be essential in addressing a wide variety of problems in this domain. 
-	Although ConfliBERT is a novel language model, the concept, methodology, implementation follows the BERT model. While it can contribute to the area of political science and computational social science in general, it is not clear how this work contributes to the area of NLP. 
-	The paper lacks a sound discussion to explain certain observations. Although, the experimental results unanimously show that for problems related to this domain ConfliBERT is a better choice but it is not clear which version of ConfliBERT is better, SCR or Cont. On many occasions, we see that the Cont version (built on top of BERT) performs better than SCR. This raises two questions – under what conditions Cont is more likely to perform better and given that Cont is trained on top of BERT, what are the features of BERT that are important in this case. The paper should address the merits of BERT that are part of Cont but not of SCR. Additional experiments may help to show whether this is a data problem or a model problem. 
The paper argues the need for a domain-specific language model for the area of political conflicts and violence. They validate this claim by showing how such a language model can improve downstream tasks in this area. The paper is clearly written and the claims are evaluated well using an extensive set of experiments. 
The advantage and the utility of the proposed language model are clear but there remain a few gaps that are important to understand the full strength of this model. The authors should present a clear discussion on the advantages and disadvantages of using the domain-specific datasets used in the training. The authors discussed that their dataset has additional words related to terrorism that are not present in a more general-purpose corpus but are there any other types of words that enriched the training of ConfliBERT? We see that only 3 out of 9 problems are related to terrorism. Indeed, the SCR model performed better in all the tasks involving terrorism-related data. On the other hand for protest-related data, we see a mixed performance, where Cont doing better in 2 out of 3 cases. For the case of Cont, are there any disadvantages for not using a general-purpose model/data? What is the percentage of vocabulary that is present in the general dataset but not in the domain-specific data? If this percentage is large, will that create a roadblock in the wider applicability of this language model? On the other hand, having too many unrelated words in the general-purpose data can act as noise for more domain-dependent tasks? The paper will benefit from a more in-depth analysis and comparison of the datasets used against a more generic corpus. 
Minor point: On page 6, section 5.2, lines 514, 515, it is not clear how the p-values were computed. What tests were performed to compare the two cases? ","- While this model is one of its kind in this area, the language model’s scope is too narrow to have a wide range of applications. Other similar BERT-based models (e.g. BioBERT, SciBERT) has a wider coverage. The authors should strengthen the claim of the importance of this model by discussing important problems in this area and how this language model will be essential in addressing a wide variety of problems in this domain.",-1.0,1.0,1.0,0.0,nan,-1,1,-1,-1
1822,ARR_2022_288_review,"-	While this model is one of its kind in this area, the language model’s scope is too narrow to have a wide range of applications. Other similar BERT-based models (e.g. BioBERT, SciBERT) has a wider coverage. The authors should strengthen the claim of the importance of this model by discussing important problems in this area and how this language model will be essential in addressing a wide variety of problems in this domain. 
-	Although ConfliBERT is a novel language model, the concept, methodology, implementation follows the BERT model. While it can contribute to the area of political science and computational social science in general, it is not clear how this work contributes to the area of NLP. 
-	The paper lacks a sound discussion to explain certain observations. Although, the experimental results unanimously show that for problems related to this domain ConfliBERT is a better choice but it is not clear which version of ConfliBERT is better, SCR or Cont. On many occasions, we see that the Cont version (built on top of BERT) performs better than SCR. This raises two questions – under what conditions Cont is more likely to perform better and given that Cont is trained on top of BERT, what are the features of BERT that are important in this case. The paper should address the merits of BERT that are part of Cont but not of SCR. Additional experiments may help to show whether this is a data problem or a model problem. 
The paper argues the need for a domain-specific language model for the area of political conflicts and violence. They validate this claim by showing how such a language model can improve downstream tasks in this area. The paper is clearly written and the claims are evaluated well using an extensive set of experiments. 
The advantage and the utility of the proposed language model are clear but there remain a few gaps that are important to understand the full strength of this model. The authors should present a clear discussion on the advantages and disadvantages of using the domain-specific datasets used in the training. The authors discussed that their dataset has additional words related to terrorism that are not present in a more general-purpose corpus but are there any other types of words that enriched the training of ConfliBERT? We see that only 3 out of 9 problems are related to terrorism. Indeed, the SCR model performed better in all the tasks involving terrorism-related data. On the other hand for protest-related data, we see a mixed performance, where Cont doing better in 2 out of 3 cases. For the case of Cont, are there any disadvantages for not using a general-purpose model/data? What is the percentage of vocabulary that is present in the general dataset but not in the domain-specific data? If this percentage is large, will that create a roadblock in the wider applicability of this language model? On the other hand, having too many unrelated words in the general-purpose data can act as noise for more domain-dependent tasks? The paper will benefit from a more in-depth analysis and comparison of the datasets used against a more generic corpus. 
Minor point: On page 6, section 5.2, lines 514, 515, it is not clear how the p-values were computed. What tests were performed to compare the two cases? ","- The paper lacks a sound discussion to explain certain observations. Although, the experimental results unanimously show that for problems related to this domain ConfliBERT is a better choice but it is not clear which version of ConfliBERT is better, SCR or Cont. On many occasions, we see that the Cont version (built on top of BERT) performs better than SCR. This raises two questions – under what conditions Cont is more likely to perform better and given that Cont is trained on top of BERT, what are the features of BERT that are important in this case. The paper should address the merits of BERT that are part of Cont but not of SCR. Additional experiments may help to show whether this is a data problem or a model problem. The paper argues the need for a domain-specific language model for the area of political conflicts and violence. They validate this claim by showing how such a language model can improve downstream tasks in this area. The paper is clearly written and the claims are evaluated well using an extensive set of experiments. The advantage and the utility of the proposed language model are clear but there remain a few gaps that are important to understand the full strength of this model. The authors should present a clear discussion on the advantages and disadvantages of using the domain-specific datasets used in the training. The authors discussed that their dataset has additional words related to terrorism that are not present in a more general-purpose corpus but are there any other types of words that enriched the training of ConfliBERT? We see that only 3 out of 9 problems are related to terrorism. Indeed, the SCR model performed better in all the tasks involving terrorism-related data. On the other hand for protest-related data, we see a mixed performance, where Cont doing better in 2 out of 3 cases. For the case of Cont, are there any disadvantages for not using a general-purpose model/data? What is the percentage of vocabulary that is present in the general dataset but not in the domain-specific data? If this percentage is large, will that create a roadblock in the wider applicability of this language model? On the other hand, having too many unrelated words in the general-purpose data can act as noise for more domain-dependent tasks? The paper will benefit from a more in-depth analysis and comparison of the datasets used against a more generic corpus. Minor point: On page 6, section 5.2, lines 514, 515, it is not clear how the p-values were computed. What tests were performed to compare the two cases?",1.0,1.0,1.0,1.0,nan,0,1,1,-1
5776,NIPS_2018_600,"weakness of the non-local (NL) module [31] that the correlations across channels are less taken into account, and then formulate the compact generalized non-local (CGNL) module to remedy the issue through summarizing the previous methods of NL and bilinear pooling [14] in a unified manner. The CGNL is evaluated on thorough experiments for action and fine-grained classification tasks, exhibiting promising performance competitive to the state-of-the-arts. Positives: + The paper is well organized and easy to follow. + The generalized formulation (8,9) to unify bilinear pooling and non-local module is theoretically sound. + Good performance. Negatives: - Less discussion on the linear version of CGNL using dot product for f. - Missing fundamental comparison to the simple ResBlock. The authors nicely present the generalized formulation toward CGNL by unifying the two previous works of bilinear pooling and non-local module. Though the kernelized (non-linear) correlation function f is well theoretically motivated, the actual form of f that achieves the better empirical performance is a âlinearâ form (dot product). In this regard, the reviewer has the following concerns. - Less discussion about the linear form. If the reviewer correctly understands the CGNL formulation, the linear function f of dot product f (line 204) can greatly simplify the CGNL into Y = X * W_theta * tr[(X*W_phi)â * (X*W_g)] = X * W_theta * tr[(XâX)* W_g* W_phiâ]  = s * X * W_theta, where s = tr[(XâX) * W_g * W_phiâ]= tr[(XâX)* W] is just a scalar and W = W_g*W_phiâ. This reformulation would be beneficial from the following viewpoints. > It reduces the parameters from {W_theta, W_phi, W_g} to {W_theta, W}, which facilitates the implementation. > It is closely related to squeeze-and-excitation (SE) module [9]. The above formulation can be regarded as a bilinear extension of SE from âsqueezeâ viewpoint since it âsqueezesâ the feature map X into the bilinear form of XâX while SE simply employs an average-pooling.  Such discussions as above would help the readers to further understand the methods and to further extend the method. - Missing comparison. Based on the above discussion, one can think that the baseline for the linear CGNL is a simple ResBlock of Z = BatchNorm( X * W_z ) + X, while the linear CGNL is Z = BatchNorm( s * X * W_theta * W_z ) + X  = BatchNorm( s * X * W_tz ) + X. The only difference is the scaling factor s that is also build on X. Through batch normalization, such a scaling might be less effective (during the training) and thus by comparing these closely-related methods, the authors have to clarify its effectiveness of CGNL empirically. Due to this concern, the reviewer can not fairly evaluate the impact of the method on classification performance. [After Rebuttal] The reviewer appreciates the authorsâ efforts to perform the comparison experiments in such a short rebuttal period. The comparison with the standard ResBlock clarifies the effectiveness of the proposed method as well as helps us to further understand how it works. ",+ Good performance. Negatives:- Less discussion on the linear version of CGNL using dot product for f.,-1.0,1.0,-1.0,-1.0,nan,-1,0,-1,-1
1193,ICLR_2023_1294,"weaknesses:
1: The best feature of CLIP is the generality, that is, being able to recognize any image without pre-defined/fixed classes. MUST adapt the CLIP model to a specific dataset (which is the main purpose of this paper). A simple solution is claimed by authors in the limitation section: ""There exists a simple way to address this concern: gather unlabeled image from all the domains of interest, and perform MUST to learn a single model that can generalize to multiple domains."" It would be really great to have 1-2 such experiments to verify this hypothesis.
Minor weaknesses:
2: The paper does not reach out to theoretical backup to explain why MUST works.
3: Adding results on ImageNet-Sketch will further strengthen this paper.
4: A related work [1] is worth discussing.
[1]: Test-time training with masked autoencoders, NeurIPS 2022",2: The paper does not reach out to theoretical backup to explain why MUST works.,-1.0,-1.0,0.0,-1.0,nan,-1,0,-1,-1
4288,NIPS_2020_251,"* The NF assumption was not discussed as compared to a standard SSM which uses additive measurement noise. Placing the emission noise *before* the nonlinearity is a crucial move; otherwise filtering is not tractable. I would have appreciated further discussion of the impact of this. It's possible that this technique can be applied as a drop-in replacement in many models to avoid awkward approximations such as EKF, UKF and PF; however this conclusion is not immediate from the work presented in this paper. * As a simple example, consider a univariate example where $f$ is a sigmoid, and the true $z = -5$, hence $\E[y] ≈ 0$. If $y$ is observed with additive noise of +0.2, the inferred $z = f^{-1}(0.2) ≈ -1.4$, which may cause substantial problems for inference and learning. * The qualitative experiments seemed particularly artificial; I did not learn much here beyond the fact that the implementation broadly seems to work. If these are indicative of a real-world problem, it would be helpful to make this clearer. * NKF does not show markedly better performance than the GP-Copula model in the main experiments.","* As a simple example, consider a univariate example where $f$ is a sigmoid, and the true $z = -5$, hence $\E[y] ≈ 0$. If $y$ is observed with additive noise of +0.2, the inferred $z = f^{-1}(0.2) ≈ -1.4$, which may cause substantial problems for inference and learning.",-1.0,1.0,1.0,0.0,nan,0,0,1,1
352,ICLR_2022_2232,"Weaknesses
The writing should be improved overall. Issues throughout include grammar, misuse of commas, capitalization (as in reference to algorithm 1 on page 6), technical details left out, poor formatting.
There seems to be a lack of novelty in the modeling approach: the same training schemes, DNN model, etc have been developed before, in papers that are cited by this one.
The results are rather limited and do not seem to show a clear advantage over standard techniques.
Some sentences have unclear meaning, e.g.: Page 1 - ‘a manual adaptation and business knowledge are needed…” - ‘its dynamic dimension reflects directly the demand change over the learning steps…” Page 2 - ‘Before we deep dive in the model architecture and present its main components, we should briefly highlight some problem-related concepts’ - the narration is too casual Page 5 - Equation 13 label is cut off - means that violation is given -infinity in what sense? A large floating point number? Page 6 - Training: Sample rollout and greedy rollout - are these ever defined? What is the baseline function used in the REINFORCE algorithm? Page 7 - Google OR-Tools baseline - what are the details of the implementation? Is it the CP-Sat solver? A specialized solver? - What is the meaning of the numbers in Table 1? Is lower better? - Why does RNN-RL appear twice in Table 2 with different results? - Is OR-tools called with a solver timeout? Or it is allowed to run to completion? - The results for RNN-RL are very similar to OR-tools. Can you highlight what is thew advantage of your method?
General questions:
Because the solution is built incrementally, is it possible to take an action that leads to no further feasible actions? (Assuming that feasible solutions require every demand to be met - this isn’t made clear in the VRPTW description). This case is different from those in the remark on page 5 - what is done in this case?
Generally, does the masking scheme guarantee solutions to be feasible? Is this discussed in the paper?
What is the novelty of the approach? The network architecture, training scheme, masking, input representation, etc have all been studied before.","- The results for RNN-RL are very similar to OR-tools. Can you highlight what is thew advantage of your method? General questions: Because the solution is built incrementally, is it possible to take an action that leads to no further feasible actions? (Assuming that feasible solutions require every demand to be met - this isn’t made clear in the VRPTW description). This case is different from those in the remark on page 5 - what is done in this case? Generally, does the masking scheme guarantee solutions to be feasible? Is this discussed in the paper? What is the novelty of the approach? The network architecture, training scheme, masking, input representation, etc have all been studied before.",1.0,1.0,0.0,1.0,nan,1,1,-1,-1
2582,NIPS_2019_933,"weaknesses: + I liked the simplicity of the solution to divide the problem into star graphs. The domination number introduced seems to be a natural quantity for this problem. +/- To my opinion, the setting seems somewhat contrived combining feedback graphs and switching costs. The application to policy regret with counterfactual however provides a convincing example that the analysis can be useful and inspire future work. +/- The main part of the paper is rather clear and well written. Yet, I found the proofs in the appendices sometimes a bit hard to follow with sequences of unexplained equations. I would suggest to had some details. - There is a gap between the lower bound and the upper-bound (\sqrt(\beta) instead of \beta^{1/3}). In particular, for some graphs, the existing bound with the independence number may be better. This is also true for the results on the adaptive adversary and the counterfactual feedback. Other remarks: - Was the domination number already introduced for feedback graphs without switching costs? If yes, existing results for this problem should be cited. If not, it would be interesting to state what kind of results your analysis would provide without using the mini-batches. - Note that the length of the mini-batches tau_t may be non-integers. This should be clarified to be sure there are no side effects. For instance, what happens if $\tau_t << 1$? I am not sure if the analysis is still valid. - A better (more formal) definition of the independence and the domination numbers should be provided. It took me some time to understand their meaning. - Alg 1 and Thm 3.1: Since only upper-bounds on the pseudo-regret are provided, the exploration parameter gamma seems to be useless, isn't it? The choice gamma=0 seems to be optimal. A remark on high-probability upper-bounds and the role of gamma might be interesting. In particular, do you think your analysis (which is heavily based on expectations) can be extended to high-probability bounds on the regret? - I understand that this does not suit the analysis (which uses the equivalence in expectation btw Alg1 and Alg6) but it seems to be suboptimal (at least in practice) to discard all the feedbacks obtained while playing non-revealing actions. It would be nice to have practical experiments to understand better if we lose something here. It would be also nice to compare it with existing algorithms.  Typos: - p2, l86: too many )) - Thm 3.1: A constant 2 in the number of switches is missing. - p13, l457: some notations seem to be undefined (w_t, W_t). - p14, you may add a remark - p15, l458: the number of switches can be upper-bounded by **twice** the number of times the revealing action is played - p16, l514: I did not understand why Thm 3.1 implies the condition of Thm C.5 with alpha=1/2 and not 1. By the way, (rho_t) should be non-decreasing for this condition to hold. ","- p2, l86: too many )) - Thm 3.1: A constant 2 in the number of switches is missing. - p13, l457: some notations seem to be undefined (w_t, W_t). - p14, you may add a remark - p15, l458: the number of switches can be upper-bounded by **twice** the number of times the revealing action is played - p16, l514: I did not understand why Thm 3.1 implies the condition of Thm C.5 with alpha=1/2 and not 1. By the way, (rho_t) should be non-decreasing for this condition to hold.",1.0,1.0,0.0,0.0,nan,-1,1,-1,1
5529,NIPS_2020_1796,"While the result is interesting, many of the design decisions behind the models and training procedures seemed poorly motivated and discussion on their nuances lacking. - Why represent the rewards as a function of a VAE used to encode exploratory frames in the environment? How does more or less exploration impact the effect of the auxiliary rewards learned this way? - What is the impact of environment ordering during training? Are there any curriculum effects at play? Why train with such a curriculum in the first place? An ablation demonstrating the necessity of this approach would contextualize this decision. - The language stating ""the agent learns R_AUP"" was confusing (Line 138). The reviewer believes this language was meant to describe ""training the Q_i functions"" corresponding to each R_i. This confusing language was used in the caption for the reward learning curves in the supplementary materials, which seems supported by the statement starting on Line 202: ""In the supplementary material..."" - Some key concepts are not defined, for example ""initial state reachability"" (Line 42). - It seems the claim that safe reinforcement learning focuses on just avoiding negative side effects during training is inaccurate. As stated in the abstract of a paper the authors cite (García et al, 2015), safe RL is also concerned with safety at deployment. - The language is often unclear, e.g. Line 211: ""AUP stops moving entirely."" The reviewer believes this is referring to the AUP learning a policy in which the agent remains immobile. - The discussion around the theoretical results (3.2) does not add much insight to the experiments and results presented in the paper. - The contribution is not very novel, as it is simply applying AUP as presented in Turner et al, 2020 to another environment, with little to no modification. - Not clear why Lines 55-57 are included in the related work, as they do not seem particularly relevant to safe RL.",- Why represent the rewards as a function of a VAE used to encode exploratory frames in the environment? How does more or less exploration impact the effect of the auxiliary rewards learned this way?,0.0,1.0,0.0,0.0,nan,-1,1,0,-1
5136,NIPS_2020_44,"The main weaknesses which make me a little less excited about this work are mostly related to the scalability of the algorithm(s) and the applications of their techniques. - Scalability: Barrier-Greedy++ is not scalable but achieves a slightly better approximation (by a factor of 2) compared to the relatively more scalable Barrier-Greedy. However, Barrier-Greeedy itself though is linear in n, is cubic in r (which is the size of the largest feasible set). Even if r is a fraction of n (say, 10% of n), the algorithm is still cublc in n which could be very slow for n in range of a million instances. - Motivating applications: Given that greedy algorithm already achieves a factor of k for multiple matroid constraints (which occur mostly in practice), I do not see this algorithm being useful in only the matroid case. Moreover, I do not see any guarantees in the *only* knapsack case (i.e. if there is no matroid constraint). As far as I have seen even in the related work of Mirzasoleiman et al and Feldman et al, they either have only matroid constraints or only knapsack constraints. I would really like the authors to clarify this. In my opining, this paper would be significantly strenghted if this algorithm applies to only multiple knapsack constraints. It seems the algorithm also has an additional assumption of (l \leq k) whcih the authors later relax (but this part was not super clear in the paper).","- Scalability: Barrier-Greedy++ is not scalable but achieves a slightly better approximation (by a factor of 2) compared to the relatively more scalable Barrier-Greedy. However, Barrier-Greeedy itself though is linear in n, is cubic in r (which is the size of the largest feasible set). Even if r is a fraction of n (say, 10% of n), the algorithm is still cublc in n which could be very slow for n in range of a million instances.",-1.0,1.0,1.0,0.0,nan,0,0,-1,-1
3946,NIPS_2020_1659,"The ability of EvolveGraph to uncover known dynamic relations is not explored in as much detail as it could be. More specifically, the one synthetic experiment designed to evaluate this is somewhat simple, in that all relations change from ""active"" to ""inactive"" for all entities at the same moment in time, and this switch happens once. What happens when relations change at different times for different variables? What happens if the re-encoding gap is ""out of sync"" with the actual change in relations? How well does the model perform if relations change multiple times aperiodically? These questions are not explored here. There are a few modeling decisions which are made that are not explained or explored either. The ones that stick out to me: - The observation model has learned attentional coefficients that seem to be static across time. Do these contribute meaningfully to model performance? Also, doesn't the fact that these coefficients are static mean that they ""pre-determine"" the impact some variables have on others in a data-agnostic manner? - A different prediction mode is selected for each variable for every time step. What happens if modes are re-evaluated less often? How do the frequency of mode selection and relation re-prediction relative to each other impact final performance? - How many modes does the model predict, and how does performance vary as the number of predicted modes changes? Right now, it's difficult to understand if the performance improvements are primarily due to modeling multi-modality, modeling dynamic relations, or both. These criticisms are relatively minor, however; there is enough present in this work for it to be a worthwhile publication.","- The observation model has learned attentional coefficients that seem to be static across time. Do these contribute meaningfully to model performance? Also, doesn't the fact that these coefficients are static mean that they ""pre-determine"" the impact some variables have on others in a data-agnostic manner?",0.0,1.0,0.0,0.0,nan,1,1,-1,1
196,ICLR_2022_1224,"Weakness] 1. One of the experimental results can be interpreted differently so that one of the contributions can be just a misreading of the experimental results. 2. Some parts of the paper require more explanations and formal descriptions about the concepts.
[Comments] 1. About Figure 2b, as far as I understand, the authors tested two attack methods (single-point attack and multi-point attack) against two ResNet50 models (regular and robust) over the same set of target data points. (If they are tested on different sets of target data points, it could be an unfair comparison.) Then, against the regular ResNet50 model, the single-point attack can find much better perturbations (than the multi-point attack) for the same set of target data points. Doesn’t this just mean that “the multi-point attack is not effective against the regular ResNet50 model” rather than “adversarially trained model is more vulnerable (than the regular ResNet50 model) against the multi-point attack”? In other words, the main contribution that “certain black-box attack can perform better against adversarially trained model” is just a misreading of the experimental result and there is another possible interpretation that “the multi-point attack is not effective against the regular model”. (The reason for this another interpretation could be the reason that is provided by the authors; a regular model has a less smooth boundary.) Also, the comparison with DeepFool (Figure 3b) says that the robustness gain is bigger for white-box attacks (constantly 17) compared to other black-box attacks. However, since the robustness gain is defined as a ratio, this value can be small just because black-box attacks cannot find a small enough perturbation for regular models. Again, we still don’t know whether this is because of the vulnerability of adversarially trained models or because of the poor performance of the black-box attacks. I suggest the authors check the average perturbation sizes to show that the black-box attacks do not perform poorly against the adversarially trained model. 2. First, robustness gain is only briefly described in the introduction and I cannot see any formal definition of it. Even though experiments are the only way to compute the robustness gain, it is better to describe it formally (an ideal & theoretical definition. If there is any reference that supports the concept, cite it.) and explain the intuition behind the concept. Second, more details are needed for the robustness gain experiment. The main motivation for this experiment is unclear. η
(which must be the robustness gain) was not defined before it is mentioned. 3. Lastly, I don’t think that robustness gain is a good measure to make comparisons. This is because the robustness gain is a ratio so it can be decreased by the poor performances of black-box attacks against a regular model. In other words, it is unclear whether the results come from the vulnerability of an adversarially trained model against black-box attacks or the results just come from the poor performance of the attacks against a regular model.","2. First, robustness gain is only briefly described in the introduction and I cannot see any formal definition of it. Even though experiments are the only way to compute the robustness gain, it is better to describe it formally (an ideal & theoretical definition. If there is any reference that supports the concept, cite it.) and explain the intuition behind the concept. Second, more details are needed for the robustness gain experiment. The main motivation for this experiment is unclear. η (which must be the robustness gain) was not defined before it is mentioned.",1.0,1.0,0.0,1.0,nan,1,1,-1,1
2582,NIPS_2019_933,"weaknesses: + I liked the simplicity of the solution to divide the problem into star graphs. The domination number introduced seems to be a natural quantity for this problem. +/- To my opinion, the setting seems somewhat contrived combining feedback graphs and switching costs. The application to policy regret with counterfactual however provides a convincing example that the analysis can be useful and inspire future work. +/- The main part of the paper is rather clear and well written. Yet, I found the proofs in the appendices sometimes a bit hard to follow with sequences of unexplained equations. I would suggest to had some details. - There is a gap between the lower bound and the upper-bound (\sqrt(\beta) instead of \beta^{1/3}). In particular, for some graphs, the existing bound with the independence number may be better. This is also true for the results on the adaptive adversary and the counterfactual feedback. Other remarks: - Was the domination number already introduced for feedback graphs without switching costs? If yes, existing results for this problem should be cited. If not, it would be interesting to state what kind of results your analysis would provide without using the mini-batches. - Note that the length of the mini-batches tau_t may be non-integers. This should be clarified to be sure there are no side effects. For instance, what happens if $\tau_t << 1$? I am not sure if the analysis is still valid. - A better (more formal) definition of the independence and the domination numbers should be provided. It took me some time to understand their meaning. - Alg 1 and Thm 3.1: Since only upper-bounds on the pseudo-regret are provided, the exploration parameter gamma seems to be useless, isn't it? The choice gamma=0 seems to be optimal. A remark on high-probability upper-bounds and the role of gamma might be interesting. In particular, do you think your analysis (which is heavily based on expectations) can be extended to high-probability bounds on the regret? - I understand that this does not suit the analysis (which uses the equivalence in expectation btw Alg1 and Alg6) but it seems to be suboptimal (at least in practice) to discard all the feedbacks obtained while playing non-revealing actions. It would be nice to have practical experiments to understand better if we lose something here. It would be also nice to compare it with existing algorithms.  Typos: - p2, l86: too many )) - Thm 3.1: A constant 2 in the number of switches is missing. - p13, l457: some notations seem to be undefined (w_t, W_t). - p14, you may add a remark - p15, l458: the number of switches can be upper-bounded by **twice** the number of times the revealing action is played - p16, l514: I did not understand why Thm 3.1 implies the condition of Thm C.5 with alpha=1/2 and not 1. By the way, (rho_t) should be non-decreasing for this condition to hold. ","- Alg 1 and Thm 3.1: Since only upper-bounds on the pseudo-regret are provided, the exploration parameter gamma seems to be useless, isn't it? The choice gamma=0 seems to be optimal. A remark on high-probability upper-bounds and the role of gamma might be interesting. In particular, do you think your analysis (which is heavily based on expectations) can be extended to high-probability bounds on the regret?",0.0,1.0,-1.0,0.0,nan,1,-1,-1,1
280,ICLR_2022_586,"weakness I see is the way of presenting the results in Fig. 3. All the percentages of optimally solved problems are relatively low, so the plots for some algorithms are not clearly visible (however, it is clear that the introduced algorithm outperforms other approaches). I recommend acceptance of this article.","3. All the percentages of optimally solved problems are relatively low, so the plots for some algorithms are not clearly visible (however, it is clear that the introduced algorithm outperforms other approaches). I recommend acceptance of this article.",0.0,1.0,0.0,0.0,nan,-1,1,-1,-1
1646,ICLR_2023_1255,"Weakness:
The description of the developed methodology is unclear. It is hard to follow the work. The notation and equation formulation are complicated. Together with the corresponding explanation, they should be largely improved.
The long range information is the main advantage of the proposed method, however, there are no corresponding experimental discuss or theoretical analyses in the manuscript.
The computation complexity analysis is a big concern. The proposed method uses more parameters and computation steps during message passing, this would bring lots of computation burden. However, from the real dataset experimental results in table 4, the performance promotion is slight. 4 The novelty isn't particularly high. Most techniques used were proposed and demonstrated before.
How about experimental results on the PDBbind dataset.",4 The novelty isn't particularly high. Most techniques used were proposed and demonstrated before. How about experimental results on the PDBbind dataset.,1.0,1.0,-1.0,0.0,nan,-1,-1,-1,-1
4450,NIPS_2020_1451,"1. Unlike the works HaoChen and Sra and Nagaraj et.al, this work uses the fact that all component functions f_i are mu strongly convex. 2. The authors need to explain why removing some of the assumptions like bounded variance and bounded gradients is an important contribution via. solid examples. 3. The quantity sigma^{*} being finite also implies that all the gradients are finite via. smoothness property of the functions f_i and gives a natural upper bound.",2. The authors need to explain why removing some of the assumptions like bounded variance and bounded gradients is an important contribution via. solid examples.,1.0,1.0,0.0,0.0,nan,-1,1,-1,1
4812,NIPS_2020_1627,"- While the theoretical results seem correct, it is not clear to me the advantages of this approach compared to previous work, in particular, gradient Q-learning (GQ). On line 110, it is written that the assumptions are not as stringent but I am not convinced that this is the case. Could the authors clarify this point? - Assumption 1 does not seem very natural to me. If I am interpreting it correctly, it assumes that we have a fixed replay buffer of data on which we are doing updates, as in the offline batch RL setting. It is not specified which policy is used to collect this data and I would expect certain assumptions on this behavior policy. - I do not think assumption 4 would be extremely realistic in practice, but I think this is acceptable in this case since it seems like this assumption is mainly made to provide more insight on the performance of the algorithm (in a special case). As such, I would be more comfortable if it was presented as such, instead of trying to justify it in practice. For example, line 196: ""We note that Assumption (IV) does not impose any additional constraint on the features considered, since we can make them orthogonal and scale them to ensure that the latter assumption holds."" I do not find this argument convincing since we may be given features that do not satisfy this condition in practice or features may be changing over time if they are being learned. - I would have appreciated some more explanation concerning the intuition of the two-timescale updates. Line 121: ""...but instead match the projection of the output along the feature space, much like the “pre-conditioning” step from [1]."" seems to hint at the idea but it is not clear to me exactly what this means. - One of the contributions is listed as ""A better theoretical understanding for the use of the target network in DQN."" (line 112). I think the paper could have included more explanations about this point. Currently, I cannot find much discussion about how CQL informs us about DQN. - For the empirical experiments, it is not clear how the hyperparamters were selected. On line 222, it is simply written what the step sizes are but the algorithms can be sensitive to this choice. It would be much more informative if sweeps over the two step sizes were done and the algorithms' sensitivity to them was assessed. Full parameter sweeps seems feasible in this case due to the simplicity of the environments. - For the mountain car experiments, it is surprising that only 3 training runs were done (line 255) for each algorithm. I would expect many more for such a simple environment, say, at least 10. Currently, the standard errors are very large and it is difficult to make meaningful comparisons between the algorithms.","- I would have appreciated some more explanation concerning the intuition of the two-timescale updates. Line 121: ""...but instead match the projection of the output along the feature space, much like the “pre-conditioning” step from [1]."" seems to hint at the idea but it is not clear to me exactly what this means.",1.0,1.0,1.0,1.0,nan,-1,1,-1,1
5493,NIPS_2020_393,"Even though the paper is well written, simple to follow and provides an extensive set of experiments. However, the paper is relatively dense and a lot of further insight can be found in the appendix (which could almost already make another paper). Nevertheless, certain aspects of the analysis seem to be brushed over or left out: - Section 4 starts with the statement that it has been shown that deep ensembles indeed perform Bayesian Model Averaging, however no part of Section 3 directly addresses this point. It is clear that ensembles perform some sort of model averaging, however it would be interesting to further discuss the form q(w|D) takes in deep ensembles and which implicit assumptions about the prior are made and whether deep ensembles recover the true p(w|D) in the limit of infinite models in the ensemble (Sampling perspective?) or whether they are closer to a variational approximation and which implicit assumptions are made about the form of q(w|D). - Fig 3 offers a comparison of different predictive distributions and it is claimed that an increase in samples does not improve the estimate of the predictive distribution for SVI. However, I believe that this is an unfair comparison as this estimate is strongly influenced by the form of variational approximation used. Therefore, an approximation with little expressive power can only gain little improvements by further samples, whereas more complicated variational distributions might cover multiple modes in the weight distribution and could benefit from more samples. This should me more thoroughly examined.","- Section 4 starts with the statement that it has been shown that deep ensembles indeed perform Bayesian Model Averaging, however no part of Section 3 directly addresses this point. It is clear that ensembles perform some sort of model averaging, however it would be interesting to further discuss the form q(w|D) takes in deep ensembles and which implicit assumptions about the prior are made and whether deep ensembles recover the true p(w|D) in the limit of infinite models in the ensemble (Sampling perspective?) or whether they are closer to a variational approximation and which implicit assumptions are made about the form of q(w|D).",1.0,1.0,1.0,1.0,nan,-1,0,1,1
2578,NIPS_2019_1348,"Weaknesses: 0. My first concern is the assumption that a human risk measure is gold standard when it comes to fairness. There are many reasons to question this assumption. First, humans are the worst random number generators, e.g. the distribution over random integers from 1 to 10 is highly skewed in the center. Similarly, if humans perceive a higher risk in the tails of a distribution, it doesn't necessarily mean that minimizing such risk makes the model fair. This still needs to be discussed and proven. 1. The paper suggests that using EHRM has fairness implications. These fairness implications are obtained as a side effect of using different hyperparameter setting for the skewness of the human risk distribution. There is no direct relationship between fairness consideration and the risk metric used. 2. In the Introduction, the authors choose to over-sell their work by presenting their work as a ""very natural if simple solution to addressing these varied desiderata"" where the desiderata include ""fairness, safety, and robustness"". This is a strong statement but incorrect at the same time. The paper lacks any connection between these objectives and the proposed risk metric. One could try to investigate these connections before claiming to address them. 3. One example of connection would be the definition of Calibration used in, for example, Kleinberg et al. and connect it to a human calibration measure and derive a Human risk objective from there as well. It is a straightforward application but the work lacks that. 4. There are no comparison baselines even when applying to a fairness problem which has a number of available software to get good results. Agarwal 2018: ""A Reductions Approach to Fair Classification"" is seemingly relevant as it reduces fairness in classification to cost-sensitive learning. In this case, the weighting is done on the basis of the loss and not the group identities or class values, but it may be the reason why there is a slight improvement in fairness outcomes. Since the EHRM weights minorities higher, it might be correlated to the weights under a fair classification reduction and hence giving you slight improvements in fairness metrics. 5. There were a few typos and some other mistakes: - doomed -> deemed (Line50) - Line 74: Remove hence. The last line doesn't imply this sentence. It seems independent. ","0. My first concern is the assumption that a human risk measure is gold standard when it comes to fairness. There are many reasons to question this assumption. First, humans are the worst random number generators, e.g. the distribution over random integers from 1 to 10 is highly skewed in the center. Similarly, if humans perceive a higher risk in the tails of a distribution, it doesn't necessarily mean that minimizing such risk makes the model fair. This still needs to be discussed and proven.",1.0,1.0,1.0,0.0,nan,0,-1,-1,0
5748,NIPS_2018_394,"Weakness: - The experiments are insufficient to validate the claim. Only CIFAR10/100 are used, but many of studied techniques that were effective on CIFAR10/100 and MNIST turned out ineffective on other larger datasets/tasks. I would be happy to raise my score if the authors could provide ImageNet improvement (at least for SO and SRIP). - As the authors also implied, MC is not enforced in the âright wayâ (columns not normalized). I would like the authors to report their MC performance with column normalization for completeness. ","- The experiments are insufficient to validate the claim. Only CIFAR10/100 are used, but many of studied techniques that were effective on CIFAR10/100 and MNIST turned out ineffective on other larger datasets/tasks. I would be happy to raise my score if the authors could provide ImageNet improvement (at least for SO and SRIP).",-1.0,1.0,-1.0,-1.0,nan,1,1,-1,-1
2969,NIPS_2022_1846,"Weaknesses and Questions 1. For the distribution estimation, this paper uses three Gradient flow networks to learn different parameters. According to Section 4.3, the networks learn specific parameters for each class using different inputs (i.e., x ¯ j
). That is to say, the network F 1
will output c j j = 1 n for n
classes. However, in Line 142, the authors point that the parameter c
is shared between all classes. How to unify this c
? 2. How to update F 2
, and F 3
via minimizing Eq. (16)? When the classifiers are fixed, it seems that only the network F 1
can be trained. 3. Some experimental details are missing. 3.1. What is the ratio of training data D t
to validation data D v
in the training stage. 3.2. What is the value of initial c
. 4. In Table 2, the metric-based baseline FEAT performs similar accuracy to the proposed method. It’s better to discuss the superiority of the method in terms of time consumption. According to Algorithm 2, the upper bound Eq. (14) simplifies the training of classifiers, but Eq. (16) is still difficult to compute. Typo: In Table 2, the description does not match the content, e.g., ""Euclidean Metric"" (or ""Hyperbolic Metric"") and ""Model"".","2. How to update F 2 , and F 3 via minimizing Eq. (16)? When the classifiers are fixed, it seems that only the network F 1 can be trained.",1.0,1.0,0.0,0.0,nan,-1,0,-1,1
3401,NIPS_2020_1223,"*Temporal logic as such is often useful when considering infinite traces. Signal temporal logic is quite useful in the case of finite-time traces when dealing with continuous time systems. Neither of them are under consideration here, and I think this is the biggest draw back. *Novelty is quite limited. Much of the ideas in the paper have been introduced before. I will list some out here (which hasn't been discussed in the paper): 1. Writing STL specifications in terms of DNF specifications/using logical operators has been done previous in works such as: a) https://arxiv.org/abs/1703.09563 (they use DNFs/MILPS, which are equivalent), b) https://openreview.net/forum?id=BklC2RNKDS *Projecting outputs to satisfy constraints has been considered in works such as: a)https://arxiv.org/pdf/1805.07075.pdf, b) https://arxiv.org/abs/1801.08757 c)https://arxiv.org/abs/1603.06318. In fact, if you're only looking at finite+discrete time traces, this work is quite similar to c. Without considering infinite traces, the STL specifications reduce to first-order logic specifications as considered in c already. 2. There is a rich history of consider temporal logic specifications, and even STL specifications in the CPS community. As such, the specifications introduced here are not novel/new. 3. Propositions 4.1, 4.2 and 4.3 are trivial/obvious to the best of my knowledge. 4. There's very little discussion in terms of related work regarding enforcing STL/TL specifications for learning systems -- there have been several papers attempting to do this. a) https://robotics.sciencemag.org/content/4/37/eaay6276.full b) https://dorsa.fyi/publications/sadigh2014learning.pdf c) https://dl.acm.org/doi/abs/10.5555/3306127.3331994 d) https://openreview.net/forum?id=BklC2RNKDS","*Temporal logic as such is often useful when considering infinite traces. Signal temporal logic is quite useful in the case of finite-time traces when dealing with continuous time systems. Neither of them are under consideration here, and I think this is the biggest draw back. *Novelty is quite limited. Much of the ideas in the paper have been introduced before. I will list some out here (which hasn't been discussed in the paper):",1.0,1.0,-1.0,0.0,nan,-1,-1,-1,-1
3013,NIPS_2022_1564,"Weaknesses:
1.The main part can be more concise (especially for the introduction part)and including empirical results.
2.Given the new introduced hyper-parameters, it is still not clear whether this new proposed method is empirically useful. How to choose hyper-parameters in a more practical training setting?
3.The empirical evaluations can not well supported their theoretical analysis. As the authors claim running experiments with 24 A100 GPUs, all methods should be compared in a relatively large scaled training task. Only small linear regression experiment results are reported, where communication is not really an issue.
The paper discusses a new variant on a technique in distributed training. As far as I’m concerned, there is no serious issue or limitation that would impact society.","3.The empirical evaluations can not well supported their theoretical analysis. As the authors claim running experiments with 24 A100 GPUs, all methods should be compared in a relatively large scaled training task. Only small linear regression experiment results are reported, where communication is not really an issue. The paper discusses a new variant on a technique in distributed training. As far as I’m concerned, there is no serious issue or limitation that would impact society.",nan,nan,nan,nan,nan,-1,-1,-1,-1
5328,NIPS_2020_1036,"* I was surprised to see, after the authors touted advantages of using a consistent training and test implementations, that the results of the (UN+UQ) system were significantly worse than those of the ""inconsistent"" solution introduced by Balle et al 2017 (UN+Q). Only when the softened quantizer is added (UN+UQ+SR) do we see a relatively small improvement. Why? Are there potential ways to improve this? * This makes one wonder about how much the UQ noise matters. In particular, it would be instructive to see a comparison to (UN+SR). Given the previous comment, one might suspect this would lead to even better performance - and thus that the UQ methodology, despite its mathematical interest, is not of practical value. * Although I think it's important and interesting, this is a pretty heavy and narrowly-focused topic for the NeurIPS community.","* This makes one wonder about how much the UQ noise matters. In particular, it would be instructive to see a comparison to (UN+SR). Given the previous comment, one might suspect this would lead to even better performance - and thus that the UQ methodology, despite its mathematical interest, is not of practical value.",nan,nan,nan,nan,nan,1,-1,-1,1
5646,NIPS_2018_809,"Weakness: - The uniqueness of connecting curves between two weights would be unclear, and there might be a gap between the curve and FGE. A natural question would be, for example, if we run the curve findings several times, we will see many different curves? Or, those curves would be nearly unique?  - The evidences are basically empirical, and it would be nice if we have some supportive explanations on why this curve happens (and whether it always happens). - The connections of the curve finding (the first part) and FGE (the second part) would be rather weak. When I read the first part and the title, I imagined that take random weights, learn curves between weights, and find nice wights to be mixed into the final ensemble, but it was not like that. (this can work, but also computationally demanding)  Comment: - Overall I liked the paper even though the evidences are empirical. It was fun to read. The reported phenomena are quite mysterious, and interesting enough to inspire some subsequent research. - To be honest, I'm not sure the first curve-finding part explains well why the FGE work. The cyclical learning rate scheduling would perturb the weight around the initial converged weight, but it cannot guarantee that weight is changing along the curve described in the first part.","- Overall I liked the paper even though the evidences are empirical. It was fun to read. The reported phenomena are quite mysterious, and interesting enough to inspire some subsequent research.",nan,nan,nan,nan,nan,0,1,-1,0
5563,NIPS_2020_1167,"The motivation and illustration are not clear. The details are as follows, 1. Why the RANet can capture more context information than SPP and previous attentional models? The authors claim that RANet naturally provides the spatial and category relationship of pixels to construct the contextual representations, but the category information in RANet may be not accurate, which could results in error guiding information. 2. After obtaining the contextual representation $O$ as described by Eq.(8), how to get the final segmentation map? 3.In Eq.(1), $B_{i \arrow j}$ denote a set of pixels on the line, what is the direction of the line? Vertical?horizontal？or oblique？","3.In Eq.(1), $B_{i \arrow j}$ denote a set of pixels on the line, what is the direction of the line? Vertical?horizontal？or oblique？",nan,nan,nan,nan,nan,-1,0,0,1
5592,NIPS_2018_55,"weakness of this paper lies in the evaluation. Although it is a great thing that this paper uses more datasets than MNIST, the evaluation can be much improved. 1) The statements in the MNIST experiment such as ""While results without an CAE are quite convincing, the CAE clearly improves the pertinent positives and negatives in many cases. Regarding pertinent positives, the cyan highlighted pixels in the column with CAE (CAE CEM PP) are a superset to the cyan-highlighted pixels in column without (CEM PP). While these explanations are at the same level of confidence regarding the classifier, explanations using an AE are visually more interpretable."" are problematic. These are quite subjective statements, and some form of quantitative evaluation across subjects is required for such claims. 2) In the procurement fraud experiment, it seems that the experts like everything that the algorithm shows. Risk evaluation seems a non-trivial problem. It is unclear whether these experts or humans are good at this task. Also, given the sample size, it is unclear whether the difference in Table 1 is statistically significant.  3) This paper did not provide enough information regarding how the evaluation was done in the brain functional imaging experiment. It seems that the only sentence is ""With the help of domain experts"". 4) c, \beta, and \gamma are important parameters for the proposed approach. The main paper did not discuss the choice of these parameters at all, and the supplementary material only gives procedural information. It would be great if this paper provides more thoughtful discussions on the choices of these parameters, or maybe the insensitivity of these parameters if that is the case. Overall, I really like the idea of this paper and believe that this paper should be accepted. Given the space limit of NIPS submissions, one possible way to improve the paper is to drop one experiment and make the other two experiments more solid. Minor presentation-related suggestions:   I like the introduction overall, but the first sentence seems a bit out of nowhere and statements such as ""Explanations as such are used frequently by people"" are questionable and at least requires better evidence.   line 218: an CAE -> a CAE   line 252: spend -> spending I have read the review and it would be useful if the user can clarify how some set operations in the formulation apply to continuous variables.","2) In the procurement fraud experiment, it seems that the experts like everything that the algorithm shows. Risk evaluation seems a non-trivial problem. It is unclear whether these experts or humans are good at this task. Also, given the sample size, it is unclear whether the difference in Table 1 is statistically significant.",nan,nan,nan,nan,nan,-1,0,-1,-1
5632,NIPS_2018_1007,"Weakness: Which brings us to various unclear parts in the paper. First of all, there are key claims that are hard to justify. For instance: ""a key strength of neural models is their effectiveness at efficient transfer"". I am sure you'll find a lot of disagreement here especially when you are not working in the vision community where ImageNet models transfer fairly well. This is not the case with models trained with RL (DQN or policy gradients) because the gradients are a lot noisier and the representations learning is more difficult. Another example being, ""A3C algorithm [â¦], because it is simple, robust and stable"" is hard to swallow given the term ""asynchronous"" in the algorithm. The paper's treatment of ""transfer"" is quite unclear too. Transfer learning has a long history and would refer to multiple surveys on transfer in RL [1,2] to better place their objective. Moreover, we can expect that the NIPS audience wouldn't know as much about symbolic AI and RDDL description, so use of terms like fluents without defining them first, leaves things unclear to the reader. Similarly, even thought the components of the architecture are clearly explained individually, their exact combination and how exactly the losses are setup is quite unclear. I hope the authors are atleast planning on releasing their code for easier replication. There are quite a few components in the proposed method. Whether they are warranted can only be checked by experimental verification. The paper is quite unclear about the exact nature of these problem domains - what's the observation space like, what are the possible number of problems that are generated in a domain, etc. (One can look it up on IPPC but making the paper clear would be better). Moreover, since these are planning problems it's hard to say if DeepRL algorithms like A3C are right baselines to benchmark against. The paper _is_ using the model after all (transition). Wouldn't it be useful to at least show the standard methods used in IPPC and their efficiency. Do we even gain on anything at all by showing transfer abilities if the total time taken by standard planning algorithms for each problem domain is less than learning via DeepRL? Moreover it's unclear what were the parameters of A3C algorithms itself - number of workers/batch size etc. It doesn't look like Figure 2 and Figure 3 show averaged runs over multiple seeds (maybe fill color to show standard error?) nor is there any standard deviation for Table 2 results. So although the inclusion of ""SAD"" seems pretty big as an improvement, I can't make a strong claim given how much variance there can be with DeepRL experiments.  # Minor things:  - Line 85: Missing citation? - Line 329: Not sure if Table 2 suggests that. Possibly meant to be Figure 3? [1]: http://www.jmlr.org/papers/volume10/taylor09a/taylor09a.pdf [2]: https://hal.inria.fr/hal-00772626/document ",- Line 329: Not sure if Table 2 suggests that. Possibly meant to be Figure 3? [1]: http://www.jmlr.org/papers/volume10/taylor09a/taylor09a.pdf [2]: https://hal.inria.fr/hal-00772626/document,nan,nan,nan,nan,nan,1,1,1,1
4011,NIPS_2020_182,"1. The utilization of the approximation in (10) is not properly validated. For example, the error between the approximation of the deep neural network and the original Mori-Zwanzig memory term is not evaluated. 2．In the section of numerical experiments, different baselines are compared in different tasks. However, choosing them in these tasks is not well justified. For example, InfluLearner is only compared in the task of Infection probability and influence function estimation. Obviously, by combining with the classical greedy algorithm, it can be compared in the task of Influence Maximization. Thus, why choosing these compared algorithms in different tasks needs more discussion. 3. Technical details in this paper is a bit hard to follow. It is better to given a neural network diagram or a pseudo-code algorithm to help readers between understand the details of the proposed framework. 4. In line 216, it is said that 1,000 source sets are generated. However, in line 224, MAE is only averaged over 100 source sets, which is contrary to previous description. 5. There are many typos in this paper, e.g., - Line 40: “and and reture” - Line 127 and Line 142: “Appendix ??”",3. Technical details in this paper is a bit hard to follow. It is better to given a neural network diagram or a pseudo-code algorithm to help readers between understand the details of the proposed framework.,nan,nan,nan,nan,nan,1,1,0,-1
2396,NIPS_2021_311,"Weaknesses - The paper leaves some natural questions open (see questions below). - Line 170 mentions that the corpus residual can be used to detect an unsuitable corpus, but there are no experiments to support this.
After authors' response All the weakness points have been addressed by the authors' response. Consequently I have raised my score. In particular:
The left open questions have all been answered.
There indeed is an experiment to support this, thanks to the authors' for clarifying this, that connection was not clear to me previously.
Questions - Line 60: Why do you say that e.g. influence functions cannot be used to explain a prediction? The explanation of a prediction could be the training examples whose removal (as determined by the influence function) would lead to the largest score drop for a prediction. - How does the method scale as the corpus size or hidden dimension size is increased? - What happens if a too small corpus is chosen? Can this be detected? - What if we don’t know that a test example is crucially different, e.g. what if we don’t know that the patient of Figure 8 is “British” and we use the American corpus to explain it? Can this be detected with the corpus residual value? - In the supplementary material you mention how it is possible to check if a decomposition is unique. Do you do this in practice when conducting experiments? How do you choose a decomposition if it is not unique? What does it imply for the experiments (and the usage of the method in real-world applications) if the decomposition is not unique?
Typos, representation etc. - Line 50: An example of when a prototype model would be unsuitable would strengthen your argument. - Footnote 2: “or” -> “of” - Line 191: when the baseline is first introduced, [10] or other references would be helpful to support this approach - Line 319: “the the” -> “the” - Line 380: “at” -> “to”?
A broader impact section could be added. In a separate section (e.g. supplementary material), there could be an explicit discussion on when the method should not be used, e.g. as shown in Figure 8, the American corpus shouldn’t be used to explain the British patient. Also see last question above – what if we don’t know that the patient is British? Can this be detected? This should also be discussed in such a section.","- What if we don’t know that a test example is crucially different, e.g. what if we don’t know that the patient of Figure 8 is “British” and we use the American corpus to explain it? Can this be detected with the corpus residual value?",nan,nan,nan,nan,nan,-1,0,0,1
4575,NIPS_2020_1719,"Just 3 concerns: 1. Equation 11 is expressed without the regularization terms ... and it is stated that extending it with the same is straightforward. Is that really so? It is not really that straightforward when projecting. SO authors must expand on this a bit. 2. Justification provided for not comparing against Pareto-frontier search methods is very loose and ambiguous. and not convincing in anyway. Authors should expand on this more. 3. This agnostic formulation in this case is related with solving a minmax problem ... in ""robust MDPs"" or even in adversarial games.... Authors should make an attempt to discuss the same. Finally, while the evaluations are acceptable they definitely have room for improvement, at least in the way the results are discussed. -- that is sub-par. Ideally the authors must define evaluation goals as in what is measured and for what reason.. what is it that they are trying to show. Then when discussed the tables/plots connect the discussion back to the goals.","3. This agnostic formulation in this case is related with solving a minmax problem ... in ""robust MDPs"" or even in adversarial games.... Authors should make an attempt to discuss the same. Finally, while the evaluations are acceptable they definitely have room for improvement, at least in the way the results are discussed. -- that is sub-par. Ideally the authors must define evaluation goals as in what is measured and for what reason.. what is it that they are trying to show. Then when discussed the tables/plots connect the discussion back to the goals.",nan,nan,nan,nan,nan,0,-1,-1,-1
5331,NIPS_2020_790,"- While the theoretical bounds are nice, no algorithmic results for efficiently estimating the CRS model is given. I suppose that this all relies directly on the machinery developed for CDM in [48]. - I also find the utilization of the page limit very suboptimal. Main discussions such as those about the discrepancy of the optimization should not appear in the Appendix. - One important limitation is that the theorems provide guarantees only for datasets of *full* rankings. In many practical scenarios, the data would consist of partial rankings over (many small) subsets of items. Similar guarantees for this case would be very helpful, and would strengthen the contribution. - Given the parameter scaling of the model (quadratic in the number of items) it might not be easily applicable in practice. In fact I find the simulation results confusing. It is not clear why CRS has such nonlinear performance. I do not find the explanation on line 522-527 satisfactory.",- I also find the utilization of the page limit very suboptimal. Main discussions such as those about the discrepancy of the optimization should not appear in the Appendix.,nan,nan,nan,nan,nan,1,-1,-1,1
2829,NIPS_2022_158,"Weakness
Not sure what the main take away is. The goal appears to be to understand the neural encoding in the retina, but after that the analysis and results, there is no attempt to tie these back to neurobiological mechanisms. It seems one could, but the paper just ends with the statement, ""our results are in strong agreement with observed retinal data,"" which leaves you hanging.
Specific issues:
The difference of Gaussians model in eq. 8: it mentions that the center position of each kernel is different for each neuron, but is this also learned? not mentioned.
Section 3: linear model in the continuum limit - this is very unclear. what is being continuized? space? The integral is over frequency space - not following what's going on. principal vectors a_1, a_2 and reciprocal vectors b_1, b_2 - what are these?
Section 4.1: "" power spectral density can be well approximated by a product of spatial and temporal power-law densities"" - Dong & Atick is cited, but curiously the claim the exact opposite, it is not separable.
Figure 4, panel A shows striking clustering in temporal spectral centroids - they are all stacked neatly in tight columns, no scatter. is this what emerges from the learned filters, or is somehow the quantization imposed?
The mosaics are interesting to look at, but not clear what to take away from this.
Overall this seems like a very promising direction, I want to like this paper, but I find it a bit confusing and lacking a clear message.","8: it mentions that the center position of each kernel is different for each neuron, but is this also learned? not mentioned. Section 3: linear model in the continuum limit - this is very unclear. what is being continuized? space? The integral is over frequency space - not following what's going on. principal vectors a_1, a_2 and reciprocal vectors b_1, b_2 - what are these? Section 4.1: "" power spectral density can be well approximated by a product of spatial and temporal power-law densities"" - Dong & Atick is cited, but curiously the claim the exact opposite, it is not separable. Figure 4, panel A shows striking clustering in temporal spectral centroids - they are all stacked neatly in tight columns, no scatter. is this what emerges from the learned filters, or is somehow the quantization imposed? The mosaics are interesting to look at, but not clear what to take away from this. Overall this seems like a very promising direction, I want to like this paper, but I find it a bit confusing and lacking a clear message.",nan,nan,nan,nan,nan,-1,0,-1,-1
4787,NIPS_2020_611,"I think this paper would benefit from a more comprehensive connection to existing ideas in the field of biologically-plausible learning. Specifically: 1. There is a body of literature on biologically plausible methods for training feedforward ANNs with labels, see [R1] and [R2] for example. 2. Biologically-plausible learning rules that do not require label information have been studied in [R3] for shallow networks, and in [R4] for training multiple hidden layers of representations. The latter work, although targeting similarity search as a downstream task and not classification, also extensively uses divisive normalization for images. Similarly to this work, this seems to be important for achieving high accuracy (precision). 3. The empirical evaluations (Table 1) need to be compared with previously published results in the biologically-plausible settings. For instance, [R3] reports accuracy on fully connected network for MNIST better than 98.5%. Refs [1,3] report slightly better than 50% accuracy for fully connected architectures on CIFAR-10. Refs: R1. https://arxiv.org/abs/1412.7525 R2. https://www.frontiersin.org/articles/10.3389/fncom.2017.00024/full R3. https://www.pnas.org/content/116/16/7723 R4. https://arxiv.org/abs/2001.04907","2. Biologically-plausible learning rules that do not require label information have been studied in [R3] for shallow networks, and in [R4] for training multiple hidden layers of representations. The latter work, although targeting similarity search as a downstream task and not classification, also extensively uses divisive normalization for images. Similarly to this work, this seems to be important for achieving high accuracy (precision).",nan,nan,nan,nan,nan,0,0,1,1
3649,NIPS_2020_791,There are several issues here which I would like the authors to address: * Could the authors comment on the use percentile rank? I understand the reasoning behind it more or less but this is not explained in the paper at all. * What is the relationship between the CDF and percentile rank in this case? is there a way to express one with the other? * The experiments show that in a controlled setting (where a clear target patch and template patch are defined) it is possible to explain several illusions. One thing which is common to all the illusions is that the target patch is flat - what about cases where the patch to explain may have some structure? like the Kanitze triangle? this would make a much more convincing case for the method. * The authors show that the percentile rank correlates with the perceived *relative* lightness (for example) but they do not show if this is actually at the same scale of perception - do subjects report the same change in lightness perception? (I'm sure these numbers can be found in literature). * Only one generative model is tested here - do results change with other models? say a simple GMM or a sparse coding based one?,* Could the authors comment on the use percentile rank? I understand the reasoning behind it more or less but this is not explained in the paper at all.,nan,nan,nan,nan,nan,1,1,0,-1
1812,ARR_2022_174_review,"1. Authors could have investigated Vrank predictions, towards understanding where the model makes mistakes. Assuming that Vrank would be adopted to evaluate VIST models, it is crucial to know its limitations. Additionally, this could serve as guidance to collect extra annotations to mitigate those mistakes. 2. Vrank does not account for the actual images. This is somehow reflected in the correlation results of Vrank for Obj and Event error types. This seems to be a weakness of the proposed approach since by definition, it is trying to imitate human judgment, but without access to the same information that annotators had to decide. In the Appendix, ""Model Design"" section, authors state that tried vision and language models but do not provide details. What was actually tried? Did it improve in detecting Obj and Event error types?
3. Given the insights gathered by the authors, I would expect a critical discussion regarding the inclusion of Vrank in VIST evaluation protocols. Namely, provided that Vrank also has error, the best possible automatic protocol would include only Vrank or be complemented with other metrics? 
In overall, the paper is well written, but there are some minor typos so I would suggest proofreading the manuscript. Some of the typos/grammar issues found: - Line 130-131: check grammar - Line 248: ""... and is ..."" - Line 400-401: check grammar - Line 426: ""autometric"" - Line 556-557: check grammar ","- Line 130-131: check grammar - Line 248: ""... and is ..."" - Line 400-401: check grammar - Line 426: ""autometric"" - Line 556-557: check grammar",nan,nan,nan,nan,nan,0,0,0,1
4575,NIPS_2020_1719,"Just 3 concerns: 1. Equation 11 is expressed without the regularization terms ... and it is stated that extending it with the same is straightforward. Is that really so? It is not really that straightforward when projecting. SO authors must expand on this a bit. 2. Justification provided for not comparing against Pareto-frontier search methods is very loose and ambiguous. and not convincing in anyway. Authors should expand on this more. 3. This agnostic formulation in this case is related with solving a minmax problem ... in ""robust MDPs"" or even in adversarial games.... Authors should make an attempt to discuss the same. Finally, while the evaluations are acceptable they definitely have room for improvement, at least in the way the results are discussed. -- that is sub-par. Ideally the authors must define evaluation goals as in what is measured and for what reason.. what is it that they are trying to show. Then when discussed the tables/plots connect the discussion back to the goals.",2. Justification provided for not comparing against Pareto-frontier search methods is very loose and ambiguous. and not convincing in anyway. Authors should expand on this more.,nan,nan,nan,nan,nan,-1,-1,-1,-1
3471,NIPS_2020_679,"he main weaknesses of the paper are: * the lack of comparisons to other model-based exploration approaches to disentangle the impact of the model-based aspect vs the novelty measure on performance. * the lack of empirical comparisons and discussion of ICM (Pathak et al., 2017) and RND (Burda, 2018). * the lack of statistical tests to support empirical comparisons. * the lack of an ablative study with respect to the 6 different losses used by the proposed approach.","* the lack of empirical comparisons and discussion of ICM (Pathak et al., 2017) and RND (Burda, 2018).",nan,nan,nan,nan,nan,-1,0,1,-1
5616,NIPS_2018_232,"weaknesses - Strengths: the paper is well-written and well-organized. It clearly positions the main idea and proposed approach related to existing work and experimentally demonstrates the effectiveness of the proposed approach in comparison with the state-of-the-art. - Weaknesses: the research method is not very clearly described in the paper or in the abstract. The paper lacks a clear assessment of the validity of the experimental approach, the analysis, and the conclusions. Quality - Your definition of interpretable (human simulatable) focuses on to what extent a human can perform and describe the model calculations. This definition does not take into account our ability to make inferences or predictions about something as an indicator of our understanding of or our ability to interpret that something. Yet, regarding your approach, you state that you are ânot trying to find causal structure in the data, but in the modelâs responseâ and that âwe can freely manipulate the input and observe how the model response changesâ. Is your chosen definition of interpretability too narrow for the proposed approach? Clarity - Overall, the writing is well-organized, clear, and concise. - The abstract does a good job explaining the proposed idea but lacks description of how the idea was evaluated and what was the outcome. Minor language issues p. 95: âfrom fromâ -> âfromâ p. 110: âto toâ -> âhow toâ p. 126: âas wayâ -> âas a wayâ p. 182 âcan sortedâ -> âcan be sortedâ p. 197: âon directly onâ -> âdirectly onâ p. 222: âwhere wantâ -> âwhere we wantâ p. 245: âas accurateâ -> âas accurate asâ Tab. 1: âsquareâ -> âsquared errorâ p. 323: âthis are featuresâ -> âthis is featuresâ Originality - the paper builds on recent work in IML and combines two separate lines of existing work; the work by Bloniarz et al. (2016) on supervised neighborhood selection for local linear modeling (denoted SILO) and the work by Kazemitabar et al. (2017) on feature selection (denoted DStump). The framing of the problem, combination of existing work, and empirical evaluation and analysis appear to be original contributions. Significance - the proposed method is compared to a suitable state-of-the-art IML approach (LIME) and outperforms it on seven out of eight data sets. - some concrete illustrations on how the proposed method makes explanations, from a user perspective, would likely make the paper more accessible for researchers and practitioners at the intersection between human-computer interaction and IML. You propose a âcausal metricâ and use it to demonstrate that your approach achieves âgood local explanationsâ but from a user or human perspective it might be difficult to get convinced about the interpretability in this way only. - the experiments conducted demonstrate that the proposed method is indeed effective with respect to both accuracy and interpretability, at least for a significant majority of the studied datasets. - the paper points out two interesting directions for future work, which are likely to seed future research.","- Weaknesses: the research method is not very clearly described in the paper or in the abstract. The paper lacks a clear assessment of the validity of the experimental approach, the analysis, and the conclusions. Quality - Your definition of interpretable (human simulatable) focuses on to what extent a human can perform and describe the model calculations. This definition does not take into account our ability to make inferences or predictions about something as an indicator of our understanding of or our ability to interpret that something. Yet, regarding your approach, you state that you are ânot trying to find causal structure in the data, but in the modelâs responseâ and that âwe can freely manipulate the input and observe how the model response changesâ. Is your chosen definition of interpretability too narrow for the proposed approach? Clarity - Overall, the writing is well-organized, clear, and concise.",nan,nan,nan,nan,nan,-1,1,-1,NO_LABEL
2396,NIPS_2021_311,"Weaknesses - The paper leaves some natural questions open (see questions below). - Line 170 mentions that the corpus residual can be used to detect an unsuitable corpus, but there are no experiments to support this.
After authors' response All the weakness points have been addressed by the authors' response. Consequently I have raised my score. In particular:
The left open questions have all been answered.
There indeed is an experiment to support this, thanks to the authors' for clarifying this, that connection was not clear to me previously.
Questions - Line 60: Why do you say that e.g. influence functions cannot be used to explain a prediction? The explanation of a prediction could be the training examples whose removal (as determined by the influence function) would lead to the largest score drop for a prediction. - How does the method scale as the corpus size or hidden dimension size is increased? - What happens if a too small corpus is chosen? Can this be detected? - What if we don’t know that a test example is crucially different, e.g. what if we don’t know that the patient of Figure 8 is “British” and we use the American corpus to explain it? Can this be detected with the corpus residual value? - In the supplementary material you mention how it is possible to check if a decomposition is unique. Do you do this in practice when conducting experiments? How do you choose a decomposition if it is not unique? What does it imply for the experiments (and the usage of the method in real-world applications) if the decomposition is not unique?
Typos, representation etc. - Line 50: An example of when a prototype model would be unsuitable would strengthen your argument. - Footnote 2: “or” -> “of” - Line 191: when the baseline is first introduced, [10] or other references would be helpful to support this approach - Line 319: “the the” -> “the” - Line 380: “at” -> “to”?
A broader impact section could be added. In a separate section (e.g. supplementary material), there could be an explicit discussion on when the method should not be used, e.g. as shown in Figure 8, the American corpus shouldn’t be used to explain the British patient. Also see last question above – what if we don’t know that the patient is British? Can this be detected? This should also be discussed in such a section.",- How does the method scale as the corpus size or hidden dimension size is increased?,nan,nan,nan,nan,nan,-1,0,-1,0
905,ICLR_2023_2312,"Weaknesses
1. Literature Review
The paper regrettably fails to acknowledge a vast body of related literature, on (i) intention-conditioned trajectory prediction, (ii) variational graph methods for trajectory prediction, and (iii) models that explicitly model social interactions for forecasting. At the very least, these references ought to be mentioned and discussed for a diligent representation of the research space, even if the methods are not directly compared against.
(i) Intention-Conditioned Trajectory Prediction:
[R1, R2, R3] talk about intention-conditioned trajectory prediction for autonomous vehicles. Apart from the data the methods are applied to, the architectures can be applicable to, and are relevant for, the problem being addressed here. Crucially, the DROGON paper defines intention explicitly (more on this in Weakness 2. below).
(ii) Variational Graph Methods:
[R4] from the Neurips I Can't Believe It's Not Better Workshop explicitly deals with graph conditional variational methods for multi-agent trajectory prediction. The results in that paper are very relevant for this research area and should be included.
(iii) Encoding Social Interactions:
Graph and other stochastic methods that encode social interactions between agents have been long applied to trajectory and behavior forecasating problems. [R5] explicitly incorporates a spatiotemporal graph for incorporating social interactions between agents. [R6] more recently explicitly takes a meta-learning approach for modeling the dynamics unique to a group for probabilistic forecasting. A sports team is a group, and if each team is viewed as having unique social dynamics resulting from the team's strategy then [R6]'s core modeling idea is directly applicable. The cue in [R6] terms is simply player location here. Their modeling of social influence of other agents is also permutation invariant, a limitation this paper claims about existing methods. References:
[R1] DROGON: A Trajectory Prediction Model based on Intention-Conditioned Behavior Reasoning - Choi et al.
[R2] Intention-Driven Trajectory Prediction for Autonomous Driving - Fan et al.
[R3] LOKI: Long Term and Key Intentions for Trajectory Prediction - Girase et al.
[R4] Graph Conditional Variational Models: Too Complex for Multiagent Trajectories? - Rudolph et al.
[R5] Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction - Mohamed et al.
[R6] Social Processes: Self-Supervised Meta-Learning over Conversational Groups for Forecasting Nonverbal Social Cues - Raman et al.
2. Unsupported claims and definitions
The paper doesn't actually define agent intentions and causality in the specific setting, so there is no reasonable way to evaluate whether the proposed method actually models intentions. The intention-conditioned trajectory works I've mentioned talk about intention over long- and short- time horizons, where e.g. the former is in terms of goal destinations. Here the paper is talking about team sports with player intentions but simply states that this results from communication. What does intention mean here? Also, the paper claims to model causal relationships, but I can't see any explicit causal factors modeled of learned in the graph structure. There might be other exogenous variables explaining trajectory behavior.
3. Notation
There are a few notational errors. For instance, the variable used for the sequence cannot be the same as the individual elements: x < t = [ x 1 , . . . ]
. See [R4] for this. In many places there exist grammatical errors and incomplete sentences. Please do a pass to fix these.",- Rudolph et al. [R5] Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction - Mohamed et al. [R6] Social Processes: Self-Supervised Meta-Learning over Conversational Groups for Forecasting Nonverbal Social Cues - Raman et al.,nan,nan,nan,nan,nan,0,0,-1,0
4011,NIPS_2020_182,"1. The utilization of the approximation in (10) is not properly validated. For example, the error between the approximation of the deep neural network and the original Mori-Zwanzig memory term is not evaluated. 2．In the section of numerical experiments, different baselines are compared in different tasks. However, choosing them in these tasks is not well justified. For example, InfluLearner is only compared in the task of Infection probability and influence function estimation. Obviously, by combining with the classical greedy algorithm, it can be compared in the task of Influence Maximization. Thus, why choosing these compared algorithms in different tasks needs more discussion. 3. Technical details in this paper is a bit hard to follow. It is better to given a neural network diagram or a pseudo-code algorithm to help readers between understand the details of the proposed framework. 4. In line 216, it is said that 1,000 source sets are generated. However, in line 224, MAE is only averaged over 100 source sets, which is contrary to previous description. 5. There are many typos in this paper, e.g., - Line 40: “and and reture” - Line 127 and Line 142: “Appendix ??”","4. In line 216, it is said that 1,000 source sets are generated. However, in line 224, MAE is only averaged over 100 source sets, which is contrary to previous description.",nan,nan,nan,nan,nan,-1,1,1,1
475,ICLR_2022_3205,"Weaknesses
This method trades one intractible problem for another: it requires the learning of cross-values v e ′ ( x t ; e )
for all pairs of possible environments e , e ′
. It is not clear that this will be an improvement when scaling up.
At a few points the paper introduces approximations, but the gap to the true value and the implications of these approximations are not made completely clear to me. The authors should be more precise about the tradeoffs and costs of the methods they propose, both in terms of accuracy and computational cost.
On page 6, it claims that estimating v c
according to samples will lead to Thompson sampling-like behavior, which might lead to better exploration. This seems a bit facetious given that this paper attempts to find a Bayes-optimal policy and explicitly points out the weaknesses of Thompson sampling in an earlier section.
Not scaled to larger domains, but this is understandable.
Questions and minor comments
Is the belief state conditioning the policy also supposed to change with time τ
? As written it looks like the optimal Bayes-adaptive policy conditions on one sampled belief about the environment and then plays without updating that belief.
It is not intuitive to me how it is possible to estimate v f
, despite the Bellman equation written in Eq. 12. It would seem that this update would have to integrate over all possible environments in order to be meaningful, assuming that the true environment is not known at update time. Is that correct?
I guess this was probably for space reasons, but the bolded sections in page 6 should really be broken out into \paragraphs — it's currently a huge wall of text.","12. It would seem that this update would have to integrate over all possible environments in order to be meaningful, assuming that the true environment is not known at update time. Is that correct? I guess this was probably for space reasons, but the bolded sections in page 6 should really be broken out into \paragraphs — it's currently a huge wall of text.",nan,nan,nan,nan,nan,-1,1,-1,1
2606,NIPS_2019_1408,"Weaknesses: - The paper is not that original given the amount of work in learning multimodal generative models:   â For example, from the perspective of the model, the paper builds on top of the work by Wu and Goodman (2018) except that they learn a mixture of experts rather than a product of experts variational posterior.   â In addition, from the perspective of the 4 desirable attributes for multimodal learning that the authors mention in the introduction, it seems very similar to the motivation in the paper by Tsai et al. Learning Factorized Multimodal Representations, ICLR 2019, which also proposed a multimodal factorized deep generative model that performs well for discriminative and generative tasks as well as in the presence of missing modalities. The authors should have cited and compared with this paper. ****************************Quality**************************** Strengths: - The experimental results are nice. The paper claims that their MMVAE modal fulfills all four criteria including (1) latent variables that decompose into shared and private subspaces, (2) be able to generate data across all modalities, (3) be able to generate data across individual modalities, and (4) improve discriminative performance in each modality by leveraging related data from other modalities. Let's look at each of these 4 in detail:   â (1) Yes, their model does indeed learn factorized variables which can be shown by good conditional generation on MNIST+SVHN dataset.   â (2) Yes, joint generation (which I assume to mean generation from a single modality) is performed on vision -> vision and language -> language for CUB,   â (3) Yes, conditional generation can be performed on CUB via language -> vision and vice versa.  Weaknesses: - (continuing on whether the model does indeed achieve the 4 properties that the authors describe)   â (3 continued) However, it is unclear how significant the performance is for both 2) and 3) since the authors report no comparisons with existing generative models, even simple ones such as a conditional VAE from language to vision. In other words, what if I forgo with the complicated MoE VAE, and all the components of the proposed model, and simply use a conditional VAE from language to vision. There are many ablation studies that are missing from the paper especially since the model is so complicated.   â (4) The authors have not seemed to perform extensive experiments for this criteria since they only report the performance of a simple linear classifier on top of the latent variables. There has been much work in learning discriminative models for multimodal data involving aligning or fusing language and vision spaces. Just to name a few involving language and vision:     - Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding, EMNLP 2016     - DeViSE: A Deep Visual-Semantic Embedding Model, NeurIPS 2013 Therefore, it is important to justify why I should use this MMVAE model when there is a lot of existing work on fusing multimodal data for prediction. ****************************Clarity**************************** Strengths: - The paper is generally clear. I particularly liked the introduction of the paper especially motivation Figures 1 and 2. Figure 2 is particularly informative given what we know about multimodal data and multimodal information. - The table in Figure 2 nicely summarizes some of the existing works in multimodal learning and whether they fulfill the 4 criteria that the authors have pointed out to be important. Weaknesses: - Given the authors' great job in setting up the paper via Figure 1, Figure 2, and the introduction, I was rather disappointed that section 2 did not continue on this clear flow. To begin, a model diagram/schematic at the beginning of section 2 would have helped a lot. Ideally, such a model diagram could closely resemble Figure 2 where you have already set up a nice 'Venn Diagram' of multimodal information. Given this, your model basically assigns latent variables to each of the information overlapping spaces as well as arrows (neural network layers) as the inference and generation path from the variables to observed data. Showing such a detailed model diagram in an 'expanded' or 'more detailed' version of Figure 2 would be extremely helpful in understanding the notation (which there are a lot), how MMVAE accomplishes all 4 properties, as well as the inference and generation paths in MMVAE. - Unfortunately, the table in Figure 2 it is not super complete given the amount of work that has been done in latent factorization (e.g. Learning Factorized Multimodal Representations, ICLR 2019) and purely discriminative multimodal fusion (i.e. point d on synergy) - There are a few typos and stylistic issues: 1. line 18: ""Given the lack explicit labels availableâ -> âGiven the lack of explicit labels availableâ 2. line 19: âcan provided importantâ -> âcan provide importantâ 3. line 25: âbetween (Yildirim, 2014) themâ -> âbetween them (Yildirim, 2014)â 4. and so onâ¦ ****************************Significance**************************** Strengths: - This paper will likely be a nice addition to the current models we have for processing multimodal data, especially since the results are quite interesting. - The paper did a commendable job in attempting to perform experiments to justify the 4 properties they outlined in the introduction. - I can see future practitioners using the variational MoE layers for encoding multimodal data, especially when there is missing multimodal data. Weaknesses: - That being said, there are some important concerns especially regarding the utility of the model as compared to existing work. In particular, there are some statements in the model description where it would be nice to have some experimental results in order to convince the reader that this model compares favorably with existing work: 1. line 113: You set \alpha_m uniformly to be 1/M which implies that the contributions from all modalities are the same. However, works in multimodal fusion have shown that dynamically weighting the modalities is quite important because 1) modalities might contain noise or uncertain information, 2) different modalities contribute differently to the prediction (e.g. in a video when a speaker is not saying anything then their visual behaviors are more indicative than their speech or language behaviors). Recent works therefore study, for example, gated attentions (e.g. Gated-Attention Architectures for Task-Oriented Language Grounding, AAAI 2018 or Multimodal Sentiment Analysis with Word-level Fusion and Reinforcement Learning, ICMI 2017) to learn these weights. How does your model compare to this line of related work, and can your model be modified to take advantage of these fusion methods? 2. line 145-146: ""We prefer the IWAE objective over the standard ELBO objective not just for the fact that it estimates a tighter bound, but also for the properties of the posterior when computing the multi-sample estimate."" -> Do you have experimental results that back this up? How significant is the difference? 3. line 157-158: ""needing M^2 passes over the respective decoders in total"" -> Do you have experimental runtimes to show that this is not a significant overhead? The number of modalities is quite small (2 or 3), but when the decoders are large recurrent of deconvolutional layers then this could be costly. ****************************Post Rebuttal**************************** The author response addressed some of my concerns regarding novelty but I am still inclined to keep my score since I do not believe that the paper is substantially improving over (Wu and Goodmann, 2018) and (Tsai et al, 2019). The clarity of writing can be improved in some parts and I hope that the authors would make these changes. Regarding the quality of generation, it is definitely not close to SOTA language models such as GPT-2 but I would still give the authors credit since generation is not their main goal, but rather one of their 4 defined goals to measure the quality of multimodal representation learning.","- The paper is not that original given the amount of work in learning multimodal generative models: â For example, from the perspective of the model, the paper builds on top of the work by Wu and Goodman (2018) except that they learn a mixture of experts rather than a product of experts variational posterior. â In addition, from the perspective of the 4 desirable attributes for multimodal learning that the authors mention in the introduction, it seems very similar to the motivation in the paper by Tsai et al. Learning Factorized Multimodal Representations, ICLR 2019, which also proposed a multimodal factorized deep generative model that performs well for discriminative and generative tasks as well as in the presence of missing modalities. The authors should have cited and compared with this paper. ****************************Quality**************************** Strengths:",nan,nan,nan,nan,nan,-1,0,0,1
4349,NIPS_2020_1636,"While the general idea of the paper is appealing and has been evaluated extensively, the presentation of the methodology is lacking in clarity at times. After reading section 3, some issues could have been addressed more clearly: • Regarding line 171/172: what do the authors mean by “regret reaches the plateau”? Can this be quantified? • If the tree is constructed as described, it is questionable that the leftmost leave is actually the ‘best’ leave. Can this be shown? • How is the problem treated that SVM can lead to many distinct areas in the described methodology? Consider the case of the 1D sine function and we have data points only at increments of pi. K-means would result in two clusters, i.e., the points with values +1 and -1, respectively. Then, SVM would potentially cluster the domain in the two classes resulting in alternating regions for each class. What would be the resulting domain for TuRBO then? In the very beginning, the authors mention that only deterministic objective functions are considered. It is not clear how this statement fits to the the main result: the optimization of policies on the MuJoCo tasks which are known to be inherently stochastic objectives. Does LA-MCTS depend on the deterministic assumption? If yes: why does it work well in practice on stochastic functions, and if not: Why assume it then? The empirical performance of LA-MCTS is impressive. However, the method combines many different building blocks and as such introduces many additional hyperparameters. Though an ablation study was performed, the performance of the method depends drastically on the choice of hyperparameters. As such, the practicability of the approach is limited as an additional layer of parameters needs to be tuned in addition to the BO parameters. It is not exactly clear, why the authors call their method ‘latent actions’ as these are just the decision boundaries from the SVM classifier. No theoretical work is presented. ------------------------------ After reading the authors response: Thank you for the detailed response to the raised concerns as well as the additional experiments. Tree construction: Being the best node in expectation is something different then being the best node. This should be made more clear in the main paper. Further, Figure 10 does not really help to make this issue more clear as for example the evaluated points are missing in the plot. How's the initial purple region selected when no data is available? Also, using a contour-plot to visualize the objective function would help to understand the figure better. Deterministic assumption: if no component depends on being deterministic, than I'd highly recommend removing this from the main paper in the beginning. Also, just using a sample mean of 5 rollouts does not lead to a deterministic function but just reduces the variance by a factor of 5, which can still be relatively high for RL tasks especially as the outcome does not necessarily follow a uni-modal distribution. Also, please make the use of multiple rollouts more transparent as this simplifies the RL problem drastically. Minor: Appendix A.1: Hit-and-Run and Gibbs sampling do not require the region to be a convex polytope. Overall: The approach presented in this paper shows great potential but the quality of the paper is not yet at the level of a top-tier conference.","• How is the problem treated that SVM can lead to many distinct areas in the described methodology? Consider the case of the 1D sine function and we have data points only at increments of pi. K-means would result in two clusters, i.e., the points with values +1 and -1, respectively. Then, SVM would potentially cluster the domain in the two classes resulting in alternating regions for each class. What would be the resulting domain for TuRBO then? In the very beginning, the authors mention that only deterministic objective functions are considered. It is not clear how this statement fits to the the main result: the optimization of policies on the MuJoCo tasks which are known to be inherently stochastic objectives. Does LA-MCTS depend on the deterministic assumption? If yes: why does it work well in practice on stochastic functions, and if not: Why assume it then? The empirical performance of LA-MCTS is impressive. However, the method combines many different building blocks and as such introduces many additional hyperparameters. Though an ablation study was performed, the performance of the method depends drastically on the choice of hyperparameters. As such, the practicability of the approach is limited as an additional layer of parameters needs to be tuned in addition to the BO parameters. It is not exactly clear, why the authors call their method ‘latent actions’ as these are just the decision boundaries from the SVM classifier. No theoretical work is presented. ------------------------------ After reading the authors response: Thank you for the detailed response to the raised concerns as well as the additional experiments. Tree construction: Being the best node in expectation is something different then being the best node. This should be made more clear in the main paper. Further, Figure 10 does not really help to make this issue more clear as for example the evaluated points are missing in the plot. How's the initial purple region selected when no data is available? Also, using a contour-plot to visualize the objective function would help to understand the figure better. Deterministic assumption: if no component depends on being deterministic, than I'd highly recommend removing this from the main paper in the beginning. Also, just using a sample mean of 5 rollouts does not lead to a deterministic function but just reduces the variance by a factor of 5, which can still be relatively high for RL tasks especially as the outcome does not necessarily follow a uni-modal distribution. Also, please make the use of multiple rollouts more transparent as this simplifies the RL problem drastically. Minor: Appendix A.1: Hit-and-Run and Gibbs sampling do not require the region to be a convex polytope. Overall: The approach presented in this paper shows great potential but the quality of the paper is not yet at the level of a top-tier conference.",nan,nan,nan,nan,nan,NO_LABEL,1,NO_LABEL,1
4223,NIPS_2020_1003,"1. The study among different adversarially trained models is missing, thus the trade-off is unclear among robust trained models. For example, the TRADES model may improve both the robustness and back-door robustness. 2. Following the point above, it is unclear whether the trade-off still holds when the models that are partially adversarial robust. Since the results are present in two extreme without the middle results. For example, models with 10%,20%, 30% adversarial robustness accuracy. A curve with some reasonable resolution is needed to show the trade-off. 3. Experiment details missing. It is unclear to the reviewer whether the data for the adversarial training is poisoned or not. Would adversarial training still work under poison data? Would that mean successful backdoor attack (weak back-door robustness) also reduce the adversarial robustness? Maybe a figure showing the trade-off under this setting is missing. 4. Too few steps of attack for adversairal attack (only 5 to 10 steps), it is may not access the true adversarial robustness.",3. Experiment details missing. It is unclear to the reviewer whether the data for the adversarial training is poisoned or not. Would adversarial training still work under poison data? Would that mean successful backdoor attack (weak back-door robustness) also reduce the adversarial robustness? Maybe a figure showing the trade-off under this setting is missing.,nan,nan,nan,nan,nan,-1,-1,-1,1
4450,NIPS_2020_1451,"1. Unlike the works HaoChen and Sra and Nagaraj et.al, this work uses the fact that all component functions f_i are mu strongly convex. 2. The authors need to explain why removing some of the assumptions like bounded variance and bounded gradients is an important contribution via. solid examples. 3. The quantity sigma^{*} being finite also implies that all the gradients are finite via. smoothness property of the functions f_i and gives a natural upper bound.",3. The quantity sigma^{*} being finite also implies that all the gradients are finite via. smoothness property of the functions f_i and gives a natural upper bound.,nan,nan,nan,nan,nan,0,0,-1,-1
5331,NIPS_2020_790,"- While the theoretical bounds are nice, no algorithmic results for efficiently estimating the CRS model is given. I suppose that this all relies directly on the machinery developed for CDM in [48]. - I also find the utilization of the page limit very suboptimal. Main discussions such as those about the discrepancy of the optimization should not appear in the Appendix. - One important limitation is that the theorems provide guarantees only for datasets of *full* rankings. In many practical scenarios, the data would consist of partial rankings over (many small) subsets of items. Similar guarantees for this case would be very helpful, and would strengthen the contribution. - Given the parameter scaling of the model (quadratic in the number of items) it might not be easily applicable in practice. In fact I find the simulation results confusing. It is not clear why CRS has such nonlinear performance. I do not find the explanation on line 522-527 satisfactory.","- One important limitation is that the theorems provide guarantees only for datasets of *full* rankings. In many practical scenarios, the data would consist of partial rankings over (many small) subsets of items. Similar guarantees for this case would be very helpful, and would strengthen the contribution.",nan,nan,nan,nan,nan,1,1,-1,1
811,ICLR_2021_1181,"Weaknesses
1.For domain adaptation in the NLP field, powerful pre-trained language models, e.g., BERT, XLNet, can overcome the domain-shift problem to some extent. Thus, the authors should be used as the base encoder for all methods and then compare the efficacy of the transfer parts instead of the simplest n-gram features.
2.The whole procedure is slightly complex. The author formulates the prototypical distribution as a GMM, which has high algorithm complexity. However, formal complexity analysis is absent. The author should provide an analysis of the time complexity and training time of the proposed SAUM method compared with other baselines. Besides, a statistically significant test is absent for performance improvements.
3.The motivation of learning a large margin between different classes is exactly discriminative learning, which is not novel when combined with domain adaptation methods and already proposed in the existing literature, e.g., Unified Deep Supervised Domain Adaptation and Generalization, Saeid et al., ICCV 2017. Contrastive Adaptation Network for Unsupervised Domain Adaptation, Kang et al., CVPR 2019 Joint Domain Alignment and Discriminative Feature Learning for Unsupervised Deep Domain Adaptation, Chen et al., AAAI 2019.
However, this paper lacks detailed discussions and comparisons with existing discriminative feature learning methods for domain adaptation.
4.The unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced, which is impractical in real-world applications. Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.
5.The paper lacks some related work about cross-domain sentiment analysis, e.g., End-to-end adversarial memory network for cross-domain sentiment classification, Li et al., IJCAI 2017 Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018 Hierarchical attention transfer network for cross-domain sentiment classification, Li et al., AAAI 18 Questions:
1.Have the authors conducted the significance tests for the improvements?
2.How fast does this algorithm run or train compared with other baselines?",2.How fast does this algorithm run or train compared with other baselines?,nan,nan,nan,nan,nan,-1,0,0,0
275,ICLR_2022_1955,"weaknesses ablation of representation is missing: It could be argued that the most gains are from the new GNN architecture. It could be instructive to try out the same model with the same architecture that G2G, GLN, or NeuralSym uses. Or maybe with DRGAT, G2G, GLN, or NeuralSym would also perform better?
baselines is missing: I would suggest to add
Sacha et al - MEGAN model https://arxiv.org/abs/2006.15426
Sun et al https://arxiv.org/abs/2007.13437
Seidl et al https://arxiv.org/abs/2104.03279 to the results table, which outperforms SemiRetro in top10 accuracy.
notes: In the introduction, the authors write: Fortunately, with the rapid accumulation of chemical data, machine learning is promising to solve this problem (Szymkuc et al., 2016; Coley et al., 2018; Segler et al., 2018). - However, Szymkuc et al 2016 argue against the use of data-driven approaches, so I would suggest to not to cite them in this context.","- However, Szymkuc et al 2016 argue against the use of data-driven approaches, so I would suggest to not to cite them in this context.",nan,nan,nan,nan,nan,1,-1,1,1
2316,ACL_2017_216_review.json,"Weaknesses: 1. Compared to Balikas COLING16's work, the paper has a weaker visualization (Fig 5), which makes us doubt about the actual segmenting and assigning results of document. It could be more convincing to give a longer exemplar and make color assignment consistent with topics listed in Figure 4. 
2. Since the model is more flexible than that of Balikas COLING16, it may be underfitting, could you please explain this more?
- General Discussion: The paper is well written and structured. The intuition introduced in the Abstract and again exemplified in the Introduction is quite convincing. The experiments are of a full range, solid, and achieves better quantitative results against previous works. If the visualization part is stronger, or explained why less powerful visualization, it will be more confident. Another concern is about computation efficiency, since the seminal LDA work proposed to use Variational Inference which is faster during training compared to MCMC, we wish to see the author’s future development. ","2. Since the model is more flexible than that of Balikas COLING16, it may be underfitting, could you please explain this more?",nan,nan,nan,nan,nan,-1,1,-1,-1
2396,NIPS_2021_311,"Weaknesses - The paper leaves some natural questions open (see questions below). - Line 170 mentions that the corpus residual can be used to detect an unsuitable corpus, but there are no experiments to support this.
After authors' response All the weakness points have been addressed by the authors' response. Consequently I have raised my score. In particular:
The left open questions have all been answered.
There indeed is an experiment to support this, thanks to the authors' for clarifying this, that connection was not clear to me previously.
Questions - Line 60: Why do you say that e.g. influence functions cannot be used to explain a prediction? The explanation of a prediction could be the training examples whose removal (as determined by the influence function) would lead to the largest score drop for a prediction. - How does the method scale as the corpus size or hidden dimension size is increased? - What happens if a too small corpus is chosen? Can this be detected? - What if we don’t know that a test example is crucially different, e.g. what if we don’t know that the patient of Figure 8 is “British” and we use the American corpus to explain it? Can this be detected with the corpus residual value? - In the supplementary material you mention how it is possible to check if a decomposition is unique. Do you do this in practice when conducting experiments? How do you choose a decomposition if it is not unique? What does it imply for the experiments (and the usage of the method in real-world applications) if the decomposition is not unique?
Typos, representation etc. - Line 50: An example of when a prototype model would be unsuitable would strengthen your argument. - Footnote 2: “or” -> “of” - Line 191: when the baseline is first introduced, [10] or other references would be helpful to support this approach - Line 319: “the the” -> “the” - Line 380: “at” -> “to”?
A broader impact section could be added. In a separate section (e.g. supplementary material), there could be an explicit discussion on when the method should not be used, e.g. as shown in Figure 8, the American corpus shouldn’t be used to explain the British patient. Also see last question above – what if we don’t know that the patient is British? Can this be detected? This should also be discussed in such a section.",- What happens if a too small corpus is chosen? Can this be detected?,nan,nan,nan,nan,nan,-1,1,-1,0
5529,NIPS_2020_1796,"While the result is interesting, many of the design decisions behind the models and training procedures seemed poorly motivated and discussion on their nuances lacking. - Why represent the rewards as a function of a VAE used to encode exploratory frames in the environment? How does more or less exploration impact the effect of the auxiliary rewards learned this way? - What is the impact of environment ordering during training? Are there any curriculum effects at play? Why train with such a curriculum in the first place? An ablation demonstrating the necessity of this approach would contextualize this decision. - The language stating ""the agent learns R_AUP"" was confusing (Line 138). The reviewer believes this language was meant to describe ""training the Q_i functions"" corresponding to each R_i. This confusing language was used in the caption for the reward learning curves in the supplementary materials, which seems supported by the statement starting on Line 202: ""In the supplementary material..."" - Some key concepts are not defined, for example ""initial state reachability"" (Line 42). - It seems the claim that safe reinforcement learning focuses on just avoiding negative side effects during training is inaccurate. As stated in the abstract of a paper the authors cite (García et al, 2015), safe RL is also concerned with safety at deployment. - The language is often unclear, e.g. Line 211: ""AUP stops moving entirely."" The reviewer believes this is referring to the AUP learning a policy in which the agent remains immobile. - The discussion around the theoretical results (3.2) does not add much insight to the experiments and results presented in the paper. - The contribution is not very novel, as it is simply applying AUP as presented in Turner et al, 2020 to another environment, with little to no modification. - Not clear why Lines 55-57 are included in the related work, as they do not seem particularly relevant to safe RL.","- The language stating ""the agent learns R_AUP"" was confusing (Line 138). The reviewer believes this language was meant to describe ""training the Q_i functions"" corresponding to each R_i. This confusing language was used in the caption for the reward learning curves in the supplementary materials, which seems supported by the statement starting on Line 202: ""In the supplementary material..."" - Some key concepts are not defined, for example ""initial state reachability"" (Line 42).",nan,nan,nan,nan,nan,-1,1,0,1
2582,NIPS_2019_933,"weaknesses: + I liked the simplicity of the solution to divide the problem into star graphs. The domination number introduced seems to be a natural quantity for this problem. +/- To my opinion, the setting seems somewhat contrived combining feedback graphs and switching costs. The application to policy regret with counterfactual however provides a convincing example that the analysis can be useful and inspire future work. +/- The main part of the paper is rather clear and well written. Yet, I found the proofs in the appendices sometimes a bit hard to follow with sequences of unexplained equations. I would suggest to had some details. - There is a gap between the lower bound and the upper-bound (\sqrt(\beta) instead of \beta^{1/3}). In particular, for some graphs, the existing bound with the independence number may be better. This is also true for the results on the adaptive adversary and the counterfactual feedback. Other remarks: - Was the domination number already introduced for feedback graphs without switching costs? If yes, existing results for this problem should be cited. If not, it would be interesting to state what kind of results your analysis would provide without using the mini-batches. - Note that the length of the mini-batches tau_t may be non-integers. This should be clarified to be sure there are no side effects. For instance, what happens if $\tau_t << 1$? I am not sure if the analysis is still valid. - A better (more formal) definition of the independence and the domination numbers should be provided. It took me some time to understand their meaning. - Alg 1 and Thm 3.1: Since only upper-bounds on the pseudo-regret are provided, the exploration parameter gamma seems to be useless, isn't it? The choice gamma=0 seems to be optimal. A remark on high-probability upper-bounds and the role of gamma might be interesting. In particular, do you think your analysis (which is heavily based on expectations) can be extended to high-probability bounds on the regret? - I understand that this does not suit the analysis (which uses the equivalence in expectation btw Alg1 and Alg6) but it seems to be suboptimal (at least in practice) to discard all the feedbacks obtained while playing non-revealing actions. It would be nice to have practical experiments to understand better if we lose something here. It would be also nice to compare it with existing algorithms.  Typos: - p2, l86: too many )) - Thm 3.1: A constant 2 in the number of switches is missing. - p13, l457: some notations seem to be undefined (w_t, W_t). - p14, you may add a remark - p15, l458: the number of switches can be upper-bounded by **twice** the number of times the revealing action is played - p16, l514: I did not understand why Thm 3.1 implies the condition of Thm C.5 with alpha=1/2 and not 1. By the way, (rho_t) should be non-decreasing for this condition to hold. ",- A better (more formal) definition of the independence and the domination numbers should be provided. It took me some time to understand their meaning.,nan,nan,nan,nan,nan,1,1,-1,-1
2055,ARR_2022_17_review,"- If the 5 new tasks are indeed assessing different properties than the 10 superb tasks do, they are not all well justified. AST is tested on only one couple of language (EN->De) while OODASR on 3 (+spontaneous). Regarding SE and SS, given that SSL models are trained only on clean read speech it is not properly justified why such tasks are relevant. - The 5 tasks are indeed an interesting addition to SUPERB but : AST is not new since it has already been used in SSL benchmarks (cf. LeBenchmark). A more realistic OODASR would arguably be out-of-domain data (cf. Hsu et al 2021) rather than out of language data for which XLSR and XLS-R are far more adequate. Finally, the SE and SS tasks are difficult to justify and probably far less relevant for an ACL venue than more speech oriented events.  - Such contribution is really useful to assess to which extent models can improve downstream tasks but it does not reveal why they do it. At the end we don't learn much about the models. - Finally, it is rare that models are used without fine-tuning so it is unclear why such fine-tuning was not considered in the study (adaptability is not an interesting feature?) 
Most of my comments are given above. Details : some references have no venue -> please correct this.   misc{hsu2021robust,    title={Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training},    author={Wei-Ning Hsu and Anuroop Sriram and Alexei Baevski and Tatiana Likhomanenko and Qiantong Xu and Vineel Pratap and Jacob Kahn and Ann Lee and Ronan Collobert and Gabriel Synnaeve and Michael Auli},    year={2021},    eprint={2104.01027},    archivePrefix={arXiv},    primaryClass={cs. SD} } ","- Finally, it is rare that models are used without fine-tuning so it is unclear why such fine-tuning was not considered in the study (adaptability is not an interesting feature?) Most of my comments are given above. Details : some references have no venue -> please correct this. misc{hsu2021robust, title={Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training}, author={Wei-Ning Hsu and Anuroop Sriram and Alexei Baevski and Tatiana Likhomanenko and Qiantong Xu and Vineel Pratap and Jacob Kahn and Ann Lee and Ronan Collobert and Gabriel Synnaeve and Michael Auli}, year={2021}, eprint={2104.01027}, archivePrefix={arXiv}, primaryClass={cs. SD} }",nan,nan,nan,nan,nan,-1,-1,-1,-1
4011,NIPS_2020_182,"1. The utilization of the approximation in (10) is not properly validated. For example, the error between the approximation of the deep neural network and the original Mori-Zwanzig memory term is not evaluated. 2．In the section of numerical experiments, different baselines are compared in different tasks. However, choosing them in these tasks is not well justified. For example, InfluLearner is only compared in the task of Infection probability and influence function estimation. Obviously, by combining with the classical greedy algorithm, it can be compared in the task of Influence Maximization. Thus, why choosing these compared algorithms in different tasks needs more discussion. 3. Technical details in this paper is a bit hard to follow. It is better to given a neural network diagram or a pseudo-code algorithm to help readers between understand the details of the proposed framework. 4. In line 216, it is said that 1,000 source sets are generated. However, in line 224, MAE is only averaged over 100 source sets, which is contrary to previous description. 5. There are many typos in this paper, e.g., - Line 40: “and and reture” - Line 127 and Line 142: “Appendix ??”","1. The utilization of the approximation in (10) is not properly validated. For example, the error between the approximation of the deep neural network and the original Mori-Zwanzig memory term is not evaluated. 2．In the section of numerical experiments, different baselines are compared in different tasks. However, choosing them in these tasks is not well justified. For example, InfluLearner is only compared in the task of Infection probability and influence function estimation. Obviously, by combining with the classical greedy algorithm, it can be compared in the task of Influence Maximization. Thus, why choosing these compared algorithms in different tasks needs more discussion.",nan,nan,nan,nan,nan,1,0,-1,1
3644,NIPS_2020_1156,"- Other papers have done somewhat similar things, e.g. Duncker & Sahani (2018) have condition-dependent latents as well as single-trial latents. - The paper is somewhat light on experimental results, and the conclusions are somewhat abstract (on *average* there is less overlap between noise and sensory coding dimensions, but there seems to be substantial trial-to-trial variability) - I don't have any other major concerns besides the typical complications and drawbacks of Gaussian Processes. It would be useful to consider different choices for the GP kernel function. Also more discussion on how to choose parameters like the lengthscale of the kernel would be useful. (In the original GPFA paper the authors place a prior over the lengthscale... Is that done here or is the lengthscale a user-determined constant?)","- The paper is somewhat light on experimental results, and the conclusions are somewhat abstract (on *average* there is less overlap between noise and sensory coding dimensions, but there seems to be substantial trial-to-trial variability) - I don't have any other major concerns besides the typical complications and drawbacks of Gaussian Processes. It would be useful to consider different choices for the GP kernel function. Also more discussion on how to choose parameters like the lengthscale of the kernel would be useful. (In the original GPFA paper the authors place a prior over the lengthscale... Is that done here or is the lengthscale a user-determined constant?)",nan,nan,nan,nan,nan,1,1,-1,-1
1455,ICLR_2023_4735,"Weaknesses: 1) The contribution of this paper is to exploit the knowledge from the multiple pretrained deep models for VQA, while the practical method is doubtful. First, I am wondering why there are different pretrained models for different datasets. It is better to have a deeper analysis or insight into the fusion mechanism of various pretrained deep models. How the different pretrained models contribute to the quality-aware feature extraction is also valuable to be studied. 2) There are many pretrained models for various tasks, more pretrained models are encouraged to study for VQA. 3) I am still unclear about the motivation of intra-consistency and inter-divisibility loss related to quality assessment.","1) The contribution of this paper is to exploit the knowledge from the multiple pretrained deep models for VQA, while the practical method is doubtful. First, I am wondering why there are different pretrained models for different datasets. It is better to have a deeper analysis or insight into the fusion mechanism of various pretrained deep models. How the different pretrained models contribute to the quality-aware feature extraction is also valuable to be studied.",nan,nan,nan,nan,nan,-1,-1,-1,-1
429,ICLR_2022_1745,"Weaknesses Major
The authors have some fundamental issues and misconceptions about the BootstrappedDQN (BootDQN) algorithm. Section 2 mentions that BootDQN addresses exploration by running multiple behavior policies in the environment; if so, then it would be true that the method would have no reason to solve sparse reward tasks a priori as described by the authors. However, the reason for BootDQN's success in exploration is because of posterior sampling [8] and the fact that the ensemble is an approximate posterior over the optimal action-value function of the MDP, conditioned on all agent interactions observed thus far. It is precisely this principle that allows the algorithm to address sparse-reward tasks [2]. The authors' description of Thompson sampling in BootDQN as an ad-hoc heuristic seems incorrect given the rigorous theoretical guarantees that accompany randomized least-squares value-iteration algorithms [3]. The authors are also confused about the use of replay buffers in BootDQN, claiming that data from each head is held separate. There is exactly one replay buffer used in BootDQN and Bernoulli masks are sampled and stored with each transition for implementing the statistical bootstrap. Overall, the connection the authors draw with BootDQN in this work seem rather disingenuous; the proposed algorithm is simply applying ensembles of actor-critic pairs with no connection to the statistical bootstrap, unlike BootDQN. Renaming the algorithm and rephrasing the contribution seem appropriate.
A more critical issue concerning BootDQN and the proposed BHER algorithm is that the former is a purely value-based RL algorithm that maintains a posterior distribution over the optimal action-value function. In contrast, the latter is an off-policy actor-critic algorithm where, naturally, the critic is meant to be an estimate of the action-value function induced by the actor policy. While the empirical results of this paper confirm empirical benefits of this ensembling heuristic (the ablation in Figure 5 shows that this is responsible for most of the BHER performance), the authors have offered no real justification for this ensemble actor-critic algorithm. What is the point of representing epistemic uncertainty over the actor and critic in this manner?
I don't find the so-called counterintuitive prioritization to be counterintuitive at all. It seems natural that hindsight transitions will serve the agent well only when there is little uncertainty in the associated optimal behavior under the relabeled goal. Can the authors explain why sampling based on higher variance seems to still maintain reasonable performance in three of seven environments shown in Figure 5? Minor
In the first paragraph of Section 4.2, the authors describe an instance of Prioritized Experience Replay (PER) [6] where the variance of the critic ensemble is used to prioritize transitions sampled from the replay buffer. They seem to confuse this technique with methods for intrinsic motivation [7] based on curiosity and Random Network Distillation. Clarity Strengths
The authors provide ample details about their experimental setup for reproducibility of their results. Weaknesses Major
Overall, the paper is not well written. There are numerous grammatical errors throughout, genuinely too many for me to sensibly list them all out here. Oftentimes, these errors are missing articles (for example, ""it uses successful trajectories generated by agent as expert demonstrates"") or incorrect phrases (""on the contrast"", ""we inference all the Q-values""). Normally, I wouldn't bother nitpicking at a small handful of these, but there are too many throughout the entire body for what may end up being a published conference paper. Minor
The authors should remove the phrase ""importance sampling"" that is used twice in the paper to, in my reading, talk about the importance of sampled goals, rather than the Monte-Carlo technique of the same name. Originality Strengths
The authors demonstrate a good instinct in examining how other techniques used in deep reinforcement learning might further improve the efficacy of HER. Weaknesses Major
Fundamentally, this paper rests on the idea of using ensembles and prioritized experience replay together, neither of which is new to (deep) reinforcement learning [1,4,5,9]. Though I do not know of any prior work that has explored this specific combination, it would not surprise me if such prior work already exists.
More importantly, there are other options for leveraging such ensembles that have not been addressed in this work [1,4]. Similarly, the authors only consider variance-based prioritization schemes, rather than the traditional prioritization based on TD-error or any recent variants of PER. Demonstrating that the authors' specific choices in the proposed approach are better than these existing approaches to ensembling and PER would dramatically improve what so far seems to be a rather incremental algorithm. Minor
While it is appropriate for the related work section to focus on HER, it should also acknowledge the two fundamental innovations of this paper (ensembles and prioritization schemes) and provide an overview of related work for these areas as well. Significance Strengths
The only positive I can glean from this paper are the empirical results which seem to support the use of ensembling in actor-critic algorithms. Figure 5 shows a marginal drop in performance when the proposed counterintuitive prioritization scheme is not used. That said, it is not clear that this paper advances our understanding of ensembling in deep RL any more than prior work. Weaknesses Major
Given the lack of comparisons mentioned above, it's difficult to assess how impactful the proposed approach will be. With the breadth of existing work on the topic, I'm unconvinced that this will add any novel insights into how practitioners use ensemble methods in reinforcement learning. The prioritization scheme, while slightly interesting on the surface, doesn't seem to be a critical ingredient to the proposed algorithm's success based on the ablation studies shown.
I don't believe any of the experiments have shown results for regular DDPG without the use of HER. Having this baseline in place is important as it communicates the extent to which HER is even necessary for achieving a reasonable level of performance in each of the examined environments. Minor References
Lee, Kimin, Michael Laskin, Aravind Srinivas, and Pieter Abbeel. ""Sunrise: A simple unified framework for ensemble learning in deep reinforcement learning."" In International Conference on Machine Learning, pp. 6131-6141. PMLR, 2021.
Osband, Ian, and Benjamin Van Roy. ""Why is posterior sampling better than optimism for reinforcement learning?."" In International conference on machine learning, pp. 2701-2710. PMLR, 2017.
Osband, Ian, Benjamin Van Roy, Daniel J. Russo, and Zheng Wen. ""Deep Exploration via Randomized Value Functions."" J. Mach. Learn. Res. 20, no. 124 (2019): 1-62.
Peer, Oren, Chen Tessler, Nadav Merlis, and Ron Meir. ""Ensemble Bootstrapping for Q-Learning."" arXiv preprint arXiv:2103.00445 (2021).
Saphal, Rohan, Balaraman Ravindran, Dheevatsa Mudigere, Sasikant Avancha, and Bharat Kaul. ""SEERL: Sample Efficient Ensemble Reinforcement Learning."" In Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems, pp. 1100-1108. 2021.
Schaul, Tom, John Quan, Ioannis Antonoglou, and David Silver. ""Prioritized Experience Replay."" In ICLR, 2016.
Singh, Satinder, Richard L. Lewis, Andrew G. Barto, and Jonathan Sorg. ""Intrinsically motivated reinforcement learning: An evolutionary perspective."" IEEE Transactions on Autonomous Mental Development 2, no. 2 (2010): 70-82.
Strens, Malcolm. ""A Bayesian framework for reinforcement learning."" In ICML, vol. 2000, pp. 943-950. 2000.
Wiering, Marco A., and Hado Van Hasselt. ""Ensemble algorithms in reinforcement learning."" IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics) 38, no. 4 (2008): 930-936.","124 (2019): 1-62. Peer, Oren, Chen Tessler, Nadav Merlis, and Ron Meir. ""Ensemble Bootstrapping for Q-Learning."" arXiv preprint arXiv:2103.00445 (2021). Saphal, Rohan, Balaraman Ravindran, Dheevatsa Mudigere, Sasikant Avancha, and Bharat Kaul. ""SEERL: Sample Efficient Ensemble Reinforcement Learning."" In Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems, pp. 1100-1108. 2021. Schaul, Tom, John Quan, Ioannis Antonoglou, and David Silver. ""Prioritized Experience Replay."" In ICLR, 2016. Singh, Satinder, Richard L. Lewis, Andrew G. Barto, and Jonathan Sorg. ""Intrinsically motivated reinforcement learning: An evolutionary perspective."" IEEE Transactions on Autonomous Mental Development 2, no.",nan,nan,nan,nan,nan,0,0,0,-1
1944,ARR_2022_248_review,"It is a bit confusing about the word error rates in Fig. 3. The description in the paper use word error rate (WER) all the time. But in Fig. 3, the authors used (100 - WER) as the vertical axis. It is not clear about the motivation of doing this. Note: the WER can exceed 100% in some cases. 
Some grammar issues need to be reviewed. For example, at line 394 in section 4.2:      Like the baseline models Shon et al. (2021), we to train on the finer label set (18 entity tags) and evaluate on the com396 bined version (7 entity tags) -> ""we to ...."" ","3. The description in the paper use word error rate (WER) all the time. But in Fig. 3, the authors used (100 - WER) as the vertical axis. It is not clear about the motivation of doing this. Note: the WER can exceed 100% in some cases. Some grammar issues need to be reviewed. For example, at line 394 in section 4.2: Like the baseline models Shon et al. (2021), we to train on the finer label set (18 entity tags) and evaluate on the com396 bined version (7 entity tags) -> ""we to ....""",nan,nan,nan,nan,nan,0,1,-1,1
5339,NIPS_2020_1039,"1) It could be better if a more comprehensive comparison of the asymptotic performances among on/off-policy methods. Off policy methods enjoy better sample efficiency at the cost of higher computation burden. Maybe an additional table could be provided in the appendix. Personally, I don’t actually expect a gap between the on/off-policy methods. 2) Although the usage of current f-function in the f-divergence is justified, it will still be interesting to see a comparison if the alternative f-functions were adopted. An empirical comparison would further justify the usage of the author’s current choice. Minor: 1) In eq. 12 (the proof of Lemma 2), in the third from the last line, the integration should be over \mathcal{S} \times \mathcal{S} instead of \mathcal{S} \times \mathcal{A} \times \mathcal{S}. 2) Notations in sec. 8.6 are inconsistent: sampling from \pi is switching back and forth between $a \sim \pi(s)$ and $a \sim \pi(\cdot | s)$. 3) At the end of Algorithm box 1, does J_{\nabla \theta} J_{reg} (\pi_{\theta}) intends to mean that the gradient of \theta on J_{reg}? 4) Can the authors slightly justify the first equation in sec. 3.2? Why is that an equality instead of an inequality?",4) Can the authors slightly justify the first equation in sec. 3.2? Why is that an equality instead of an inequality?,nan,nan,nan,nan,nan,1,1,-1,1
352,ICLR_2022_2232,"Weaknesses
The writing should be improved overall. Issues throughout include grammar, misuse of commas, capitalization (as in reference to algorithm 1 on page 6), technical details left out, poor formatting.
There seems to be a lack of novelty in the modeling approach: the same training schemes, DNN model, etc have been developed before, in papers that are cited by this one.
The results are rather limited and do not seem to show a clear advantage over standard techniques.
Some sentences have unclear meaning, e.g.: Page 1 - ‘a manual adaptation and business knowledge are needed…” - ‘its dynamic dimension reflects directly the demand change over the learning steps…” Page 2 - ‘Before we deep dive in the model architecture and present its main components, we should briefly highlight some problem-related concepts’ - the narration is too casual Page 5 - Equation 13 label is cut off - means that violation is given -infinity in what sense? A large floating point number? Page 6 - Training: Sample rollout and greedy rollout - are these ever defined? What is the baseline function used in the REINFORCE algorithm? Page 7 - Google OR-Tools baseline - what are the details of the implementation? Is it the CP-Sat solver? A specialized solver? - What is the meaning of the numbers in Table 1? Is lower better? - Why does RNN-RL appear twice in Table 2 with different results? - Is OR-tools called with a solver timeout? Or it is allowed to run to completion? - The results for RNN-RL are very similar to OR-tools. Can you highlight what is thew advantage of your method?
General questions:
Because the solution is built incrementally, is it possible to take an action that leads to no further feasible actions? (Assuming that feasible solutions require every demand to be met - this isn’t made clear in the VRPTW description). This case is different from those in the remark on page 5 - what is done in this case?
Generally, does the masking scheme guarantee solutions to be feasible? Is this discussed in the paper?
What is the novelty of the approach? The network architecture, training scheme, masking, input representation, etc have all been studied before.",- Is OR-tools called with a solver timeout? Or it is allowed to run to completion?,nan,nan,nan,nan,nan,1,0,0,-1
3459,NIPS_2020_1464,"- significance and novelty: is quite similar to closely related work [13,14] (and maybe PathNet), but does not compare to them. -- The discussion says ""the major difference between [13,14] and ours is that they treat their network depends on the task, which might not be suitable for online continual learning setting."" So the only difference is that they may underperform. This paper either has to compare to [13,14] (especially [13] is very similar and open-source), or show numbers in efficiency (FLOPs, test time, etc) to show that they cannot be used efficiently. - claims and evaluation -- fairness of number of parameters: As far as I can tell, HAT has 7.1M params, A-GEM uses ResNet18 which is 11M params. This paper uses 43M params which is not fair. It is also not fair to say all methods have similar efficiency at test time, since multiple blocks in the same layer can be on. -- The exploration trick improved performance quite a lot. It is great that this paper did an ablation study, but since it has a lot of hyperparameters and design choices (why H^1/2 not H, why sigmoid, how are gamma/kappa/epsilon chosen), it is unclear how the design choices are made and how the hyperparameter was tuned, as this would tweak the balance between learning and remembering. An analysis of sensitivity to hyperparameters is preferred. -- The paper is not *entirely* an online method, since the model is pre-trained on the first task (with multiple epochs) to make NAS training work. --- Was line 253 epochs referring to this? Or did this paper train anything else with more than 1 epoch?","- claims and evaluation -- fairness of number of parameters: As far as I can tell, HAT has 7.1M params, A-GEM uses ResNet18 which is 11M params. This paper uses 43M params which is not fair. It is also not fair to say all methods have similar efficiency at test time, since multiple blocks in the same layer can be on. -- The exploration trick improved performance quite a lot. It is great that this paper did an ablation study, but since it has a lot of hyperparameters and design choices (why H^1/2 not H, why sigmoid, how are gamma/kappa/epsilon chosen), it is unclear how the design choices are made and how the hyperparameter was tuned, as this would tweak the balance between learning and remembering. An analysis of sensitivity to hyperparameters is preferred. -- The paper is not *entirely* an online method, since the model is pre-trained on the first task (with multiple epochs) to make NAS training work. --- Was line 253 epochs referring to this? Or did this paper train anything else with more than 1 epoch?",nan,nan,nan,nan,nan,-1,0,NO_LABEL,0
4223,NIPS_2020_1003,"1. The study among different adversarially trained models is missing, thus the trade-off is unclear among robust trained models. For example, the TRADES model may improve both the robustness and back-door robustness. 2. Following the point above, it is unclear whether the trade-off still holds when the models that are partially adversarial robust. Since the results are present in two extreme without the middle results. For example, models with 10%,20%, 30% adversarial robustness accuracy. A curve with some reasonable resolution is needed to show the trade-off. 3. Experiment details missing. It is unclear to the reviewer whether the data for the adversarial training is poisoned or not. Would adversarial training still work under poison data? Would that mean successful backdoor attack (weak back-door robustness) also reduce the adversarial robustness? Maybe a figure showing the trade-off under this setting is missing. 4. Too few steps of attack for adversairal attack (only 5 to 10 steps), it is may not access the true adversarial robustness.","2. Following the point above, it is unclear whether the trade-off still holds when the models that are partially adversarial robust. Since the results are present in two extreme without the middle results. For example, models with 10%,20%, 30% adversarial robustness accuracy. A curve with some reasonable resolution is needed to show the trade-off.",nan,nan,nan,nan,nan,1,1,-1,1
207,ICLR_2022_1625,"Weakness
--- The overall technical contribution is limited. The proposed contribution on loss designs is limited to the locomotion tasks, and it is not clear whether these losses would generalize to other robots and the real world [1, 2].
-- The use of the sine activation function is not well supported by the experiments. In table 1, sine function shows marginal improvement over tanh, and in table 5 of the appendix, using tanh shows much better performance over sine. Furthermore, tanh tends to become saturated during backpropagation of a long sequence. I would suggest the author also compares with ReLU.
-- Presentation in the paper can be improved:
The modified Adam optimizer is listed as one of the technical contributions. However, it is not stated clearly what is the modification and how does it compare to the original Adam optimizer.
The name of the robots are presented in Fig. 7 of Sec. 4.5 but are referenced multiple times in previous sections and table 1. It would be helpful to clarify the name of the agents early on.
Reference of Fig. 5 at the end of Sec. 4.2 seems to be incorrect, as no comparison of SGD and Adam is shown in Fig. 5.
[1] Lee, Joonho, et al. ""Learning quadrupedal locomotion over challenging terrain."" Science robotics 5.47 (2020). [2] Zhao, Allan, et al. ""RoboGrammar: graph grammar for terrain-optimized robot design."" ACM Transactions on Graphics (TOG) 39.6 (2020): 1-16.","5. [1] Lee, Joonho, et al. ""Learning quadrupedal locomotion over challenging terrain."" Science robotics 5.47 (2020). [2] Zhao, Allan, et al. ""RoboGrammar: graph grammar for terrain-optimized robot design."" ACM Transactions on Graphics (TOG) 39.6 (2020): 1-16.",nan,nan,nan,nan,nan,-1,0,0,0
1305,ICLR_2023_1603,"Weaknesses - 1. The main drawback of the design is that it relies heavily on a centrally available dataset. One of the two primary goals of the system is to handle non-IIDness in the data, which raises the question - how does the performance of F2L depend on the quality of the root dataset at the server. How well does the root dataset represent the non-IIDness present among the clients? How is scalability affected if the root dataset is not updated to well represent the newly joined clients? More experiments are required to convince the reader that the system can do well even when the root dataset does not exactly represent the data distribution among the clients. 2. Table 1 shows that F2L performs significantly better than Fed-Distill. The lower performance of the other benchmarks can be attributed to the fact that they do not leverage any information from a root dataset. What essentially leads to this improvement with respect to Fed-Distill? Do they both use the same root datasets? Is Fed-Distill well tuned for best performance? 3. Figure 2c shows the performance of F2L when a client is injected into the system midway during the training. F2L can be seen to perform better than vanilla FL. Can this be attributed to knowledge distillation? How would it compare with Fed-Distill? How sensitive are the observations with respect to the knowledge distillation parameters - lambda and temperature? 4. F2L relies on switching between LKD and FedAvg after sufficient convergence has happened. How is this threshold chosen? What can be a general way to choose this value for any dataset? 5. Figure 3 shows that a student can outperform a teacher in F2L. This experiment was performed on EMNIST. Does this observation hold in general, independent of the dataset? If not, what conditions does this depend on?",2. Table 1 shows that F2L performs significantly better than Fed-Distill. The lower performance of the other benchmarks can be attributed to the fact that they do not leverage any information from a root dataset. What essentially leads to this improvement with respect to Fed-Distill? Do they both use the same root datasets? Is Fed-Distill well tuned for best performance?,nan,nan,nan,nan,nan,1,0,-1,1
493,ICLR_2022_1823,"Weaknesses
The main weakness is that the relationship between ADU and constituency tree is not clearly described. Is it true that ADU are often phrases that occur in the constituency tree? How often does this happen? Does the new BERT-based model adhere to constituency constraints? Is the BENEPAR parser appropriate for this data? Based on Trautmann et al.’s comments on grammaticality and clauses, my intuition is that an ADU is almost always a phrase in the tree, in which case it is somewhat less surprising that it helps this task (and maybe it should be helping even more). If this is the case, it’s worth considering related work in distant supervision to include.
The treatment of constituency trees is haphazard. 1) At times it is not clear if dependency or constituency trees are being used; 2) Table 1 should be made more clear, what do the percentage values indicate, and why not use the full tree at all; 3) It is worth adding to the related work more work in constituency tree representation, such as but not limited to Yang and Deng 2020 that also use GNN to represent constituency tree.
(low priority) Some technical details are concerning as described. For example, it is true that batching heterogeneous graphs may be somewhat more challenging than batching similar length sequences, but it is hard to believe this is one of the “major difficulties” of this work. If it is such a challenge, then it may have warranted further discussion about tradeoffs in architecture selection and impact on speed or performance.",1) At times it is not clear if dependency or constituency trees are being used;,nan,nan,nan,nan,nan,-1,0,-1,-1
4008,NIPS_2020_404,"- What strikes me as surprising is the direct usage of the function f as the part embedding and point embedding. This needs further justifications, as ideally a BAE-like network should assign a hard per-part occupancy score of {0,1}. e.g. if the point coordinate belongs to the wing of an airplane, then the ideal f should output a one-hot vector. Clearly networks struggle in doing so, thus creating non binary outputs. However, this is more of a bug than a feature. Yet, the authors here exploit this approximation by making the network encode per-point subtleties into this approximated 1-hot. My intuition tells me this is not a principled way of doing it and perhaps a point embedding should be an intermediate prediction from which another few layers convert it into a part embedding? - The CR loss assumes all sampled points on the source have a corresponding point on the target. However, as explained by the authors, often part may appear and/or disappear. How is this being addressed? minor: line 109: a more detailed definition of f^-1 is recommended. In particular, it should be made explicit that f^-1 takes as input both the semantic embedding as well as the shape code and retrieves the coordinate. references: Probably relevant is this recent work that also uses implicit neural function to register between a partial and a full shape: ""The Whole Is Greater Than the Sum of Its Nonrigid Parts""","- The CR loss assumes all sampled points on the source have a corresponding point on the target. However, as explained by the authors, often part may appear and/or disappear. How is this being addressed? minor: line 109: a more detailed definition of f^-1 is recommended. In particular, it should be made explicit that f^-1 takes as input both the semantic embedding as well as the shape code and retrieves the coordinate. references: Probably relevant is this recent work that also uses implicit neural function to register between a partial and a full shape: ""The Whole Is Greater Than the Sum of Its Nonrigid Parts""",nan,nan,nan,nan,nan,1,1,-1,1
4072,NIPS_2020_1186,"Theoretical Grounding: - Since the regret bound relies on bounding the state reconstruction error at each point in a finite-length sequence, it seems clear to me that the bound only applies to MBRL algorithms that rely exclusively on full-episode rollouts for planning (e.g. PILCO). This criticism in particular seems to apply to the practical algorithm used in the submission, since it relies on a parametric value function approximator to make the planning horizon more tractable. - In practice we don't know \beta _a priori_. How should \beta be chosen? Empirical Evaluation: - The method is not evaluated in a stochastic environment. If you have set out to solve the issue of conflation of epistemic and aleatoric uncertainty, you should evaluate your method in a stochastic environment, not deterministic Mujoco environments. As it is the experiments give the impression of a bait-and-switch. - No comparison to competing methods only an ablation of the proposed exploration strategy with greedy improvement and approximate Thompson Sampling. - No ablations of β (presumably a crucial design choice). - No demonstration that their dynamics models as implemented satisfy their calibration assumption. Significance/Impact: - Information on the specific implementation details is fairly sparse (e.g. what learning rate and batch size did you use for your dynamics models? Did you reuse a previous implementation of MPO?). Reproducing the authors' findings would likely prove very difficult. MBRL is notorious in the machine learning field for reproducibility issues. If you (the authors) had to reimplement your method from scratch tomorrow, what details would you need?",- No ablations of β (presumably a crucial design choice).,nan,nan,nan,nan,nan,-1,0,-1,1
1231,ICLR_2023_3550,"Weaknesses
I am not entirely sure about the use of individual training accuracy gain as part of the metric, I think we should technically look at user-level accuracy, where we have at least a single sample held out test for a given training sample thereby measuring generalization accuracy gains. I think measuring the gain on training samples is a bit meaningless as technically the default accuracy on those samples could be 100% for that user, if we do like a KNN classifier.
The measurement of privacy expenditure is inconsistent, there should just be 4 privacy budget epsilons and all experiments done on those, as opposed to different epsilons and even different ways of reporting. Like for one method epsilon is reported,for another the standard deviation of the noise added is reported (which could be converted to epsilon and I think should be for presenting results). All this said, I find stacking all these inconsistent guarantees together like that in Figure 3 in appropriate.
I am not sure I fully understand the two lines of reasoning for why the naive definitions of IF are bad, in section 3.2: • A training algorithm is individually fair if users having similar data face similar privacy risks. This definition is inadequate because a difference in privacy risks can be large if users’ data are dissimilar --> I am not sure how this relates to the former sentence. Doesn't really make sense. • A training algorithm is individually fair if the difference in privacy risks between any pair of users is small. This definition can be satisfied by reducing privacy risks with privacy-preserving ML because the differences are small if all users’ privacy risks are small. However, strong privacy protection with DP is known to degrade classification performance --> There are two issues with this: a) the only way to get similar privacy risks is not by applying privacy preserving methods, there could be other ways out there, so to say that this is achieved by strong DP guarantees is a bit inaccurate, and b) there are recent papers that show DP can be achieved with little loss to accuracy [3-5]
I am not really sure what the conclusion “necessity of the proposed IF for NNs'' really means. If it means we need improvements, there are some group level improvements, why not try them and then test? Improvments like [1-2]. I think the fact that the only conclusion from the paper is that individual level fairness is not good in privacy preserving methods is a bit repetitive gien prior work.
[1] Tran, Cuong, Ferdinando Fioretto, and Pascal Van Hentenryck. ""Differentially private and fair deep learning: A lagrangian dual approach."" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 35. No. 11. 2021.
[2] Fioretto, Ferdinando, et al. ""Differential Privacy and Fairness in Decisions and Learning Tasks: A Survey."" arXiv preprint arXiv:2202.08187 (2022).
[3] Li X, Tramer F, Liang P, Hashimoto T. Large language models can be strong differentially private learners. arXiv preprint arXiv:2110.05679. 2021 Oct 12. (ICLR 2022)
[4] Yu D, Naik S, Backurs A, Gopi S, Inan HA, Kamath G, Kulkarni J, Lee YT, Manoel A, Wutschitz L, Yekhanin S. Differentially private fine-tuning of language models. arXiv preprint arXiv:2110.06500. 2021 Oct 13. (ICLR 2022)
[5] Tramer, Florian, and Dan Boneh. ""Differentially Private Learning Needs Better Features (or Much More Data)."" International Conference on Learning Representations. 2020.",• A training algorithm is individually fair if users having similar data face similar privacy risks. This definition is inadequate because a difference in privacy risks can be large if users’ data are dissimilar --> I am not sure how this relates to the former sentence. Doesn't really make sense.,nan,nan,nan,nan,nan,0,-1,-1,-1
2297,ACL_2017_71_review.json,"Weaknesses:  -The explanation of methods in some paragraphs is too detailed and there is no mention of other work and it is repeated in the corresponding method sections, the authors committed to address this issue in the final version. 
  -README file for the dataset [Authors committed to add README file] - General Discussion:  - Section 2.2 mentions examples of DBpedia properties that were used as features. Do the authors mean that all the properties have been used or there is a subset? If the latter please list them. In the authors' response, the authors explain in more details this point and I strongly believe that it is crucial to list all the features in details in the final version for clarity and replicability of the paper. 
  - In section 2.3 the authors use Lample et al. Bi-LSTM-CRF model, it might be beneficial to add that the input is word embeddings (similarly to Lample et al.)  - Figure 3, KNs in source language or in English? ( since the mentions have been translated to English). In the authors' response, the authors stated that they will correct the figure. 
  - Based on section 2.4 it seems that topical relatedness implies that some features are domain dependent. It would be helpful to see how much domain dependent features affect the performance. In the final version, the authors will add the performance results for the above mentioned features, as mentioned in their response. 
  - In related work, the authors make a strong connection to Sil and Florian work where they emphasize the supervised vs. unsupervised difference. The proposed approach is still supervised in the sense of training, however the generation of training data doesn’t involve human interference ","- Based on section 2.4 it seems that topical relatedness implies that some features are domain dependent. It would be helpful to see how much domain dependent features affect the performance. In the final version, the authors will add the performance results for the above mentioned features, as mentioned in their response.",nan,nan,nan,nan,nan,1,1,1,1
811,ICLR_2021_1181,"Weaknesses
1.For domain adaptation in the NLP field, powerful pre-trained language models, e.g., BERT, XLNet, can overcome the domain-shift problem to some extent. Thus, the authors should be used as the base encoder for all methods and then compare the efficacy of the transfer parts instead of the simplest n-gram features.
2.The whole procedure is slightly complex. The author formulates the prototypical distribution as a GMM, which has high algorithm complexity. However, formal complexity analysis is absent. The author should provide an analysis of the time complexity and training time of the proposed SAUM method compared with other baselines. Besides, a statistically significant test is absent for performance improvements.
3.The motivation of learning a large margin between different classes is exactly discriminative learning, which is not novel when combined with domain adaptation methods and already proposed in the existing literature, e.g., Unified Deep Supervised Domain Adaptation and Generalization, Saeid et al., ICCV 2017. Contrastive Adaptation Network for Unsupervised Domain Adaptation, Kang et al., CVPR 2019 Joint Domain Alignment and Discriminative Feature Learning for Unsupervised Deep Domain Adaptation, Chen et al., AAAI 2019.
However, this paper lacks detailed discussions and comparisons with existing discriminative feature learning methods for domain adaptation.
4.The unlabeled data (2000) from the preprocessed Amazon review dataset (Blitzer version) is perfectly balanced, which is impractical in real-world applications. Since we cannot control the label distribution of unlabeled data during training, the author should also use a more convinced setting as did in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018, which directly samples unlabeled data from millions of reviews.
5.The paper lacks some related work about cross-domain sentiment analysis, e.g., End-to-end adversarial memory network for cross-domain sentiment classification, Li et al., IJCAI 2017 Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification, He et al., EMNLP 2018 Hierarchical attention transfer network for cross-domain sentiment classification, Li et al., AAAI 18 Questions:
1.Have the authors conducted the significance tests for the improvements?
2.How fast does this algorithm run or train compared with other baselines?","2.The whole procedure is slightly complex. The author formulates the prototypical distribution as a GMM, which has high algorithm complexity. However, formal complexity analysis is absent. The author should provide an analysis of the time complexity and training time of the proposed SAUM method compared with other baselines. Besides, a statistically significant test is absent for performance improvements.",nan,nan,nan,nan,nan,1,1,-1,-1
