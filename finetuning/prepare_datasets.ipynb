{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>focused_review</th>\n",
       "      <th>review_point</th>\n",
       "      <th>id</th>\n",
       "      <th>chatgpt_verifiability_extraction_score</th>\n",
       "      <th>chatgpt_verifiability_extraction_rationale</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NIPS_2022_511</td>\n",
       "      <td>NIPS_2022</td>\n",
       "      <td>1.Some theorems could be better formatted in t...</td>\n",
       "      <td>2. It would be helpful if the authors could fu...</td>\n",
       "      <td>8281</td>\n",
       "      <td>yes</td>\n",
       "      <td>The comment suggests that the authors should f...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACL_2017_365_review</td>\n",
       "      <td>ACL_2017</td>\n",
       "      <td>1) Instead of arguing that the MTL approach re...</td>\n",
       "      <td>- the authors did not respond to my questions ...</td>\n",
       "      <td>354</td>\n",
       "      <td>yes</td>\n",
       "      <td>The comment suggests that the authors did not ...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>diKRhKs5yl</td>\n",
       "      <td>ICLR_2025</td>\n",
       "      <td>1. Lack of experiments with larger-scale model...</td>\n",
       "      <td>3. In the implementation of tree construction,...</td>\n",
       "      <td>11578</td>\n",
       "      <td>yes</td>\n",
       "      <td>The comment suggests that the implementation o...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tqHgSxRwiK</td>\n",
       "      <td>ICLR_2024</td>\n",
       "      <td>1. The premise and contribution of the paper i...</td>\n",
       "      <td>1. The premise and contribution of the paper i...</td>\n",
       "      <td>9274</td>\n",
       "      <td>yes</td>\n",
       "      <td>The review point expresses a lack of clarity r...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kBVPD2kJMy</td>\n",
       "      <td>ICLR_2025</td>\n",
       "      <td>Here are the weaknesses of this paper in my op...</td>\n",
       "      <td>2) Clarity and Accessibility: The paper is cha...</td>\n",
       "      <td>9647</td>\n",
       "      <td>yes</td>\n",
       "      <td>The review point contains claims about the cla...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>UmdotAAVDe</td>\n",
       "      <td>ICLR_2025</td>\n",
       "      <td>1. As we know LLM often hallucinates. How do t...</td>\n",
       "      <td>1. As we know LLM often hallucinates. How do t...</td>\n",
       "      <td>11453</td>\n",
       "      <td>X</td>\n",
       "      <td>The comment does not contain a claim, opinion,...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>rWIrdAo2xC</td>\n",
       "      <td>ICLR_2025</td>\n",
       "      <td>1. For GS dataset preparation, stage 1: per-sc...</td>\n",
       "      <td>4. The diffusion model design is very confusin...</td>\n",
       "      <td>9817</td>\n",
       "      <td>yes</td>\n",
       "      <td>The comment claims that \"the diffusion model d...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>JpyWPfzu0b</td>\n",
       "      <td>ICLR_2024</td>\n",
       "      <td>1) I strongly encourage authors to provide mor...</td>\n",
       "      <td>2) I understand the paper mainly focuses on a ...</td>\n",
       "      <td>11688</td>\n",
       "      <td>yes</td>\n",
       "      <td>The comment expresses an opinion and suggestio...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>ACL_2017_387_review</td>\n",
       "      <td>ACL_2017</td>\n",
       "      <td>(1) Replicability would be an important concer...</td>\n",
       "      <td>-General Discussion: Overall, this paper is we...</td>\n",
       "      <td>373</td>\n",
       "      <td>yes</td>\n",
       "      <td>The review point contains both positive feedba...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>ICLR_2023_892</td>\n",
       "      <td>ICLR_2023</td>\n",
       "      <td>I think it would have been nice to also compar...</td>\n",
       "      <td>2) You could have taken a pretrained systems f...</td>\n",
       "      <td>4020</td>\n",
       "      <td>yes</td>\n",
       "      <td>The review point suggests an alternative appro...</td>\n",
       "      <td>\\nThis aspect is aimed to maximize the utiliza...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                paper_id      venue  \\\n",
       "0          NIPS_2022_511  NIPS_2022   \n",
       "1    ACL_2017_365_review   ACL_2017   \n",
       "2             diKRhKs5yl  ICLR_2025   \n",
       "3             tqHgSxRwiK  ICLR_2024   \n",
       "4             kBVPD2kJMy  ICLR_2025   \n",
       "..                   ...        ...   \n",
       "995           UmdotAAVDe  ICLR_2025   \n",
       "996           rWIrdAo2xC  ICLR_2025   \n",
       "997           JpyWPfzu0b  ICLR_2024   \n",
       "998  ACL_2017_387_review   ACL_2017   \n",
       "999        ICLR_2023_892  ICLR_2023   \n",
       "\n",
       "                                        focused_review  \\\n",
       "0    1.Some theorems could be better formatted in t...   \n",
       "1    1) Instead of arguing that the MTL approach re...   \n",
       "2    1. Lack of experiments with larger-scale model...   \n",
       "3    1. The premise and contribution of the paper i...   \n",
       "4    Here are the weaknesses of this paper in my op...   \n",
       "..                                                 ...   \n",
       "995  1. As we know LLM often hallucinates. How do t...   \n",
       "996  1. For GS dataset preparation, stage 1: per-sc...   \n",
       "997  1) I strongly encourage authors to provide mor...   \n",
       "998  (1) Replicability would be an important concer...   \n",
       "999  I think it would have been nice to also compar...   \n",
       "\n",
       "                                          review_point     id  \\\n",
       "0    2. It would be helpful if the authors could fu...   8281   \n",
       "1    - the authors did not respond to my questions ...    354   \n",
       "2    3. In the implementation of tree construction,...  11578   \n",
       "3    1. The premise and contribution of the paper i...   9274   \n",
       "4    2) Clarity and Accessibility: The paper is cha...   9647   \n",
       "..                                                 ...    ...   \n",
       "995  1. As we know LLM often hallucinates. How do t...  11453   \n",
       "996  4. The diffusion model design is very confusin...   9817   \n",
       "997  2) I understand the paper mainly focuses on a ...  11688   \n",
       "998  -General Discussion: Overall, this paper is we...    373   \n",
       "999  2) You could have taken a pretrained systems f...   4020   \n",
       "\n",
       "    chatgpt_verifiability_extraction_score  \\\n",
       "0                                      yes   \n",
       "1                                      yes   \n",
       "2                                      yes   \n",
       "3                                      yes   \n",
       "4                                      yes   \n",
       "..                                     ...   \n",
       "995                                      X   \n",
       "996                                    yes   \n",
       "997                                    yes   \n",
       "998                                    yes   \n",
       "999                                    yes   \n",
       "\n",
       "            chatgpt_verifiability_extraction_rationale  \\\n",
       "0    The comment suggests that the authors should f...   \n",
       "1    The comment suggests that the authors did not ...   \n",
       "2    The comment suggests that the implementation o...   \n",
       "3    The review point expresses a lack of clarity r...   \n",
       "4    The review point contains claims about the cla...   \n",
       "..                                                 ...   \n",
       "995  The comment does not contain a claim, opinion,...   \n",
       "996  The comment claims that \"the diffusion model d...   \n",
       "997  The comment expresses an opinion and suggestio...   \n",
       "998  The review point contains both positive feedba...   \n",
       "999  The review point suggests an alternative appro...   \n",
       "\n",
       "                                                prompt  \n",
       "0    \\nThis aspect is aimed to maximize the utiliza...  \n",
       "1    \\nThis aspect is aimed to maximize the utiliza...  \n",
       "2    \\nThis aspect is aimed to maximize the utiliza...  \n",
       "3    \\nThis aspect is aimed to maximize the utiliza...  \n",
       "4    \\nThis aspect is aimed to maximize the utiliza...  \n",
       "..                                                 ...  \n",
       "995  \\nThis aspect is aimed to maximize the utiliza...  \n",
       "996  \\nThis aspect is aimed to maximize the utiliza...  \n",
       "997  \\nThis aspect is aimed to maximize the utiliza...  \n",
       "998  \\nThis aspect is aimed to maximize the utiliza...  \n",
       "999  \\nThis aspect is aimed to maximize the utiliza...  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "import utils\n",
    "aspects = [ 'actionability', 'grounding_specificity', 'verifiability', 'helpfulness']\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_excel('../chatgpt/outputs/main_data_batch_0_results.xlsx', sheet_name=None)\n",
    "\n",
    "## remove the verifiability_extraction sheet\n",
    "data.pop('verifiability_extraction')\n",
    "\n",
    "## Remove entries that has NA\n",
    "for key in data.keys():\n",
    "    data[key] = data[key].dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpfulness\n",
      "1000\n",
      "actionability\n",
      "1000\n",
      "grounding_specificity\n",
      "1000\n",
      "verifiability\n",
      "998\n"
     ]
    }
   ],
   "source": [
    "for key in data.keys():\n",
    "    print(key)\n",
    "    print(len(data[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293cb955fa0b4057846f52955980a8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d20497d7a1764a49893e0b68c3a174fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d03d44ae9f43bb8e79d5a9766594fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7615e003d2d4469882f47ad33e4db738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5af3c9e22344295bc51833a86124a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89e1cecee014b0596250c2765fe6b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82794bd9721b472fae9346e298563a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85da40388399477b92f13def81307e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41244594d5649ddb410a73e9109a604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd2e9778e394a8a9aa37362081a7222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153d6da5864e49fc9a3e3417d6d3af96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ff31f7d1a64a2ebf30db09cd346115",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12144e12e6ac468e9be5fe84f4389d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763afcbcdaab47a88d360b2cfe66325b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec74973e26c64bdbbd15746d42ab04f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46536cba03a45b98283bf8bb0d2abe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45523d62e5604dcdb51e5b58916d7c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b9eeea40a245a0b519bc28af7b7228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a279a6e5a234a47b73083849dcba140",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed63977c25914646b6f5c589fbbf26aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573b63c177f7404896fd399ea7357b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77cebe1b634400fb4d6bb551ceb6c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/736 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9310f99faf1a4e869b20912e2fa566d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/82 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b235eb4a730846d1bb2e4abe708529b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae6a97a2938438c9211c4e0a98670fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22495ad935324e009a92c0c3b19c25dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017b2909421040e1b7e18d1cc4d35893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63545131986149408dece391e9905bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### convert the df to dataset and store for each aspect\n",
    "for aspect in data.keys():\n",
    "    dataset = datasets.Dataset.from_pandas(data[aspect]).train_test_split(test_size=0.1)\n",
    "    ## add new column for the prompt do in sepratately for th train and test\n",
    "    \n",
    "    dataset['train'] = dataset['train'].map(lambda x: {'prompt': utils.get_prompt(x, aspect, task='train',evaluation_type='score_only')})\n",
    "    dataset['test'] = dataset['test'].map(lambda x: {'prompt': utils.get_prompt(x, aspect, task='test',evaluation_type='score_only')})\n",
    "    dataset.push_to_hub(f'boda/review_evaluation_automatic_labels',config_name=aspect )\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 9881 not found in verifiability\n",
      "row 5316 not found in verifiability\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "744b95031b7a4f608859a9a466081584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673a6e90bb0a41d48b2444a8b1963766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695aceae39ef45b9a0bdd7f90f1dad4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d6ae4cb37848c5bbf37bbd3177ac48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33881e94bd046ea961d5c0c997e0013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13f889abd7e4e199cfcb85c982c12c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344d1a3b329d48d7867db53cef27e81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/boda/review_evaluation_automatic_labels/commit/06298b774cdc7f8b6e2671b35a14af013479ef7d', commit_message='Upload dataset', commit_description='', oid='06298b774cdc7f8b6e2671b35a14af013479ef7d', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/boda/review_evaluation_automatic_labels', endpoint='https://huggingface.co', repo_type='dataset', repo_id='boda/review_evaluation_automatic_labels'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merged_df = []\n",
    "\n",
    "### aggregate the different aspects in one dataset\n",
    "for i,row in data['actionability'].iterrows():\n",
    "    ## remove the prompt column\n",
    "    row.pop('prompt')\n",
    "    failed = False\n",
    "    for aspect in data.keys():\n",
    "        if aspect == 'actionability':\n",
    "            continue\n",
    "        ### get the same row from the other aspects\n",
    "        ## make sure the row exist\n",
    "        if row['id'] not in data[aspect]['id'].values:\n",
    "            print(f'row {row[\"id\"]} not found in {aspect}')\n",
    "            ## ignore this row\n",
    "            failed = True\n",
    "            continue\n",
    "\n",
    "        aspect_row = data[aspect][data[aspect]['id'] == row['id']].iloc[0]\n",
    "        row[f'chatgpt_{aspect}_score'] = aspect_row[f'chatgpt_{aspect}_score']\n",
    "        row[f'chatgpt_{aspect}_rationale'] = aspect_row[f'chatgpt_{aspect}_rationale']\n",
    "        ## if the score or rationale is none then ignore this row\n",
    "        if pd.isna(aspect_row[f'chatgpt_{aspect}_score']):\n",
    "            print(f'row {row[\"id\"]} has no score in {aspect}')\n",
    "            failed = True\n",
    "            continue\n",
    "        # row[f'{aspect}_prompt'] = aspect_row['prompt']\n",
    "    if not failed:\n",
    "        merged_df.append(row)\n",
    "    \n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "\n",
    "\n",
    "## convert the df to dataset and push to hub\n",
    "dataset = datasets.Dataset.from_pandas(merged_df).train_test_split(test_size=0.1)\n",
    "## add new column for the prompt\n",
    "dataset['train'] = dataset['train'].map(lambda x: {'prompt': utils.get_prompt(x, 'all', task='train',evaluation_type='score_only')})\n",
    "dataset['test'] = dataset['test'].map(lambda x: {'prompt': utils.get_prompt(x, 'all', task='test',evaluation_type='score_only')})\n",
    "dataset.push_to_hub(f'boda/review_evaluation_automatic_labels',config_name='all' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 5 4 2]\n",
      "[3 1 5 2 4]\n",
      "['2' '3' '1' '4' '5' 'X']\n",
      "[4 1 3 5 2]\n"
     ]
    }
   ],
   "source": [
    "for aspect in aspects:\n",
    "    print(merged_df[f'chatgpt_{aspect}_score'].unique())\n",
    "\n",
    "### get the rows that has the nan values\n",
    "nan_rows = merged_df[merged_df.isna().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>venue</th>\n",
       "      <th>focused_review</th>\n",
       "      <th>review_point</th>\n",
       "      <th>id</th>\n",
       "      <th>chatgpt_actionability_score</th>\n",
       "      <th>chatgpt_actionability_rationale</th>\n",
       "      <th>chatgpt_helpfulness_score</th>\n",
       "      <th>chatgpt_helpfulness_rationale</th>\n",
       "      <th>chatgpt_grounding_specificity_score</th>\n",
       "      <th>chatgpt_grounding_specificity_rationale</th>\n",
       "      <th>chatgpt_verifiability_score</th>\n",
       "      <th>chatgpt_verifiability_rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>oVJXUvXT9b</td>\n",
       "      <td>EMNLP_2023</td>\n",
       "      <td>- The paper does not read well; the text is cl...</td>\n",
       "      <td>- The processing pipeline seems too heavy for ...</td>\n",
       "      <td>9881</td>\n",
       "      <td>4</td>\n",
       "      <td>The comment implies that the authors should co...</td>\n",
       "      <td>4</td>\n",
       "      <td>The comment identifies a potential issue with ...</td>\n",
       "      <td>3</td>\n",
       "      <td>The comment addresses the processing pipeline,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>ACL_2017_371_review</td>\n",
       "      <td>ACL_2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>- It's not true that the pRNN outperforms both...</td>\n",
       "      <td>199</td>\n",
       "      <td>5</td>\n",
       "      <td>The review comment provides explicit instructi...</td>\n",
       "      <td>5</td>\n",
       "      <td>The review comment is highly helpful as it pro...</td>\n",
       "      <td>5</td>\n",
       "      <td>The comment is fully grounded as it explicitly...</td>\n",
       "      <td>4</td>\n",
       "      <td>The review point makes a claim that the statem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Onw93uJCWO</td>\n",
       "      <td>ICLR_2025</td>\n",
       "      <td>1.Further experiments should be conducted for ...</td>\n",
       "      <td>3. The biggest weakness of this paper is that ...</td>\n",
       "      <td>5316</td>\n",
       "      <td>3</td>\n",
       "      <td>The review comment identifies a significant we...</td>\n",
       "      <td>3</td>\n",
       "      <td>The review comment identifies a significant we...</td>\n",
       "      <td>3</td>\n",
       "      <td>The comment identifies a significant weakness ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                paper_id       venue  \\\n",
       "130           oVJXUvXT9b  EMNLP_2023   \n",
       "580  ACL_2017_371_review    ACL_2017   \n",
       "604           Onw93uJCWO   ICLR_2025   \n",
       "\n",
       "                                        focused_review  \\\n",
       "130  - The paper does not read well; the text is cl...   \n",
       "580                                                NaN   \n",
       "604  1.Further experiments should be conducted for ...   \n",
       "\n",
       "                                          review_point    id  \\\n",
       "130  - The processing pipeline seems too heavy for ...  9881   \n",
       "580  - It's not true that the pRNN outperforms both...   199   \n",
       "604  3. The biggest weakness of this paper is that ...  5316   \n",
       "\n",
       "     chatgpt_actionability_score  \\\n",
       "130                            4   \n",
       "580                            5   \n",
       "604                            3   \n",
       "\n",
       "                       chatgpt_actionability_rationale  \\\n",
       "130  The comment implies that the authors should co...   \n",
       "580  The review comment provides explicit instructi...   \n",
       "604  The review comment identifies a significant we...   \n",
       "\n",
       "     chatgpt_helpfulness_score  \\\n",
       "130                          4   \n",
       "580                          5   \n",
       "604                          3   \n",
       "\n",
       "                         chatgpt_helpfulness_rationale  \\\n",
       "130  The comment identifies a potential issue with ...   \n",
       "580  The review comment is highly helpful as it pro...   \n",
       "604  The review comment identifies a significant we...   \n",
       "\n",
       "     chatgpt_grounding_specificity_score  \\\n",
       "130                                    3   \n",
       "580                                    5   \n",
       "604                                    3   \n",
       "\n",
       "               chatgpt_grounding_specificity_rationale  \\\n",
       "130  The comment addresses the processing pipeline,...   \n",
       "580  The comment is fully grounded as it explicitly...   \n",
       "604  The comment identifies a significant weakness ...   \n",
       "\n",
       "    chatgpt_verifiability_score  \\\n",
       "130                         NaN   \n",
       "580                           4   \n",
       "604                         NaN   \n",
       "\n",
       "                       chatgpt_verifiability_rationale  \n",
       "130                                                NaN  \n",
       "580  The review point makes a claim that the statem...  \n",
       "604                                                NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_to_keep = ['review_point','paper_id','venue','focused_review']\n",
    "# all_datasets = {}\n",
    "# for aspect in aspects:\n",
    "#     aspect_dataset = []\n",
    "\n",
    "#     aspect_data = all_data[all_data[f'{aspect}_label_type'] == 'gold']\n",
    "#     aspcets_columns_to_keep = columns_to_keep + [f'{aspect}_label']\n",
    "#     aspect_data = aspect_data[aspcets_columns_to_keep]\n",
    "\n",
    "#     for i,row in aspect_data.iterrows():\n",
    "#         row['prompt'] = utils.get_prompt(row, aspect, task='train',evaluation_type='score_only')\n",
    "#         aspect_dataset.append(row)\n",
    "#     aspect_dataset = pd.DataFrame(aspect_dataset)\n",
    "#     aspect_dataset = datasets.Dataset.from_pandas(aspect_dataset)\n",
    "#     if '__index_level_0__' in aspect_dataset.column_names:\n",
    "#         aspect_dataset = aspect_dataset.remove_columns('__index_level_0__')\n",
    "\n",
    "#     ## split the dataset to train and validation\n",
    "#     aspect_dataset = aspect_dataset.train_test_split(test_size=0.1)\n",
    "#     all_datasets[aspect] = aspect_dataset\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are an expert in evaluating peer review comments with respect to different aspects. These aspects are aimed to maximize the utilization of the review comments for the authors. The primary purpose of the review is to help/guide authors in improving their drafts. Keep this in mind while evaluating the review point. Whenever you encounter a borderline case, think: “Will this review point help authors improve their draft?”. There is no correlation between the aspect score and the length of the review point.actionability: Measures the level of actionability in the review point. We evaluate actionability according to two points: \\n1. Is the action stated directly, or does the author need to infer it? (Explicit vs. Implicit). \\n2.  After identifying the action, do you know how to apply it, or the action is vague? (Concrete vs. Vague)\\n- It’s more important for actions to be concrete so the authors know how to apply them. It’s also preferred that actions be stated directly rather than inferred.\\nDefinitions:\\nExplicit:  Direct or apparent actions or suggestions. Authors can directly identify modifications that they should apply to their draft. Clarification questions should be treated as explicit statements if they give a direct action.\\nImplicit:  Actions that can be deduced. This can be in the form of questions that need to be addressed or missing parts that need to be added. Actions are not stated directly, but the authors can infer what needs to be done after reading the comment.\\nConcrete: After Identifying the action, the authors know exactly what needs to be done and how to apply the action.\\nVague: After Identifying the action, the authors still don’t know how to carry out this action.\\n Actionability is rated on a scale from 1-5, and we will now provide a definition for each.\\n1: Unactionable\\nDefinition: The comment lacks any meaningful information to help the authors to improve the paper. After reading the comment, the authors do not know what they should do.\\n2: Borderline Actionable\\nDefinition: The comment includes an implicitly stated action, or the action can be inferred. Further, the action itself is vague and lacks detail on how to apply it.\\n3: Somewhat Actionable\\nDefinition: The comment explicitly states an action but is vague on how to execute it.\\n4: Mostly Actionable\\nDefinition: The comment implicitly states an action but concretely states how to implement the inferred action.\\n5: Highly Actionable\\nDefinition: The comment contains explicit action and concrete details on how to implement it. The authors know exactly how to apply it.\\ngrounding_specificity: This aspect measures how explicitly a review comment is based on a part of the paper. This is important so the authors know which part of their paper causes the issue and needs to be revised. Further, it measures how specifically the comment identifies what is the issue with this part of the paper. This aspect has two dimensions: (1) what part of the paper does this comment address, and (2) what is wrong with this part?\\nDefinitions:\\nGrounding: Measures how well the authors can identify what is being addressed by the comment. (This can be no grounding, weak grounding, or full grounding). \\n* Weak grounding means that the author can’t precisely identify the part of the paper being addressed by the point, but they have some hint or guess about it. \\n* Full grounding means the authors can accurately identify which part is being addressed. This can be done by:\\n   - Making literal mentions of sections, tables, figures, etc.\\n     - The point discusses something unique to the paper that the authors can identify.\\n     - General comments that do not need to mention specific parts of the paper, but the authors can easily infer which parts are addressed\\nSpecificity: Measures how much the reviewer detailed what is wrong/missing in this area. If the comment mentions some external work, it also measures whether it mentions specific examples. \\n  Grounding and specificity is rated on a scale from 1-5, and we will now provide a definition for each.\\n1: Not Grounded\\nDefinition: This comment is not grounded at all. It does not identify a specific area in the paper. The comment is highly unspecific.\\n2: Weakly grounded and not specific\\nDefinition: The authors can not confidently determine which part the comment addresses. Further, the comment does not specify what needs to be addressed in this part.\\n3: Weakly grounded and specific\\nDefinition: The authors can not confidently determine which part the comment addresses. However, the comment clearly specifies what needs to be addressed in this part.\\n4: Fully grounded and under-specific\\nDefinition: The comment explicitly mentions which part of that paper it addresses, or it should be obvious to the authors. However, this comment does not specify what needs to be addressed in this part.\\n5: Fully grounded and specific\\nDefinition: The comment explicitly mentions which part of that paper it addresses, it is obvious to the authors. The comment specifies what needs to be addressed in this part.\\nverifiability: This aspect measures whether there is a claim (i.e. a subjective opinion) in the comment and how well it is verified. You need to detect first whether this review comment contains any claims. If there are any, evaluate how well the reviewer justifies or proves this claim by providing logical reasoning, using common sense or providing references. The claims\\' justification or validation can come before or after the claim. Claims don’t need to be stated directly; they can also be inferred.\\nDefinitions:\\nOpinion & Claims\\nSubjective statements. For example, an opinion or a stand that the reviewer takes (like a disagreement with an experimental choice).\\nAny suggestions or requests for changes. For example, stating that something is worth discussing, should be removed, or added.\\nAny comments judging some parts of the paper. For example, stating something is hard to read, not detailed enough, or comments about how good or bad some section of the paper is.\\nAny deductions or inferred observations that go beyond just stating facts or results from the paper.\\nGenerally, any phrases where the reviewer should provide evidence to back up their claim and help the authors understand it better. This can be direct or indirect:\\n    - Ex: “Important methods like X are not discussed”. We can infer that the reviewer suggests that method X should be discussed. Hence, the reviewer should state why this method should be discussed.\\nVerification\\nThe claim is verified by providing logical reasoning.\\nThe claim is verified through common sense knowledge in the field. For example, referring to certain commonly used practices or standards.\\nThe claim is verified by providing external references.\\nNormal Statements\\nNormal statements should be given the label \"No Claim\".\\nIndicating that something exists, or missing without indicating that it should be removed or included.\\nGeneral statements about the paper, that don’t include an opinion.\\nObjective and factual statements that don’t need any kind of verification.\\nAsking for clarifications and general questions.\\nLogical statements, or things that can be inferred directly.\\nWe treat positive claims as normal sentences, as they are of little use to the authors to improve their paper.\\n    - Example: This paper is well written, and the experimentation methods are well designed.\\nVerifiability is rated on a scale from 1-5, and \"No Claim\" (for normal statements). We will now provide a definition for each.\\n1: Unverifiable\\nDefinition: The comment contains a claim without any supporting evidence or justification.\\n2: Borderline Verifiable\\nDefinition: The comment provides some support for its claim, but it is insufficient, vague, or not fully articulated. The authors will struggle to follow the justification.\\n3: Somewhat Verifiable\\nDefinition: The comment provides support for its claim, but one or more key elements are missing, such as specific examples, detailed explanations, or supporting references. It requires significant effort from the authors to follow the justification.\\n4: Mostly Verifiable\\nDefinition: The comment’s claim is sufficiently supported but has minor gaps. The reviewer could provide a more detailed explanation or reference to support their claims.\\n5: Fully Verifiable\\nDefinition: The claim is thoroughly supported by explicit, sufficient, and robust evidence. This can be done by:\\nClear and precise reasoning or explanation.\\nReferences to external works/data, when applicable, are specific and relevant.\\nCommon-sense arguments are logically unassailable.\\nX: No Claim\\nDefinition: The comment does not contain any claim, opinion, or suggestion and consists of only factual, descriptive statements that do not require any justification.\\nClear and precise reasoning or explanation.\\nReferences to external works/data, when applicable, are specific and relevant.\\nCommon-sense arguments are logically unassailable.\\nhelpfulness: Assign a subjective score to reflect the value of the review comment to the authors.\\n\\nHelpfulness is rated on a scale from 1-5, and we will now provide a definition for each.\\n\\n1. The comment is not helpful at all\\nDefinition: The comment fails to identify any meaningful weaknesses or suggest improvements, leaving the authors with no actionable feedback.\\n2. The comment is barely helpful\\nDefinition: The comment identifies a weakness or improvement area but is vague, lacks clarity, or provides minimal guidance, making it only slightly beneficial for the authors.\\n3. The comment is somewhat helpful\\nDefinition: The comment identifies weaknesses or areas for improvement but is incomplete or lacks depth. While the authors can gain some insights, the feedback does not fully address their needs for improving the draft.\\n4. The comment is mostly helpful\\nDefinition: The comment provides clear and actionable feedback on weaknesses and areas for improvement, though it could be expanded or refined to be fully comprehensive and impactful.\\n5. The comment is highly helpful\\nDefinition: The comment thoroughly identifies weaknesses and offers detailed, actionable, and constructive suggestions that empower the authors to significantly improve their draft.\\n\\nEvaluate the review based on the given definitions of the aspect(s) above. Output only the score.\\nReview Point: 2) This experiment uses ready-made embeddings (GloVe) and parameters (context2vec) that were tuned on completely different datasets with very different sizes. Comparing the two is empirically flawed, and probably biased towards the method using GloVe (which was a trained on a much larger corpus). In addition, it seems that the biggest boost in performance comes from adding similarity features and not from the proposed context representation. This is not discussed. = Miscellaneous Comments = - I liked the WordNet dataset - using the example sentences is a nice trick.', 'role': 'user'}, {'content': \"{'helpfulness_label': '3'}\", 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "print(dataset['test']['prompt'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
