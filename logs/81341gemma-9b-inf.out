starting Inf.......................
WARNING 08-26 21:19:17 utils.py:569] Gemma 2 uses sliding window attention for every odd layer, which is currently not supported by vLLM. Disabling sliding window and capping the max length to the sliding window size (4096).
INFO 08-26 21:19:17 llm_engine.py:176] Initializing an LLM engine (v0.5.3.post1) with config: model='google/gemma-2-9b-it', speculative_config=None, tokenizer='google/gemma-2-9b-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None), seed=0, served_model_name=google/gemma-2-9b-it, use_v2_block_manager=False, enable_prefix_caching=False)
INFO 08-26 21:19:20 selector.py:80] Using Flashinfer backend.
INFO 08-26 21:19:22 model_runner.py:680] Starting to load model google/gemma-2-9b-it...
INFO 08-26 21:19:22 selector.py:80] Using Flashinfer backend.
INFO 08-26 21:19:22 weight_utils.py:223] Using model weights format ['*.safetensors']
INFO 08-26 21:19:55 model_runner.py:692] Loading model weights took 17.3781 GB
INFO 08-26 21:19:57 gpu_executor.py:102] # GPU blocks: 2955, # CPU blocks: 780
INFO 08-26 21:20:00 model_runner.py:980] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 08-26 21:20:00 model_runner.py:984] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.
INFO 08-26 21:20:10 model_runner.py:1181] Graph capturing finished in 11 secs.
/fsx/homes/Abdelrahman.Sadallah@mbzuai.ac.ae/mbzuai/peerq-generation/notebooks
